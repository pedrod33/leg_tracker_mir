{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7b81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow.keras\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ffe36bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData = pd.read_csv('../feature_data/features.csv')\n",
    "allData.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "allData = allData.dropna()\n",
    "X = allData.drop([\"label\"],axis=1)\n",
    "X = X.drop([\"radius\"],axis=1)\n",
    "cols = X.keys()\n",
    "\n",
    "#normalize data\n",
    "#X = preprocessing.normalize(X, norm='max')\n",
    "\n",
    "#labels\n",
    "y = allData[\"label\"]\n",
    "\n",
    "#features\n",
    "X = pd.DataFrame(X, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e958f63c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_points</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_median_dev</th>\n",
       "      <th>width</th>\n",
       "      <th>linearity</th>\n",
       "      <th>circularity</th>\n",
       "      <th>boundary_length</th>\n",
       "      <th>boundary_regularity</th>\n",
       "      <th>mean_curvature</th>\n",
       "      <th>ang_diff</th>\n",
       "      <th>iav</th>\n",
       "      <th>std_iav</th>\n",
       "      <th>distance</th>\n",
       "      <th>dist_num_points</th>\n",
       "      <th>occluded_right</th>\n",
       "      <th>occluded_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9.489000e+03</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.307936</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>0.123339</td>\n",
       "      <td>0.442383</td>\n",
       "      <td>19.646191</td>\n",
       "      <td>1.498107e-01</td>\n",
       "      <td>0.534513</td>\n",
       "      <td>0.017417</td>\n",
       "      <td>19.784566</td>\n",
       "      <td>2.237601</td>\n",
       "      <td>2.627493</td>\n",
       "      <td>1.561736</td>\n",
       "      <td>2.957513</td>\n",
       "      <td>0.440747</td>\n",
       "      <td>0.783644</td>\n",
       "      <td>0.722942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.506733</td>\n",
       "      <td>0.233990</td>\n",
       "      <td>0.205220</td>\n",
       "      <td>0.791545</td>\n",
       "      <td>158.022617</td>\n",
       "      <td>1.136570e+00</td>\n",
       "      <td>0.933008</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>18.819969</td>\n",
       "      <td>0.623728</td>\n",
       "      <td>0.718840</td>\n",
       "      <td>0.519241</td>\n",
       "      <td>1.900385</td>\n",
       "      <td>0.528611</td>\n",
       "      <td>0.411781</td>\n",
       "      <td>0.447569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>8.969470e-16</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.045276</td>\n",
       "      <td>0.186256</td>\n",
       "      <td>0.421913</td>\n",
       "      <td>0.273109</td>\n",
       "      <td>0.289371</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.038555</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.101891</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>1.677530e-04</td>\n",
       "      <td>0.130319</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>5.679890</td>\n",
       "      <td>1.890190</td>\n",
       "      <td>2.219300</td>\n",
       "      <td>1.202750</td>\n",
       "      <td>1.478220</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.056707</td>\n",
       "      <td>0.045411</td>\n",
       "      <td>0.144635</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>8.454680e-04</td>\n",
       "      <td>0.195660</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>13.218500</td>\n",
       "      <td>2.376490</td>\n",
       "      <td>2.777150</td>\n",
       "      <td>1.578390</td>\n",
       "      <td>2.345690</td>\n",
       "      <td>0.244998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.134151</td>\n",
       "      <td>0.118170</td>\n",
       "      <td>0.380985</td>\n",
       "      <td>0.823912</td>\n",
       "      <td>5.842730e-03</td>\n",
       "      <td>0.525086</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>28.153900</td>\n",
       "      <td>2.733730</td>\n",
       "      <td>3.127850</td>\n",
       "      <td>1.915240</td>\n",
       "      <td>4.034960</td>\n",
       "      <td>0.561094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>3.033200</td>\n",
       "      <td>2.481590</td>\n",
       "      <td>12.762600</td>\n",
       "      <td>3971.650000</td>\n",
       "      <td>2.965000e+01</td>\n",
       "      <td>12.889000</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>123.093000</td>\n",
       "      <td>3.127740</td>\n",
       "      <td>4.565440</td>\n",
       "      <td>3.304990</td>\n",
       "      <td>7.458060</td>\n",
       "      <td>2.482980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_points          std  avg_median_dev        width    linearity  \\\n",
       "count  9489.000000  9489.000000     9489.000000  9489.000000  9489.000000   \n",
       "mean     17.307936     0.145534        0.123339     0.442383    19.646191   \n",
       "std      27.506733     0.233990        0.205220     0.791545   158.022617   \n",
       "min       3.000000     0.008048        0.005680     0.012648     0.000076   \n",
       "25%       6.000000     0.038555        0.031740     0.101891     0.006914   \n",
       "50%       9.000000     0.056707        0.045411     0.144635     0.025590   \n",
       "75%      17.000000     0.134151        0.118170     0.380985     0.823912   \n",
       "max     279.000000     3.033200        2.481590    12.762600  3971.650000   \n",
       "\n",
       "        circularity  boundary_length  boundary_regularity  mean_curvature  \\\n",
       "count  9.489000e+03      9489.000000          9489.000000     9489.000000   \n",
       "mean   1.498107e-01         0.534513             0.017417       19.784566   \n",
       "std    1.136570e+00         0.933008             0.012034       18.819969   \n",
       "min    8.969470e-16         0.017039             0.002987        0.045276   \n",
       "25%    1.677530e-04         0.130319             0.008200        5.679890   \n",
       "50%    8.454680e-04         0.195660             0.013237       13.218500   \n",
       "75%    5.842730e-03         0.525086             0.024435       28.153900   \n",
       "max    2.965000e+01        12.889000             0.072851      123.093000   \n",
       "\n",
       "          ang_diff          iav      std_iav     distance  dist_num_points  \\\n",
       "count  9489.000000  9489.000000  9489.000000  9489.000000      9489.000000   \n",
       "mean      2.237601     2.627493     1.561736     2.957513         0.440747   \n",
       "std       0.623728     0.718840     0.519241     1.900385         0.528611   \n",
       "min       0.186256     0.421913     0.273109     0.289371         0.002502   \n",
       "25%       1.890190     2.219300     1.202750     1.478220         0.101666   \n",
       "50%       2.376490     2.777150     1.578390     2.345690         0.244998   \n",
       "75%       2.733730     3.127850     1.915240     4.034960         0.561094   \n",
       "max       3.127740     4.565440     3.304990     7.458060         2.482980   \n",
       "\n",
       "       occluded_right  occluded_left  \n",
       "count     9489.000000    9489.000000  \n",
       "mean         0.783644       0.722942  \n",
       "std          0.411781       0.447569  \n",
       "min          0.000000       0.000000  \n",
       "25%          1.000000       0.000000  \n",
       "50%          1.000000       1.000000  \n",
       "75%          1.000000       1.000000  \n",
       "max          1.000000       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253c70ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(949, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "print(type(X_test))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=5)\n",
    "y_train.value_counts().plot.bar()\n",
    "\n",
    "print(X_test.shape)\n",
    "#oversample the minority\n",
    "y_train.value_counts().plot.bar()\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=\"minority\", random_state=5)\n",
    "#X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "#y_train.value_counts().plot.bar()\n",
    "#y_test.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addcb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally saved version\n",
    "\n",
    "def NN_Model(units = 32, dropout=0.2, optimizer = 'adam'):\n",
    "    model = models.Sequential()\n",
    "    model.add(tensorflow.keras.Input(shape=(16,)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu',))\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu',))\n",
    "    \n",
    "    model.add(layers.Dense(units = units*2, activation='leaky_relu'))\n",
    "\n",
    "    model.add(layers.Dense(units = units*4, activation='leaky_relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495a8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "def NN_Model(units = 32):\n",
    "    model = models.Sequential()\n",
    "    model.add(tensorflow.keras.Input(shape=(16,)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu',))\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu'))\n",
    "\n",
    "    model.add(layers.Dense(units = units*2, activation='leaky_relu',))\n",
    "    \n",
    "    model.add(layers.Dense(units = units*4, activation='leaky_relu'))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e15ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2\n",
    "def NN_Model(units = 32):\n",
    "    model = models.Sequential()\n",
    "    model.add(tensorflow.keras.Input(shape=(16,)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu',))\n",
    "\n",
    "    model.add(layers.Dense(units = units, activation='leaky_relu',))\n",
    "\n",
    "    model.add(layers.Dense(units = units*2, activation='leaky_relu',))\n",
    "    \n",
    "    model.add(layers.Dense(units = units*4, activation='leaky_relu'))\n",
    "\n",
    "    #model.add(layers.Dense(units = units, activation='leaky_relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a4b65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,329\n",
      "Trainable params: 3,297\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.2339 - accuracy: 0.9167 - val_loss: 0.1593 - val_accuracy: 0.9313\n",
      "Epoch 2/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1532 - accuracy: 0.9310 - val_loss: 0.1365 - val_accuracy: 0.9391\n",
      "Epoch 3/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9322 - val_loss: 0.1335 - val_accuracy: 0.9399\n",
      "Epoch 4/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1443 - accuracy: 0.9361 - val_loss: 0.1183 - val_accuracy: 0.9493\n",
      "Epoch 5/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9401 - val_loss: 0.1160 - val_accuracy: 0.9500\n",
      "Epoch 6/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9409 - val_loss: 0.1116 - val_accuracy: 0.9563\n",
      "Epoch 7/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9434 - val_loss: 0.1159 - val_accuracy: 0.9516\n",
      "Epoch 8/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9457 - val_loss: 0.1090 - val_accuracy: 0.9547\n",
      "Epoch 9/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.9459 - val_loss: 0.1077 - val_accuracy: 0.9571\n",
      "Epoch 10/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1251 - accuracy: 0.9449 - val_loss: 0.1090 - val_accuracy: 0.9571\n",
      "Epoch 11/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9504 - val_loss: 0.1050 - val_accuracy: 0.9555\n",
      "Epoch 12/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9465 - val_loss: 0.1064 - val_accuracy: 0.9571\n",
      "Epoch 13/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.9490 - val_loss: 0.1041 - val_accuracy: 0.9578\n",
      "Epoch 14/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9490 - val_loss: 0.1058 - val_accuracy: 0.9633\n",
      "Epoch 15/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1169 - accuracy: 0.9510 - val_loss: 0.1043 - val_accuracy: 0.9571\n",
      "Epoch 16/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1215 - accuracy: 0.9488 - val_loss: 0.1027 - val_accuracy: 0.9563\n",
      "Epoch 17/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1148 - accuracy: 0.9515 - val_loss: 0.1017 - val_accuracy: 0.9617\n",
      "Epoch 18/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1131 - accuracy: 0.9499 - val_loss: 0.1008 - val_accuracy: 0.9594\n",
      "Epoch 19/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9536 - val_loss: 0.1020 - val_accuracy: 0.9547\n",
      "Epoch 20/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.9515 - val_loss: 0.1019 - val_accuracy: 0.9563\n",
      "Epoch 21/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9514 - val_loss: 0.1005 - val_accuracy: 0.9594\n",
      "Epoch 22/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1178 - accuracy: 0.9527 - val_loss: 0.0990 - val_accuracy: 0.9633\n",
      "Epoch 23/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9532 - val_loss: 0.1007 - val_accuracy: 0.9555\n",
      "Epoch 24/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9527 - val_loss: 0.1016 - val_accuracy: 0.9594\n",
      "Epoch 25/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.9548 - val_loss: 0.0990 - val_accuracy: 0.9625\n",
      "Epoch 26/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9559 - val_loss: 0.0998 - val_accuracy: 0.9617\n",
      "Epoch 27/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9540 - val_loss: 0.1029 - val_accuracy: 0.9641\n",
      "Epoch 28/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9572 - val_loss: 0.1001 - val_accuracy: 0.9602\n",
      "Epoch 29/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9551 - val_loss: 0.0999 - val_accuracy: 0.9633\n",
      "Epoch 30/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9545 - val_loss: 0.0996 - val_accuracy: 0.9610\n",
      "Epoch 31/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1160 - accuracy: 0.9523 - val_loss: 0.1017 - val_accuracy: 0.9602\n",
      "Epoch 32/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9540 - val_loss: 0.0981 - val_accuracy: 0.9602\n",
      "Epoch 33/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1129 - accuracy: 0.9527 - val_loss: 0.1057 - val_accuracy: 0.9602\n",
      "Epoch 34/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9525 - val_loss: 0.1000 - val_accuracy: 0.9610\n",
      "Epoch 35/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9556 - val_loss: 0.1016 - val_accuracy: 0.9586\n",
      "Epoch 36/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9587 - val_loss: 0.0978 - val_accuracy: 0.9602\n",
      "Epoch 37/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9551 - val_loss: 0.0977 - val_accuracy: 0.9602\n",
      "Epoch 38/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9521 - val_loss: 0.0987 - val_accuracy: 0.9680\n",
      "Epoch 39/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1029 - accuracy: 0.9569 - val_loss: 0.0955 - val_accuracy: 0.9625\n",
      "Epoch 40/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9572 - val_loss: 0.1007 - val_accuracy: 0.9649\n",
      "Epoch 41/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9548 - val_loss: 0.0976 - val_accuracy: 0.9641\n",
      "Epoch 42/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1067 - accuracy: 0.9559 - val_loss: 0.0975 - val_accuracy: 0.9633\n",
      "Epoch 43/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9525 - val_loss: 0.1021 - val_accuracy: 0.9578\n",
      "Epoch 44/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9596 - val_loss: 0.0994 - val_accuracy: 0.9586\n",
      "Epoch 45/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1066 - accuracy: 0.9550 - val_loss: 0.0955 - val_accuracy: 0.9649\n",
      "Epoch 46/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9547 - val_loss: 0.1003 - val_accuracy: 0.9617\n",
      "Epoch 47/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9550 - val_loss: 0.0988 - val_accuracy: 0.9610\n",
      "Epoch 48/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.9566 - val_loss: 0.0979 - val_accuracy: 0.9633\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9581 - val_loss: 0.0948 - val_accuracy: 0.9633\n",
      "Epoch 50/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1080 - accuracy: 0.9551 - val_loss: 0.0976 - val_accuracy: 0.9602\n",
      "Epoch 51/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9566 - val_loss: 0.1016 - val_accuracy: 0.9594\n",
      "Epoch 52/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9598 - val_loss: 0.0971 - val_accuracy: 0.9649\n",
      "Epoch 53/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9577 - val_loss: 0.0983 - val_accuracy: 0.9610\n",
      "Epoch 54/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9580 - val_loss: 0.0979 - val_accuracy: 0.9617\n",
      "Epoch 55/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9596 - val_loss: 0.1076 - val_accuracy: 0.9563\n",
      "Epoch 56/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9529 - val_loss: 0.0983 - val_accuracy: 0.9610\n",
      "Epoch 57/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9587 - val_loss: 0.0977 - val_accuracy: 0.9633\n",
      "Epoch 58/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9591 - val_loss: 0.0947 - val_accuracy: 0.9633\n",
      "Epoch 59/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.9585 - val_loss: 0.0937 - val_accuracy: 0.9625\n",
      "Epoch 60/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9565 - val_loss: 0.0999 - val_accuracy: 0.9672\n",
      "Epoch 61/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9618 - val_loss: 0.0909 - val_accuracy: 0.9672\n",
      "Epoch 62/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1027 - accuracy: 0.9596 - val_loss: 0.0947 - val_accuracy: 0.9657\n",
      "Epoch 63/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9567 - val_loss: 0.0949 - val_accuracy: 0.9625\n",
      "Epoch 64/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9613 - val_loss: 0.0917 - val_accuracy: 0.9664\n",
      "Epoch 65/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9595 - val_loss: 0.0931 - val_accuracy: 0.9680\n",
      "Epoch 66/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9587 - val_loss: 0.0963 - val_accuracy: 0.9680\n",
      "Epoch 67/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9620 - val_loss: 0.1003 - val_accuracy: 0.9625\n",
      "Epoch 68/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9588 - val_loss: 0.0932 - val_accuracy: 0.9672\n",
      "Epoch 69/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9607 - val_loss: 0.0921 - val_accuracy: 0.9633\n",
      "Epoch 70/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9599 - val_loss: 0.0918 - val_accuracy: 0.9664\n",
      "Epoch 71/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9618 - val_loss: 0.0895 - val_accuracy: 0.9696\n",
      "Epoch 72/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9588 - val_loss: 0.0957 - val_accuracy: 0.9617\n",
      "Epoch 73/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9580 - val_loss: 0.0935 - val_accuracy: 0.9664\n",
      "Epoch 74/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9616 - val_loss: 0.0951 - val_accuracy: 0.9586\n",
      "Epoch 75/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9609 - val_loss: 0.0962 - val_accuracy: 0.9633\n",
      "Epoch 76/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9605 - val_loss: 0.0960 - val_accuracy: 0.9649\n",
      "Epoch 77/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9618 - val_loss: 0.0936 - val_accuracy: 0.9672\n",
      "Epoch 78/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9629 - val_loss: 0.0947 - val_accuracy: 0.9680\n",
      "Epoch 79/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9614 - val_loss: 0.0927 - val_accuracy: 0.9664\n",
      "Epoch 80/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9620 - val_loss: 0.0945 - val_accuracy: 0.9617\n",
      "Epoch 81/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9599 - val_loss: 0.0982 - val_accuracy: 0.9641\n",
      "Epoch 82/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.9616 - val_loss: 0.0942 - val_accuracy: 0.9625\n",
      "Epoch 83/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9607 - val_loss: 0.0912 - val_accuracy: 0.9680\n",
      "Epoch 84/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9583 - val_loss: 0.0979 - val_accuracy: 0.9633\n",
      "Epoch 85/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9618 - val_loss: 0.0943 - val_accuracy: 0.9657\n",
      "Epoch 86/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9623 - val_loss: 0.0951 - val_accuracy: 0.9680\n",
      "Epoch 87/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9592 - val_loss: 0.0975 - val_accuracy: 0.9664\n",
      "Epoch 88/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9631 - val_loss: 0.0934 - val_accuracy: 0.9649\n",
      "Epoch 89/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9627 - val_loss: 0.0935 - val_accuracy: 0.9672\n",
      "Epoch 90/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9610 - val_loss: 0.0921 - val_accuracy: 0.9641\n",
      "Epoch 91/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9587 - val_loss: 0.1022 - val_accuracy: 0.9633\n",
      "Epoch 92/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9624 - val_loss: 0.0901 - val_accuracy: 0.9672\n",
      "Epoch 93/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9610 - val_loss: 0.0917 - val_accuracy: 0.9672\n",
      "Epoch 94/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9625 - val_loss: 0.0929 - val_accuracy: 0.9680\n",
      "Epoch 95/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9645 - val_loss: 0.0914 - val_accuracy: 0.9672\n",
      "Epoch 96/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9628 - val_loss: 0.0888 - val_accuracy: 0.9688\n",
      "Epoch 97/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9596 - val_loss: 0.0931 - val_accuracy: 0.9641\n",
      "Epoch 98/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9638 - val_loss: 0.0912 - val_accuracy: 0.9657\n",
      "Epoch 99/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9627 - val_loss: 0.0912 - val_accuracy: 0.9672\n",
      "Epoch 100/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9628 - val_loss: 0.0961 - val_accuracy: 0.9657\n",
      "Epoch 101/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9653 - val_loss: 0.0933 - val_accuracy: 0.9649\n",
      "Epoch 102/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9600 - val_loss: 0.0973 - val_accuracy: 0.9641\n",
      "Epoch 103/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9620 - val_loss: 0.0889 - val_accuracy: 0.9688\n",
      "Epoch 104/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9620 - val_loss: 0.0919 - val_accuracy: 0.9649\n",
      "Epoch 105/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9650 - val_loss: 0.0943 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9627 - val_loss: 0.0908 - val_accuracy: 0.9680\n",
      "Epoch 107/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9610 - val_loss: 0.0923 - val_accuracy: 0.9664\n",
      "Epoch 108/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9628 - val_loss: 0.0951 - val_accuracy: 0.9649\n",
      "Epoch 109/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9623 - val_loss: 0.0917 - val_accuracy: 0.9633\n",
      "Epoch 110/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9598 - val_loss: 0.0950 - val_accuracy: 0.9625\n",
      "Epoch 111/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9640 - val_loss: 0.0940 - val_accuracy: 0.9688\n",
      "Epoch 112/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9606 - val_loss: 0.0971 - val_accuracy: 0.9625\n",
      "Epoch 113/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9635 - val_loss: 0.0931 - val_accuracy: 0.9657\n",
      "Epoch 114/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9653 - val_loss: 0.0945 - val_accuracy: 0.9688\n",
      "Epoch 115/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9628 - val_loss: 0.0897 - val_accuracy: 0.9688\n",
      "Epoch 116/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9634 - val_loss: 0.0923 - val_accuracy: 0.9696\n",
      "Epoch 117/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9607 - val_loss: 0.0940 - val_accuracy: 0.9680\n",
      "Epoch 118/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9602 - val_loss: 0.0952 - val_accuracy: 0.9633\n",
      "Epoch 119/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9656 - val_loss: 0.0890 - val_accuracy: 0.9688\n",
      "Epoch 120/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9640 - val_loss: 0.0937 - val_accuracy: 0.9657\n",
      "Epoch 121/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9623 - val_loss: 0.0978 - val_accuracy: 0.9641\n",
      "Epoch 122/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9600 - val_loss: 0.0895 - val_accuracy: 0.9672\n",
      "Epoch 123/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9616 - val_loss: 0.0974 - val_accuracy: 0.9633\n",
      "Epoch 124/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9646 - val_loss: 0.0991 - val_accuracy: 0.9657\n",
      "Epoch 125/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9656 - val_loss: 0.0963 - val_accuracy: 0.9633\n",
      "Epoch 126/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9627 - val_loss: 0.0907 - val_accuracy: 0.9711\n",
      "Epoch 127/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9625 - val_loss: 0.0945 - val_accuracy: 0.9672\n",
      "Epoch 128/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9634 - val_loss: 0.0900 - val_accuracy: 0.9657\n",
      "Epoch 129/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9629 - val_loss: 0.0914 - val_accuracy: 0.9649\n",
      "Epoch 130/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9661 - val_loss: 0.0959 - val_accuracy: 0.9696\n",
      "Epoch 131/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9638 - val_loss: 0.0955 - val_accuracy: 0.9641\n",
      "Epoch 132/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9628 - val_loss: 0.0916 - val_accuracy: 0.9672\n",
      "Epoch 133/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9635 - val_loss: 0.0939 - val_accuracy: 0.9649\n",
      "Epoch 134/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9618 - val_loss: 0.0935 - val_accuracy: 0.9664\n",
      "Epoch 135/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9642 - val_loss: 0.0935 - val_accuracy: 0.9672\n",
      "Epoch 136/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9656 - val_loss: 0.0959 - val_accuracy: 0.9641\n",
      "Epoch 137/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9627 - val_loss: 0.0936 - val_accuracy: 0.9680\n",
      "Epoch 138/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9656 - val_loss: 0.0935 - val_accuracy: 0.9664\n",
      "Epoch 139/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9621 - val_loss: 0.0909 - val_accuracy: 0.9672\n",
      "Epoch 140/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9650 - val_loss: 0.1010 - val_accuracy: 0.9633\n",
      "Epoch 141/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9662 - val_loss: 0.0961 - val_accuracy: 0.9649\n",
      "Epoch 142/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9636 - val_loss: 0.0968 - val_accuracy: 0.9633\n",
      "Epoch 143/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 0.0902 - val_accuracy: 0.9696\n",
      "Epoch 144/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9628 - val_loss: 0.0927 - val_accuracy: 0.9657\n",
      "Epoch 145/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9629 - val_loss: 0.0972 - val_accuracy: 0.9610\n",
      "Epoch 146/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9636 - val_loss: 0.0908 - val_accuracy: 0.9664\n",
      "Epoch 147/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9609 - val_loss: 0.0892 - val_accuracy: 0.9657\n",
      "Epoch 148/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9616 - val_loss: 0.0986 - val_accuracy: 0.9641\n",
      "Epoch 149/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9658 - val_loss: 0.0912 - val_accuracy: 0.9703\n",
      "Epoch 150/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9651 - val_loss: 0.0947 - val_accuracy: 0.9657\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_4 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,225\n",
      "Trainable params: 12,193\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.2145 - accuracy: 0.9129 - val_loss: 0.1477 - val_accuracy: 0.9383\n",
      "Epoch 2/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9344 - val_loss: 0.1225 - val_accuracy: 0.9469\n",
      "Epoch 3/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9346 - val_loss: 0.1173 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1414 - accuracy: 0.9398 - val_loss: 0.1245 - val_accuracy: 0.9461\n",
      "Epoch 5/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.9460 - val_loss: 0.1130 - val_accuracy: 0.9563\n",
      "Epoch 6/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1270 - accuracy: 0.9454 - val_loss: 0.1074 - val_accuracy: 0.9516\n",
      "Epoch 7/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1216 - accuracy: 0.9482 - val_loss: 0.1001 - val_accuracy: 0.9594\n",
      "Epoch 8/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9474 - val_loss: 0.1055 - val_accuracy: 0.9547\n",
      "Epoch 9/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1218 - accuracy: 0.9470 - val_loss: 0.1142 - val_accuracy: 0.9547\n",
      "Epoch 10/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1252 - accuracy: 0.9475 - val_loss: 0.1065 - val_accuracy: 0.9524\n",
      "Epoch 11/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9493 - val_loss: 0.0996 - val_accuracy: 0.9633\n",
      "Epoch 12/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1118 - accuracy: 0.9527 - val_loss: 0.1062 - val_accuracy: 0.9547\n",
      "Epoch 13/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1167 - accuracy: 0.9507 - val_loss: 0.1000 - val_accuracy: 0.9594\n",
      "Epoch 14/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1190 - accuracy: 0.9483 - val_loss: 0.1009 - val_accuracy: 0.9602\n",
      "Epoch 15/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1115 - accuracy: 0.9525 - val_loss: 0.0974 - val_accuracy: 0.9649\n",
      "Epoch 16/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.9532 - val_loss: 0.1001 - val_accuracy: 0.9617\n",
      "Epoch 17/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.9519 - val_loss: 0.1016 - val_accuracy: 0.9602\n",
      "Epoch 18/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1150 - accuracy: 0.9536 - val_loss: 0.1000 - val_accuracy: 0.9617\n",
      "Epoch 19/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9570 - val_loss: 0.0947 - val_accuracy: 0.9641\n",
      "Epoch 20/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1041 - accuracy: 0.9569 - val_loss: 0.1098 - val_accuracy: 0.9586\n",
      "Epoch 21/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9544 - val_loss: 0.0950 - val_accuracy: 0.9657\n",
      "Epoch 22/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9551 - val_loss: 0.1013 - val_accuracy: 0.9657\n",
      "Epoch 23/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1148 - accuracy: 0.9518 - val_loss: 0.1041 - val_accuracy: 0.9610\n",
      "Epoch 24/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9558 - val_loss: 0.1042 - val_accuracy: 0.9571\n",
      "Epoch 25/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.9548 - val_loss: 0.0979 - val_accuracy: 0.9641\n",
      "Epoch 26/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9578 - val_loss: 0.0953 - val_accuracy: 0.9625\n",
      "Epoch 27/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9574 - val_loss: 0.0921 - val_accuracy: 0.9633\n",
      "Epoch 28/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9577 - val_loss: 0.0865 - val_accuracy: 0.9688\n",
      "Epoch 29/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.9563 - val_loss: 0.0984 - val_accuracy: 0.9649\n",
      "Epoch 30/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9581 - val_loss: 0.0940 - val_accuracy: 0.9617\n",
      "Epoch 31/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1086 - accuracy: 0.9527 - val_loss: 0.0976 - val_accuracy: 0.9633\n",
      "Epoch 32/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9605 - val_loss: 0.1005 - val_accuracy: 0.9594\n",
      "Epoch 33/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1071 - accuracy: 0.9591 - val_loss: 0.0910 - val_accuracy: 0.9672\n",
      "Epoch 34/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9589 - val_loss: 0.0906 - val_accuracy: 0.9672\n",
      "Epoch 35/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.9567 - val_loss: 0.0917 - val_accuracy: 0.9672\n",
      "Epoch 36/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9589 - val_loss: 0.0975 - val_accuracy: 0.9649\n",
      "Epoch 37/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9594 - val_loss: 0.0933 - val_accuracy: 0.9696\n",
      "Epoch 38/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9607 - val_loss: 0.0906 - val_accuracy: 0.9657\n",
      "Epoch 39/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9585 - val_loss: 0.0889 - val_accuracy: 0.9664\n",
      "Epoch 40/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9578 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 41/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9589 - val_loss: 0.0932 - val_accuracy: 0.9625\n",
      "Epoch 42/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9617 - val_loss: 0.0932 - val_accuracy: 0.9641\n",
      "Epoch 43/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9580 - val_loss: 0.0920 - val_accuracy: 0.9672\n",
      "Epoch 44/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1076 - accuracy: 0.9570 - val_loss: 0.0887 - val_accuracy: 0.9664\n",
      "Epoch 45/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9618 - val_loss: 0.0940 - val_accuracy: 0.9664\n",
      "Epoch 46/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9584 - val_loss: 0.0900 - val_accuracy: 0.9672\n",
      "Epoch 47/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9589 - val_loss: 0.0920 - val_accuracy: 0.9672\n",
      "Epoch 48/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9609 - val_loss: 0.0868 - val_accuracy: 0.9657\n",
      "Epoch 49/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9636 - val_loss: 0.0911 - val_accuracy: 0.9664\n",
      "Epoch 50/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9613 - val_loss: 0.0849 - val_accuracy: 0.9680\n",
      "Epoch 51/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9610 - val_loss: 0.0956 - val_accuracy: 0.9664\n",
      "Epoch 52/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9591 - val_loss: 0.0893 - val_accuracy: 0.9657\n",
      "Epoch 53/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9617 - val_loss: 0.0921 - val_accuracy: 0.9657\n",
      "Epoch 54/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9627 - val_loss: 0.0902 - val_accuracy: 0.9680\n",
      "Epoch 55/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9603 - val_loss: 0.0945 - val_accuracy: 0.9610\n",
      "Epoch 56/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9616 - val_loss: 0.0846 - val_accuracy: 0.9672\n",
      "Epoch 57/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9592 - val_loss: 0.0874 - val_accuracy: 0.9680\n",
      "Epoch 58/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9618 - val_loss: 0.0932 - val_accuracy: 0.9672\n",
      "Epoch 59/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9636 - val_loss: 0.0899 - val_accuracy: 0.9680\n",
      "Epoch 60/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9636 - val_loss: 0.0895 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9614 - val_loss: 0.0858 - val_accuracy: 0.9680\n",
      "Epoch 62/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9618 - val_loss: 0.0879 - val_accuracy: 0.9664\n",
      "Epoch 63/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9625 - val_loss: 0.0865 - val_accuracy: 0.9703\n",
      "Epoch 64/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9603 - val_loss: 0.0868 - val_accuracy: 0.9688\n",
      "Epoch 65/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.0924 - val_accuracy: 0.9664\n",
      "Epoch 66/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9603 - val_loss: 0.0940 - val_accuracy: 0.9649\n",
      "Epoch 67/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9647 - val_loss: 0.0879 - val_accuracy: 0.9672\n",
      "Epoch 68/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9629 - val_loss: 0.0848 - val_accuracy: 0.9703\n",
      "Epoch 69/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9661 - val_loss: 0.0820 - val_accuracy: 0.9703\n",
      "Epoch 70/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9665 - val_loss: 0.0890 - val_accuracy: 0.9664\n",
      "Epoch 71/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9662 - val_loss: 0.0942 - val_accuracy: 0.9664\n",
      "Epoch 72/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9642 - val_loss: 0.0881 - val_accuracy: 0.9696\n",
      "Epoch 73/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9634 - val_loss: 0.0906 - val_accuracy: 0.9657\n",
      "Epoch 74/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9632 - val_loss: 0.0856 - val_accuracy: 0.9657\n",
      "Epoch 75/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9631 - val_loss: 0.0884 - val_accuracy: 0.9688\n",
      "Epoch 76/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9620 - val_loss: 0.0870 - val_accuracy: 0.9657\n",
      "Epoch 77/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9631 - val_loss: 0.0867 - val_accuracy: 0.9672\n",
      "Epoch 78/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9640 - val_loss: 0.0838 - val_accuracy: 0.9688\n",
      "Epoch 79/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9649 - val_loss: 0.0850 - val_accuracy: 0.9696\n",
      "Epoch 80/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9635 - val_loss: 0.0810 - val_accuracy: 0.9688\n",
      "Epoch 81/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9632 - val_loss: 0.0850 - val_accuracy: 0.9672\n",
      "Epoch 82/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9628 - val_loss: 0.0930 - val_accuracy: 0.9688\n",
      "Epoch 83/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9651 - val_loss: 0.0945 - val_accuracy: 0.9703\n",
      "Epoch 84/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9636 - val_loss: 0.0991 - val_accuracy: 0.9664\n",
      "Epoch 85/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9685 - val_loss: 0.0909 - val_accuracy: 0.9680\n",
      "Epoch 86/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9599 - val_loss: 0.0862 - val_accuracy: 0.9664\n",
      "Epoch 87/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 0.0945 - val_accuracy: 0.9672\n",
      "Epoch 88/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9621 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 89/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9623 - val_loss: 0.0831 - val_accuracy: 0.9672\n",
      "Epoch 90/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9656 - val_loss: 0.0817 - val_accuracy: 0.9703\n",
      "Epoch 91/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9647 - val_loss: 0.0871 - val_accuracy: 0.9672\n",
      "Epoch 92/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9631 - val_loss: 0.0908 - val_accuracy: 0.9688\n",
      "Epoch 93/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.9646 - val_loss: 0.0957 - val_accuracy: 0.9641\n",
      "Epoch 94/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9658 - val_loss: 0.0974 - val_accuracy: 0.9641\n",
      "Epoch 95/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9664 - val_loss: 0.0861 - val_accuracy: 0.9696\n",
      "Epoch 96/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9646 - val_loss: 0.0874 - val_accuracy: 0.9641\n",
      "Epoch 97/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9660 - val_loss: 0.0856 - val_accuracy: 0.9680\n",
      "Epoch 98/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9616 - val_loss: 0.0835 - val_accuracy: 0.9696\n",
      "Epoch 99/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9639 - val_loss: 0.0876 - val_accuracy: 0.9657\n",
      "Epoch 100/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9603 - val_loss: 0.0878 - val_accuracy: 0.9664\n",
      "Epoch 101/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9656 - val_loss: 0.0870 - val_accuracy: 0.9688\n",
      "Epoch 102/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9634 - val_loss: 0.0812 - val_accuracy: 0.9688\n",
      "Epoch 103/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9668 - val_loss: 0.0815 - val_accuracy: 0.9680\n",
      "Epoch 104/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9651 - val_loss: 0.0783 - val_accuracy: 0.9672\n",
      "Epoch 105/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9629 - val_loss: 0.0942 - val_accuracy: 0.9680\n",
      "Epoch 106/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9634 - val_loss: 0.0799 - val_accuracy: 0.9672\n",
      "Epoch 107/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9632 - val_loss: 0.0815 - val_accuracy: 0.9688\n",
      "Epoch 108/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9662 - val_loss: 0.0829 - val_accuracy: 0.9711\n",
      "Epoch 109/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9662 - val_loss: 0.0850 - val_accuracy: 0.9711\n",
      "Epoch 110/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9650 - val_loss: 0.0794 - val_accuracy: 0.9688\n",
      "Epoch 111/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9664 - val_loss: 0.0866 - val_accuracy: 0.9664\n",
      "Epoch 112/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.9672 - val_loss: 0.0876 - val_accuracy: 0.9641\n",
      "Epoch 113/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9658 - val_loss: 0.0791 - val_accuracy: 0.9703\n",
      "Epoch 114/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9640 - val_loss: 0.0840 - val_accuracy: 0.9664\n",
      "Epoch 115/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9629 - val_loss: 0.0837 - val_accuracy: 0.9703\n",
      "Epoch 116/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.9649 - val_loss: 0.0857 - val_accuracy: 0.9641\n",
      "Epoch 117/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9675 - val_loss: 0.0824 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9643 - val_loss: 0.0799 - val_accuracy: 0.9696\n",
      "Epoch 119/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9661 - val_loss: 0.0825 - val_accuracy: 0.9703\n",
      "Epoch 120/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9634 - val_loss: 0.0842 - val_accuracy: 0.9711\n",
      "Epoch 121/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9651 - val_loss: 0.0857 - val_accuracy: 0.9657\n",
      "Epoch 122/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9668 - val_loss: 0.0828 - val_accuracy: 0.9688\n",
      "Epoch 123/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9642 - val_loss: 0.0941 - val_accuracy: 0.9641\n",
      "Epoch 124/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9660 - val_loss: 0.0853 - val_accuracy: 0.9688\n",
      "Epoch 125/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9646 - val_loss: 0.0889 - val_accuracy: 0.9672\n",
      "Epoch 126/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9682 - val_loss: 0.0844 - val_accuracy: 0.9680\n",
      "Epoch 127/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.9671 - val_loss: 0.0865 - val_accuracy: 0.9688\n",
      "Epoch 128/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.9650 - val_loss: 0.0801 - val_accuracy: 0.9680\n",
      "Epoch 129/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.9647 - val_loss: 0.0817 - val_accuracy: 0.9711\n",
      "Epoch 130/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9683 - val_loss: 0.0881 - val_accuracy: 0.9696\n",
      "Epoch 131/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.9701 - val_loss: 0.0795 - val_accuracy: 0.9727\n",
      "Epoch 132/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9661 - val_loss: 0.0778 - val_accuracy: 0.9727\n",
      "Epoch 133/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9678 - val_loss: 0.0791 - val_accuracy: 0.9688\n",
      "Epoch 134/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 0.0801 - val_accuracy: 0.9657\n",
      "Epoch 135/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9671 - val_loss: 0.0838 - val_accuracy: 0.9680\n",
      "Epoch 136/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.9705 - val_loss: 0.0774 - val_accuracy: 0.9727\n",
      "Epoch 137/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9689 - val_loss: 0.0828 - val_accuracy: 0.9719\n",
      "Epoch 138/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9674 - val_loss: 0.0926 - val_accuracy: 0.9672\n",
      "Epoch 139/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9674 - val_loss: 0.0819 - val_accuracy: 0.9727\n",
      "Epoch 140/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9689 - val_loss: 0.0916 - val_accuracy: 0.9688\n",
      "Epoch 141/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9667 - val_loss: 0.0921 - val_accuracy: 0.9680\n",
      "Epoch 142/150\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9647 - val_loss: 0.0902 - val_accuracy: 0.9688\n",
      "Epoch 143/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9645 - val_loss: 0.0824 - val_accuracy: 0.9680\n",
      "Epoch 144/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9649 - val_loss: 0.0822 - val_accuracy: 0.9688\n",
      "Epoch 145/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9660 - val_loss: 0.0808 - val_accuracy: 0.9688\n",
      "Epoch 146/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9654 - val_loss: 0.0906 - val_accuracy: 0.9672\n",
      "Epoch 147/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9674 - val_loss: 0.0847 - val_accuracy: 0.9735\n",
      "Epoch 148/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9664\n",
      "Epoch 149/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.9671 - val_loss: 0.0862 - val_accuracy: 0.9664\n",
      "Epoch 150/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.0863 - val_accuracy: 0.9664\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_5 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,913\n",
      "Trainable params: 46,881\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9253 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
      "Epoch 2/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9383 - val_loss: 0.1198 - val_accuracy: 0.9477\n",
      "Epoch 3/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1311 - accuracy: 0.9457 - val_loss: 0.1220 - val_accuracy: 0.9422\n",
      "Epoch 4/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9492 - val_loss: 0.1187 - val_accuracy: 0.9430\n",
      "Epoch 5/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1234 - accuracy: 0.9464 - val_loss: 0.0983 - val_accuracy: 0.9625\n",
      "Epoch 6/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1232 - accuracy: 0.9459 - val_loss: 0.1183 - val_accuracy: 0.9547\n",
      "Epoch 7/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.9503 - val_loss: 0.1008 - val_accuracy: 0.9610\n",
      "Epoch 8/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9500 - val_loss: 0.1036 - val_accuracy: 0.9610\n",
      "Epoch 9/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.9534 - val_loss: 0.0989 - val_accuracy: 0.9617\n",
      "Epoch 10/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1232 - accuracy: 0.9489 - val_loss: 0.1057 - val_accuracy: 0.9617\n",
      "Epoch 11/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.9511 - val_loss: 0.0986 - val_accuracy: 0.9625\n",
      "Epoch 12/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1122 - accuracy: 0.9504 - val_loss: 0.0969 - val_accuracy: 0.9625\n",
      "Epoch 13/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.9550 - val_loss: 0.0935 - val_accuracy: 0.9633\n",
      "Epoch 14/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.9555 - val_loss: 0.1029 - val_accuracy: 0.9594\n",
      "Epoch 15/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1081 - accuracy: 0.9527 - val_loss: 0.0949 - val_accuracy: 0.9617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1089 - accuracy: 0.9522 - val_loss: 0.0940 - val_accuracy: 0.9602\n",
      "Epoch 17/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1094 - accuracy: 0.9543 - val_loss: 0.0912 - val_accuracy: 0.9672\n",
      "Epoch 18/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9533 - val_loss: 0.0894 - val_accuracy: 0.9719\n",
      "Epoch 19/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1111 - accuracy: 0.9554 - val_loss: 0.0904 - val_accuracy: 0.9649\n",
      "Epoch 20/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9556 - val_loss: 0.0888 - val_accuracy: 0.9664\n",
      "Epoch 21/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1072 - accuracy: 0.9572 - val_loss: 0.0883 - val_accuracy: 0.9711\n",
      "Epoch 22/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1063 - accuracy: 0.9559 - val_loss: 0.0878 - val_accuracy: 0.9688\n",
      "Epoch 23/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9563 - val_loss: 0.0929 - val_accuracy: 0.9641\n",
      "Epoch 24/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.9578 - val_loss: 0.0965 - val_accuracy: 0.9594\n",
      "Epoch 25/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9574 - val_loss: 0.0951 - val_accuracy: 0.9641\n",
      "Epoch 26/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 0.0884 - val_accuracy: 0.9696\n",
      "Epoch 27/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9588 - val_loss: 0.0905 - val_accuracy: 0.9657\n",
      "Epoch 28/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1050 - accuracy: 0.9558 - val_loss: 0.0907 - val_accuracy: 0.9696\n",
      "Epoch 29/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9578 - val_loss: 0.0861 - val_accuracy: 0.9703\n",
      "Epoch 30/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9599 - val_loss: 0.0892 - val_accuracy: 0.9657\n",
      "Epoch 31/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9585 - val_loss: 0.0968 - val_accuracy: 0.9672\n",
      "Epoch 32/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9606 - val_loss: 0.0872 - val_accuracy: 0.9672\n",
      "Epoch 33/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9588 - val_loss: 0.0933 - val_accuracy: 0.9633\n",
      "Epoch 34/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9592 - val_loss: 0.0900 - val_accuracy: 0.9625\n",
      "Epoch 35/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9587 - val_loss: 0.0840 - val_accuracy: 0.9696\n",
      "Epoch 36/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9600 - val_loss: 0.0802 - val_accuracy: 0.9711\n",
      "Epoch 37/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9588 - val_loss: 0.0886 - val_accuracy: 0.9672\n",
      "Epoch 38/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9587 - val_loss: 0.0853 - val_accuracy: 0.9649\n",
      "Epoch 39/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9628 - val_loss: 0.0885 - val_accuracy: 0.9711\n",
      "Epoch 40/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9595 - val_loss: 0.0913 - val_accuracy: 0.9633\n",
      "Epoch 41/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9599 - val_loss: 0.1012 - val_accuracy: 0.9633\n",
      "Epoch 42/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9631 - val_loss: 0.0878 - val_accuracy: 0.9641\n",
      "Epoch 43/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9635 - val_loss: 0.0896 - val_accuracy: 0.9672\n",
      "Epoch 44/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9632 - val_loss: 0.0925 - val_accuracy: 0.9696\n",
      "Epoch 45/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9639 - val_loss: 0.0883 - val_accuracy: 0.9641\n",
      "Epoch 46/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9625 - val_loss: 0.0813 - val_accuracy: 0.9735\n",
      "Epoch 47/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9625 - val_loss: 0.0905 - val_accuracy: 0.9696\n",
      "Epoch 48/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9620 - val_loss: 0.0857 - val_accuracy: 0.9696\n",
      "Epoch 49/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9649 - val_loss: 0.0816 - val_accuracy: 0.9703\n",
      "Epoch 50/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9629 - val_loss: 0.0837 - val_accuracy: 0.9711\n",
      "Epoch 51/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9647 - val_loss: 0.0964 - val_accuracy: 0.9680\n",
      "Epoch 52/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9614 - val_loss: 0.0815 - val_accuracy: 0.9735\n",
      "Epoch 53/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9621 - val_loss: 0.0851 - val_accuracy: 0.9696\n",
      "Epoch 54/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9632 - val_loss: 0.0862 - val_accuracy: 0.9703\n",
      "Epoch 55/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9617 - val_loss: 0.0839 - val_accuracy: 0.9727\n",
      "Epoch 56/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9613 - val_loss: 0.0966 - val_accuracy: 0.9633\n",
      "Epoch 57/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9607 - val_loss: 0.0992 - val_accuracy: 0.9657\n",
      "Epoch 58/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9617 - val_loss: 0.0895 - val_accuracy: 0.9664\n",
      "Epoch 59/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9625 - val_loss: 0.0874 - val_accuracy: 0.9688\n",
      "Epoch 60/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9647 - val_loss: 0.0957 - val_accuracy: 0.9649\n",
      "Epoch 61/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9617 - val_loss: 0.0876 - val_accuracy: 0.9696\n",
      "Epoch 62/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9638 - val_loss: 0.0901 - val_accuracy: 0.9711\n",
      "Epoch 63/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9603 - val_loss: 0.0828 - val_accuracy: 0.9727\n",
      "Epoch 64/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9620 - val_loss: 0.0802 - val_accuracy: 0.9727\n",
      "Epoch 65/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9662 - val_loss: 0.0816 - val_accuracy: 0.9719\n",
      "Epoch 66/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9651 - val_loss: 0.0847 - val_accuracy: 0.9680\n",
      "Epoch 67/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9643 - val_loss: 0.0822 - val_accuracy: 0.9711\n",
      "Epoch 68/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9657 - val_loss: 0.0870 - val_accuracy: 0.9711\n",
      "Epoch 69/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9651 - val_loss: 0.0876 - val_accuracy: 0.9703\n",
      "Epoch 70/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9649 - val_loss: 0.0857 - val_accuracy: 0.9711\n",
      "Epoch 71/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0826 - accuracy: 0.9665 - val_loss: 0.0855 - val_accuracy: 0.9703\n",
      "Epoch 72/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9660 - val_loss: 0.0844 - val_accuracy: 0.9696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.9662 - val_loss: 0.0892 - val_accuracy: 0.9688\n",
      "Epoch 74/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9656 - val_loss: 0.0958 - val_accuracy: 0.9664\n",
      "Epoch 75/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9661 - val_loss: 0.0808 - val_accuracy: 0.9672\n",
      "Epoch 76/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9679 - val_loss: 0.0943 - val_accuracy: 0.9680\n",
      "Epoch 77/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9650 - val_loss: 0.0795 - val_accuracy: 0.9719\n",
      "Epoch 78/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9668 - val_loss: 0.0814 - val_accuracy: 0.9742\n",
      "Epoch 79/150\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9645 - val_loss: 0.0830 - val_accuracy: 0.9711\n",
      "Epoch 80/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9649 - val_loss: 0.0823 - val_accuracy: 0.9680\n",
      "Epoch 81/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9664 - val_loss: 0.0825 - val_accuracy: 0.9696\n",
      "Epoch 82/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9639 - val_loss: 0.0848 - val_accuracy: 0.9672\n",
      "Epoch 83/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9657 - val_loss: 0.0877 - val_accuracy: 0.9680\n",
      "Epoch 84/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9647 - val_loss: 0.0812 - val_accuracy: 0.9680\n",
      "Epoch 85/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9657 - val_loss: 0.0804 - val_accuracy: 0.9711\n",
      "Epoch 86/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9646 - val_loss: 0.0903 - val_accuracy: 0.9696\n",
      "Epoch 87/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0846 - accuracy: 0.9665 - val_loss: 0.0905 - val_accuracy: 0.9696\n",
      "Epoch 88/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9668 - val_loss: 0.0863 - val_accuracy: 0.9742\n",
      "Epoch 89/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9674 - val_loss: 0.0839 - val_accuracy: 0.9727\n",
      "Epoch 90/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9687 - val_loss: 0.0817 - val_accuracy: 0.9735\n",
      "Epoch 91/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9674 - val_loss: 0.0939 - val_accuracy: 0.9680\n",
      "Epoch 92/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9668 - val_loss: 0.0937 - val_accuracy: 0.9672\n",
      "Epoch 93/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9696\n",
      "Epoch 94/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9686 - val_loss: 0.0832 - val_accuracy: 0.9703\n",
      "Epoch 95/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9682 - val_loss: 0.0838 - val_accuracy: 0.9727\n",
      "Epoch 96/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9667 - val_loss: 0.0872 - val_accuracy: 0.9688\n",
      "Epoch 97/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9671 - val_loss: 0.0942 - val_accuracy: 0.9688\n",
      "Epoch 98/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9661 - val_loss: 0.0802 - val_accuracy: 0.9719\n",
      "Epoch 99/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0855 - accuracy: 0.9649 - val_loss: 0.1054 - val_accuracy: 0.9688\n",
      "Epoch 100/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9678 - val_loss: 0.0814 - val_accuracy: 0.9688\n",
      "Epoch 101/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9653 - val_loss: 0.0936 - val_accuracy: 0.9649\n",
      "Epoch 102/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.9667 - val_loss: 0.1006 - val_accuracy: 0.9672\n",
      "Epoch 103/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9662 - val_loss: 0.0886 - val_accuracy: 0.9696\n",
      "Epoch 104/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9636 - val_loss: 0.0837 - val_accuracy: 0.9727\n",
      "Epoch 105/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9639 - val_loss: 0.0882 - val_accuracy: 0.9657\n",
      "Epoch 106/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0758 - accuracy: 0.9731 - val_loss: 0.0981 - val_accuracy: 0.9657\n",
      "Epoch 107/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9645 - val_loss: 0.0924 - val_accuracy: 0.9696\n",
      "Epoch 108/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9679 - val_loss: 0.0867 - val_accuracy: 0.9703\n",
      "Epoch 109/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9685 - val_loss: 0.0906 - val_accuracy: 0.9672\n",
      "Epoch 110/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9686 - val_loss: 0.0864 - val_accuracy: 0.9657\n",
      "Epoch 111/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9693 - val_loss: 0.0872 - val_accuracy: 0.9657\n",
      "Epoch 112/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9676 - val_loss: 0.0801 - val_accuracy: 0.9727\n",
      "Epoch 113/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9712 - val_loss: 0.0986 - val_accuracy: 0.9664\n",
      "Epoch 114/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9678 - val_loss: 0.0929 - val_accuracy: 0.9672\n",
      "Epoch 115/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9698 - val_loss: 0.0856 - val_accuracy: 0.9688\n",
      "Epoch 116/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9680 - val_loss: 0.0858 - val_accuracy: 0.9696\n",
      "Epoch 117/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9701 - val_loss: 0.0910 - val_accuracy: 0.9703\n",
      "Epoch 118/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.9656 - val_loss: 0.0796 - val_accuracy: 0.9696\n",
      "Epoch 119/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9690 - val_loss: 0.0833 - val_accuracy: 0.9703\n",
      "Epoch 120/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9664 - val_loss: 0.0896 - val_accuracy: 0.9680\n",
      "Epoch 121/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9653 - val_loss: 0.0905 - val_accuracy: 0.9696\n",
      "Epoch 122/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9696 - val_loss: 0.0828 - val_accuracy: 0.9688\n",
      "Epoch 123/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9697 - val_loss: 0.0817 - val_accuracy: 0.9696\n",
      "Epoch 124/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9672 - val_loss: 0.0891 - val_accuracy: 0.9688\n",
      "Epoch 125/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9685 - val_loss: 0.0844 - val_accuracy: 0.9711\n",
      "Epoch 126/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9669 - val_loss: 0.0938 - val_accuracy: 0.9703\n",
      "Epoch 127/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9685 - val_loss: 0.0831 - val_accuracy: 0.9703\n",
      "Epoch 128/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9672 - val_loss: 0.0849 - val_accuracy: 0.9711\n",
      "Epoch 129/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.9676 - val_loss: 0.0972 - val_accuracy: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.9694 - val_loss: 0.0972 - val_accuracy: 0.9641\n",
      "Epoch 131/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9709 - val_loss: 0.0915 - val_accuracy: 0.9641\n",
      "Epoch 132/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0776 - accuracy: 0.9685 - val_loss: 0.0911 - val_accuracy: 0.9672\n",
      "Epoch 133/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9694 - val_loss: 0.0818 - val_accuracy: 0.9664\n",
      "Epoch 134/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9720 - val_loss: 0.0887 - val_accuracy: 0.9703\n",
      "Epoch 135/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9696 - val_loss: 0.0862 - val_accuracy: 0.9672\n",
      "Epoch 136/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9687 - val_loss: 0.0801 - val_accuracy: 0.9696\n",
      "Epoch 137/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0741 - accuracy: 0.9701 - val_loss: 0.0968 - val_accuracy: 0.9703\n",
      "Epoch 138/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9712 - val_loss: 0.0909 - val_accuracy: 0.9719\n",
      "Epoch 139/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0797 - accuracy: 0.9660 - val_loss: 0.0910 - val_accuracy: 0.9688\n",
      "Epoch 140/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.9704 - val_loss: 0.1005 - val_accuracy: 0.9672\n",
      "Epoch 141/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9679 - val_loss: 0.0966 - val_accuracy: 0.9672\n",
      "Epoch 142/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9698 - val_loss: 0.0811 - val_accuracy: 0.9696\n",
      "Epoch 143/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9671 - val_loss: 0.0954 - val_accuracy: 0.9657\n",
      "Epoch 144/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 0.0888 - val_accuracy: 0.9672\n",
      "Epoch 145/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.0862 - val_accuracy: 0.9664\n",
      "Epoch 146/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0758 - accuracy: 0.9675 - val_loss: 0.0879 - val_accuracy: 0.9719\n",
      "Epoch 147/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9672 - val_loss: 0.0892 - val_accuracy: 0.9688\n",
      "Epoch 148/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9707 - val_loss: 0.0869 - val_accuracy: 0.9703\n",
      "Epoch 149/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9722 - val_loss: 0.0915 - val_accuracy: 0.9696\n",
      "Epoch 150/150\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.0744 - accuracy: 0.9711 - val_loss: 0.0937 - val_accuracy: 0.9664\n"
     ]
    }
   ],
   "source": [
    "ms = []\n",
    "hs = []\n",
    "for f in [16,32,64]:\n",
    "    #for d in [0.15,0.2,0.25,0.3]:\n",
    "    #    if (f == 32 and d == 0.2) or (f==64 and d==0.15) or (f==96 and d!=0.2):\n",
    "    model = NN_Model(units=f)\n",
    "    model.summary()\n",
    "    ms.append(model)\n",
    "    history = model.fit(X_train, y_train, epochs=150, \n",
    "                    validation_data=(X_val, y_val))\n",
    "    #loc = \"../models/NN_test_\"+str(f)+\".h5\"\n",
    "    #model.save(loc)\n",
    "    hs.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59a9ae78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 0s - loss: 0.0890 - accuracy: 0.9694 - 49ms/epoch - 2ms/step\n",
      "Test Loss: 0.08900036662817001\n",
      "Test Accuracy: 0.9694415330886841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9708    0.9643    0.9675       448\n",
      "           1     0.9683    0.9741    0.9711       501\n",
      "\n",
      "    accuracy                         0.9694       949\n",
      "   macro avg     0.9695    0.9692    0.9693       949\n",
      "weighted avg     0.9694    0.9694    0.9694       949\n",
      "\n",
      "30/30 - 0s - loss: 0.0961 - accuracy: 0.9694 - 48ms/epoch - 2ms/step\n",
      "Test Loss: 0.09608025848865509\n",
      "Test Accuracy: 0.9694415330886841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9663    0.9685    0.9674       444\n",
      "           1     0.9722    0.9703    0.9713       505\n",
      "\n",
      "    accuracy                         0.9694       949\n",
      "   macro avg     0.9693    0.9694    0.9693       949\n",
      "weighted avg     0.9694    0.9694    0.9694       949\n",
      "\n",
      "30/30 - 0s - loss: 0.0879 - accuracy: 0.9694 - 56ms/epoch - 2ms/step\n",
      "Test Loss: 0.08790816366672516\n",
      "Test Accuracy: 0.9694415330886841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9663    0.9685    0.9674       444\n",
      "           1     0.9722    0.9703    0.9713       505\n",
      "\n",
      "    accuracy                         0.9694       949\n",
      "   macro avg     0.9693    0.9694    0.9693       949\n",
      "weighted avg     0.9694    0.9694    0.9694       949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in ms:\n",
    "    test_loss, test_acc = m.evaluate(X_test,  y_test, verbose=2)\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "    y_pred = m.predict(X_test)\n",
    "    a = []\n",
    "    for x in y_pred:\n",
    "        a.append(1 if x[0] > 0.5 else 0)\n",
    "    y_pred = pd.Series(a)\n",
    "    plt.matshow(confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "    plt.ylabel(\"Predicted Category\", fontsize=14)\n",
    "    plt.title(\"Category\", fontsize=14)\n",
    "    plt.show()\n",
    "    print(classification_report(y_pred,y_test,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1125818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(hs)):\n",
    "    plt.plot(hs[i].history['accuracy'], label='accuracy')\n",
    "    plt.plot(hs[i].history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
