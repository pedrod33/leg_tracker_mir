{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7b81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffe36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.read_csv('../feature_data/features.csv')\n",
    "allData.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "allData = allData.dropna()\n",
    "X = allData.drop([\"label\"],axis=1)\n",
    "X = X.drop([\"radius\"],axis=1)\n",
    "cols = X.keys()\n",
    "\n",
    "#normalize data\n",
    "X = preprocessing.normalize(X, norm='max')\n",
    "\n",
    "#labels\n",
    "y = allData[\"label\"]\n",
    "\n",
    "#features\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "X['label'] = y\n",
    "\n",
    "\n",
    "X = pd.DataFrame(X, columns = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e958f63c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_points</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_median_dev</th>\n",
       "      <th>width</th>\n",
       "      <th>linearity</th>\n",
       "      <th>circularity</th>\n",
       "      <th>boundary_length</th>\n",
       "      <th>boundary_regularity</th>\n",
       "      <th>mean_curvature</th>\n",
       "      <th>ang_diff</th>\n",
       "      <th>iav</th>\n",
       "      <th>std_iav</th>\n",
       "      <th>distance</th>\n",
       "      <th>dist_num_points</th>\n",
       "      <th>occluded_right</th>\n",
       "      <th>occluded_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9396.000000</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9.396000e+03</td>\n",
       "      <td>9396.000000</td>\n",
       "      <td>9396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.592945e-01</td>\n",
       "      <td>6.469054e-03</td>\n",
       "      <td>5.388365e-03</td>\n",
       "      <td>1.869667e-02</td>\n",
       "      <td>0.212086</td>\n",
       "      <td>4.715495e-03</td>\n",
       "      <td>2.203596e-02</td>\n",
       "      <td>1.114649e-03</td>\n",
       "      <td>6.175379e-01</td>\n",
       "      <td>1.085435e-01</td>\n",
       "      <td>1.252896e-01</td>\n",
       "      <td>8.838433e-02</td>\n",
       "      <td>1.888061e-01</td>\n",
       "      <td>3.313430e-02</td>\n",
       "      <td>0.041433</td>\n",
       "      <td>0.036861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.947262e-01</td>\n",
       "      <td>5.389933e-03</td>\n",
       "      <td>4.414308e-03</td>\n",
       "      <td>1.593319e-02</td>\n",
       "      <td>0.343588</td>\n",
       "      <td>1.037735e-02</td>\n",
       "      <td>1.710205e-02</td>\n",
       "      <td>1.707077e-03</td>\n",
       "      <td>4.030051e-01</td>\n",
       "      <td>8.850316e-02</td>\n",
       "      <td>1.010140e-01</td>\n",
       "      <td>1.059230e-01</td>\n",
       "      <td>2.651925e-01</td>\n",
       "      <td>6.744615e-02</td>\n",
       "      <td>0.051378</td>\n",
       "      <td>0.049779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.593130e-12</td>\n",
       "      <td>9.689593e-14</td>\n",
       "      <td>8.191696e-14</td>\n",
       "      <td>3.366186e-13</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.989823e-16</td>\n",
       "      <td>3.450850e-13</td>\n",
       "      <td>1.038421e-15</td>\n",
       "      <td>3.767210e-13</td>\n",
       "      <td>2.347074e-13</td>\n",
       "      <td>2.275342e-13</td>\n",
       "      <td>3.540904e-14</td>\n",
       "      <td>3.185288e-13</td>\n",
       "      <td>3.185288e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.818526e-01</td>\n",
       "      <td>1.964611e-03</td>\n",
       "      <td>1.628739e-03</td>\n",
       "      <td>5.193382e-03</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>1.577377e-05</td>\n",
       "      <td>6.820499e-03</td>\n",
       "      <td>1.308422e-04</td>\n",
       "      <td>1.983662e-01</td>\n",
       "      <td>3.803375e-02</td>\n",
       "      <td>4.086856e-02</td>\n",
       "      <td>7.660437e-03</td>\n",
       "      <td>2.580247e-02</td>\n",
       "      <td>3.363338e-04</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.995796e-01</td>\n",
       "      <td>5.012774e-03</td>\n",
       "      <td>4.451575e-03</td>\n",
       "      <td>1.344239e-02</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>1.213275e-04</td>\n",
       "      <td>1.954216e-02</td>\n",
       "      <td>3.336329e-04</td>\n",
       "      <td>8.379153e-01</td>\n",
       "      <td>7.951023e-02</td>\n",
       "      <td>9.744967e-02</td>\n",
       "      <td>4.729005e-02</td>\n",
       "      <td>6.083608e-02</td>\n",
       "      <td>4.715807e-03</td>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.018704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.546740e-03</td>\n",
       "      <td>6.921655e-03</td>\n",
       "      <td>2.601469e-02</td>\n",
       "      <td>0.305077</td>\n",
       "      <td>2.446431e-03</td>\n",
       "      <td>2.833060e-02</td>\n",
       "      <td>1.351564e-03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.566307e-01</td>\n",
       "      <td>1.849632e-01</td>\n",
       "      <td>1.263992e-01</td>\n",
       "      <td>2.439817e-01</td>\n",
       "      <td>2.753039e-02</td>\n",
       "      <td>0.057476</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.761725e-02</td>\n",
       "      <td>2.864450e-02</td>\n",
       "      <td>9.636622e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.029896e-01</td>\n",
       "      <td>1.076028e-01</td>\n",
       "      <td>2.576283e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.486400e-01</td>\n",
       "      <td>6.176940e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.333343e-01</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_points           std  avg_median_dev         width    linearity  \\\n",
       "count  9.396000e+03  9.396000e+03    9.396000e+03  9.396000e+03  9396.000000   \n",
       "mean   6.592945e-01  6.469054e-03    5.388365e-03  1.869667e-02     0.212086   \n",
       "std    2.947262e-01  5.389933e-03    4.414308e-03  1.593319e-02     0.343588   \n",
       "min    7.593130e-12  9.689593e-14    8.191696e-14  3.366186e-13     0.000002   \n",
       "25%    3.818526e-01  1.964611e-03    1.628739e-03  5.193382e-03     0.000661   \n",
       "50%    5.995796e-01  5.012774e-03    4.451575e-03  1.344239e-02     0.012490   \n",
       "75%    1.000000e+00  8.546740e-03    6.921655e-03  2.601469e-02     0.305077   \n",
       "max    1.000000e+00  3.761725e-02    2.864450e-02  9.636622e-02     1.000000   \n",
       "\n",
       "        circularity  boundary_length  boundary_regularity  mean_curvature  \\\n",
       "count  9.396000e+03     9.396000e+03         9.396000e+03    9.396000e+03   \n",
       "mean   4.715495e-03     2.203596e-02         1.114649e-03    6.175379e-01   \n",
       "std    1.037735e-02     1.710205e-02         1.707077e-03    4.030051e-01   \n",
       "min    2.989823e-16     3.450850e-13         1.038421e-15    3.767210e-13   \n",
       "25%    1.577377e-05     6.820499e-03         1.308422e-04    1.983662e-01   \n",
       "50%    1.213275e-04     1.954216e-02         3.336329e-04    8.379153e-01   \n",
       "75%    2.446431e-03     2.833060e-02         1.351564e-03    1.000000e+00   \n",
       "max    2.029896e-01     1.076028e-01         2.576283e-02    1.000000e+00   \n",
       "\n",
       "           ang_diff           iav       std_iav      distance  \\\n",
       "count  9.396000e+03  9.396000e+03  9.396000e+03  9.396000e+03   \n",
       "mean   1.085435e-01  1.252896e-01  8.838433e-02  1.888061e-01   \n",
       "std    8.850316e-02  1.010140e-01  1.059230e-01  2.651925e-01   \n",
       "min    2.347074e-13  2.275342e-13  3.540904e-14  3.185288e-13   \n",
       "25%    3.803375e-02  4.086856e-02  7.660437e-03  2.580247e-02   \n",
       "50%    7.951023e-02  9.744967e-02  4.729005e-02  6.083608e-02   \n",
       "75%    1.566307e-01  1.849632e-01  1.263992e-01  2.439817e-01   \n",
       "max    4.486400e-01  6.176940e-01  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       dist_num_points  occluded_right  occluded_left  \n",
       "count     9.396000e+03     9396.000000    9396.000000  \n",
       "mean      3.313430e-02        0.041433       0.036861  \n",
       "std       6.744615e-02        0.051378       0.049779  \n",
       "min       3.185288e-15        0.000000       0.000000  \n",
       "25%       3.363338e-04        0.003488       0.000000  \n",
       "50%       4.715807e-03        0.021248       0.018704  \n",
       "75%       2.753039e-02        0.057476       0.052632  \n",
       "max       3.333343e-01        0.333333       0.333333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253c70ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "y_train.value_counts().plot.bar()\n",
    "\n",
    "\n",
    "#oversample the minority\n",
    "ros = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addcb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(filters1 = 32, filters2=64, kernel_size=3,strides=1, pool_size=4, optimizer = 'adam'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=filters1, kernel_size=kernel_size, strides=strides, activation='relu',input_shape=(16,1)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=pool_size,strides=strides))\n",
    "    model.add(layers.Conv1D(filters=filters2, kernel_size=kernel_size, strides=strides, activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a4b65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 11, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 64)             16448     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                16416     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,250\n",
      "Trainable params: 33,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 2s 5ms/step - loss: 0.4369 - accuracy: 0.8121 - val_loss: 0.4201 - val_accuracy: 0.8574\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8608 - val_loss: 0.2942 - val_accuracy: 0.8850\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2917 - accuracy: 0.8818 - val_loss: 0.3049 - val_accuracy: 0.9069\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2605 - accuracy: 0.8958 - val_loss: 0.2403 - val_accuracy: 0.9037\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.8985 - val_loss: 0.2202 - val_accuracy: 0.9085\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2511 - accuracy: 0.8992 - val_loss: 0.2296 - val_accuracy: 0.9101\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.9052 - val_loss: 0.2257 - val_accuracy: 0.9047\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2279 - accuracy: 0.9069 - val_loss: 0.2362 - val_accuracy: 0.9127\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2234 - accuracy: 0.9122 - val_loss: 0.1976 - val_accuracy: 0.9143\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2182 - accuracy: 0.9119 - val_loss: 0.1922 - val_accuracy: 0.9234\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2116 - accuracy: 0.9137 - val_loss: 0.1867 - val_accuracy: 0.9202\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2066 - accuracy: 0.9142 - val_loss: 0.2886 - val_accuracy: 0.8893\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.2034 - accuracy: 0.9168 - val_loss: 0.2137 - val_accuracy: 0.9191\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9168 - val_loss: 0.1843 - val_accuracy: 0.9207\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1947 - accuracy: 0.9209 - val_loss: 0.1768 - val_accuracy: 0.9335\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9232 - val_loss: 0.1747 - val_accuracy: 0.9271\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9217 - val_loss: 0.2158 - val_accuracy: 0.9047\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9209 - val_loss: 0.1869 - val_accuracy: 0.9212\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9246 - val_loss: 0.1821 - val_accuracy: 0.9282\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9288 - val_loss: 0.1916 - val_accuracy: 0.9196\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1794 - accuracy: 0.9270 - val_loss: 0.1752 - val_accuracy: 0.9292\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9277 - val_loss: 0.1752 - val_accuracy: 0.9228\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1798 - accuracy: 0.9290 - val_loss: 0.1806 - val_accuracy: 0.9303\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1777 - accuracy: 0.9297 - val_loss: 0.1893 - val_accuracy: 0.9186\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9286 - val_loss: 0.1749 - val_accuracy: 0.9207\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9312 - val_loss: 0.1635 - val_accuracy: 0.9372\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9297 - val_loss: 0.1860 - val_accuracy: 0.9207\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1688 - accuracy: 0.9319 - val_loss: 0.1687 - val_accuracy: 0.9324\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9346 - val_loss: 0.1783 - val_accuracy: 0.9324\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9324 - val_loss: 0.1732 - val_accuracy: 0.9218\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9362 - val_loss: 0.1634 - val_accuracy: 0.9297\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1600 - accuracy: 0.9362 - val_loss: 0.1476 - val_accuracy: 0.9457\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1559 - accuracy: 0.9365 - val_loss: 0.1470 - val_accuracy: 0.9431\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9355 - val_loss: 0.1480 - val_accuracy: 0.9462\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1546 - accuracy: 0.9373 - val_loss: 0.1677 - val_accuracy: 0.9324\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9401 - val_loss: 0.1507 - val_accuracy: 0.9484\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9398 - val_loss: 0.1451 - val_accuracy: 0.9436\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9387 - val_loss: 0.1403 - val_accuracy: 0.9473\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9392 - val_loss: 0.1500 - val_accuracy: 0.9436\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9404 - val_loss: 0.1362 - val_accuracy: 0.9500\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9432 - val_loss: 0.1482 - val_accuracy: 0.9447\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9427 - val_loss: 0.1391 - val_accuracy: 0.9494\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9409 - val_loss: 0.1386 - val_accuracy: 0.9441\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9441 - val_loss: 0.1369 - val_accuracy: 0.9484\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9417 - val_loss: 0.1567 - val_accuracy: 0.9516\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9459 - val_loss: 0.1527 - val_accuracy: 0.9356\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9460 - val_loss: 0.1431 - val_accuracy: 0.9473\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1405 - accuracy: 0.9470 - val_loss: 0.1478 - val_accuracy: 0.9447\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9470 - val_loss: 0.1341 - val_accuracy: 0.9510\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9460 - val_loss: 0.1354 - val_accuracy: 0.9494\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9455 - val_loss: 0.1424 - val_accuracy: 0.9457\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9459 - val_loss: 0.1477 - val_accuracy: 0.9415\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9489 - val_loss: 0.1362 - val_accuracy: 0.9478\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1335 - accuracy: 0.9467 - val_loss: 0.1454 - val_accuracy: 0.9425\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9470 - val_loss: 0.1329 - val_accuracy: 0.9494\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.1395 - val_accuracy: 0.9457\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9495 - val_loss: 0.1355 - val_accuracy: 0.9473\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9498 - val_loss: 0.1525 - val_accuracy: 0.9420\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1298 - accuracy: 0.9526 - val_loss: 0.1289 - val_accuracy: 0.9473\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9489 - val_loss: 0.1296 - val_accuracy: 0.9553\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 0.1317 - val_accuracy: 0.9500\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9530 - val_loss: 0.1440 - val_accuracy: 0.9404\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9528 - val_loss: 0.1243 - val_accuracy: 0.9510\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9513 - val_loss: 0.1336 - val_accuracy: 0.9516\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9528 - val_loss: 0.1419 - val_accuracy: 0.9478\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.9525 - val_loss: 0.1208 - val_accuracy: 0.9542\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9535 - val_loss: 0.1303 - val_accuracy: 0.9548\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.1473 - val_accuracy: 0.9462\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9524 - val_loss: 0.1465 - val_accuracy: 0.9447\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9524 - val_loss: 0.1251 - val_accuracy: 0.9553\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1200 - accuracy: 0.9551 - val_loss: 0.1324 - val_accuracy: 0.9553\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9587 - val_loss: 0.1501 - val_accuracy: 0.9447\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9575 - val_loss: 0.1288 - val_accuracy: 0.9505\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9567 - val_loss: 0.1448 - val_accuracy: 0.9516\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9579 - val_loss: 0.1302 - val_accuracy: 0.9521\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9530 - val_loss: 0.1299 - val_accuracy: 0.9526\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9557 - val_loss: 0.1346 - val_accuracy: 0.9558\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9532 - val_loss: 0.1241 - val_accuracy: 0.9596\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1115 - accuracy: 0.9575 - val_loss: 0.1352 - val_accuracy: 0.9526\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9595 - val_loss: 0.1559 - val_accuracy: 0.9532\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1119 - accuracy: 0.9579 - val_loss: 0.1184 - val_accuracy: 0.9569\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1085 - accuracy: 0.9589 - val_loss: 0.1392 - val_accuracy: 0.9548\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9597 - val_loss: 0.1218 - val_accuracy: 0.9585\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9553 - val_loss: 0.1422 - val_accuracy: 0.9526\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9566 - val_loss: 0.1551 - val_accuracy: 0.9505\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9613 - val_loss: 0.1209 - val_accuracy: 0.9622\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1051 - accuracy: 0.9620 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9598 - val_loss: 0.1267 - val_accuracy: 0.9574\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9620 - val_loss: 0.1291 - val_accuracy: 0.9558\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9630 - val_loss: 0.1406 - val_accuracy: 0.9478\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 0.1321 - val_accuracy: 0.9590\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1005 - accuracy: 0.9624 - val_loss: 0.1219 - val_accuracy: 0.9606\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9637 - val_loss: 0.1166 - val_accuracy: 0.9601\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1019 - accuracy: 0.9638 - val_loss: 0.1217 - val_accuracy: 0.9569\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9618 - val_loss: 0.1476 - val_accuracy: 0.9505\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9648 - val_loss: 0.1373 - val_accuracy: 0.9580\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9636 - val_loss: 0.1322 - val_accuracy: 0.9558\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9609 - val_loss: 0.1333 - val_accuracy: 0.9521\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9641 - val_loss: 0.1197 - val_accuracy: 0.9590\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9632 - val_loss: 0.1225 - val_accuracy: 0.9611\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9648 - val_loss: 0.1247 - val_accuracy: 0.9596\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9651 - val_loss: 0.1324 - val_accuracy: 0.9580\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.1305 - val_accuracy: 0.9574\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9672 - val_loss: 0.1467 - val_accuracy: 0.9542\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9640 - val_loss: 0.1436 - val_accuracy: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9655 - val_loss: 0.1337 - val_accuracy: 0.9558\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9653 - val_loss: 0.1295 - val_accuracy: 0.9569\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9669 - val_loss: 0.1274 - val_accuracy: 0.9574\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9653 - val_loss: 0.1351 - val_accuracy: 0.9569\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9651 - val_loss: 0.1278 - val_accuracy: 0.9590\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9679 - val_loss: 0.1410 - val_accuracy: 0.9574\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0876 - accuracy: 0.9674 - val_loss: 0.1412 - val_accuracy: 0.9574\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9652 - val_loss: 0.1309 - val_accuracy: 0.9617\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9668 - val_loss: 0.1550 - val_accuracy: 0.9505\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 2s 10ms/step - loss: 0.0877 - accuracy: 0.9680 - val_loss: 0.1365 - val_accuracy: 0.9537\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0846 - accuracy: 0.9678 - val_loss: 0.1417 - val_accuracy: 0.9548\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0865 - accuracy: 0.9680 - val_loss: 0.1371 - val_accuracy: 0.9558\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.1274 - val_accuracy: 0.9627\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9688 - val_loss: 0.1328 - val_accuracy: 0.9622\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9683 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9692 - val_loss: 0.1397 - val_accuracy: 0.9564\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9703 - val_loss: 0.1492 - val_accuracy: 0.9521\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9688 - val_loss: 0.1417 - val_accuracy: 0.9590\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: 0.1390 - val_accuracy: 0.9580\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0809 - accuracy: 0.9680 - val_loss: 0.1367 - val_accuracy: 0.9569\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9705 - val_loss: 0.1488 - val_accuracy: 0.9564\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9699 - val_loss: 0.1343 - val_accuracy: 0.9601\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9719 - val_loss: 0.1380 - val_accuracy: 0.9569\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9676 - val_loss: 0.1544 - val_accuracy: 0.9574\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.1483 - val_accuracy: 0.9553\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9723 - val_loss: 0.1327 - val_accuracy: 0.9617\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9711 - val_loss: 0.1442 - val_accuracy: 0.9596\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9713 - val_loss: 0.1351 - val_accuracy: 0.9601\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9730 - val_loss: 0.1294 - val_accuracy: 0.9606\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9707 - val_loss: 0.1424 - val_accuracy: 0.9569\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0770 - accuracy: 0.9714 - val_loss: 0.1423 - val_accuracy: 0.9585\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9744 - val_loss: 0.1410 - val_accuracy: 0.9564\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0746 - accuracy: 0.9727 - val_loss: 0.1339 - val_accuracy: 0.9633\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9727 - val_loss: 0.1423 - val_accuracy: 0.9601\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.1367 - val_accuracy: 0.9601\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9717 - val_loss: 0.1477 - val_accuracy: 0.9596\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.1315 - val_accuracy: 0.9611\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9727 - val_loss: 0.1565 - val_accuracy: 0.9569\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9699 - val_loss: 0.1498 - val_accuracy: 0.9569\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 0.1656 - val_accuracy: 0.9580\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9733 - val_loss: 0.1445 - val_accuracy: 0.9590\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9723 - val_loss: 0.1473 - val_accuracy: 0.9574\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9734 - val_loss: 0.1364 - val_accuracy: 0.9590\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9736 - val_loss: 0.1632 - val_accuracy: 0.9484\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9756 - val_loss: 0.1422 - val_accuracy: 0.9627\n",
      "6\n",
      "1\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 9, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 4, 64)             24640     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,378\n",
      "Trainable params: 33,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.4456 - accuracy: 0.8003 - val_loss: 0.4887 - val_accuracy: 0.8121\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8508 - val_loss: 0.3525 - val_accuracy: 0.8536\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3112 - accuracy: 0.8705 - val_loss: 0.2825 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.8776 - val_loss: 0.2747 - val_accuracy: 0.8925\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2746 - accuracy: 0.8837 - val_loss: 0.2928 - val_accuracy: 0.8866\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.2530 - accuracy: 0.8984 - val_loss: 0.2264 - val_accuracy: 0.9095\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.8985 - val_loss: 0.2127 - val_accuracy: 0.9117\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2327 - accuracy: 0.9056 - val_loss: 0.2058 - val_accuracy: 0.9159\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.9145 - val_loss: 0.2288 - val_accuracy: 0.9095\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.2252 - accuracy: 0.9120 - val_loss: 0.1964 - val_accuracy: 0.9148\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9139 - val_loss: 0.2329 - val_accuracy: 0.9021\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2092 - accuracy: 0.9181 - val_loss: 0.2323 - val_accuracy: 0.9047\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9161 - val_loss: 0.1989 - val_accuracy: 0.9196\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2033 - accuracy: 0.9204 - val_loss: 0.1873 - val_accuracy: 0.9212\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9203 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9231 - val_loss: 0.1791 - val_accuracy: 0.9250\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1901 - accuracy: 0.9242 - val_loss: 0.1770 - val_accuracy: 0.9255\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1855 - accuracy: 0.9278 - val_loss: 0.1843 - val_accuracy: 0.9202\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9267 - val_loss: 0.1975 - val_accuracy: 0.9159\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1858 - accuracy: 0.9269 - val_loss: 0.1732 - val_accuracy: 0.9287\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1794 - accuracy: 0.9277 - val_loss: 0.1877 - val_accuracy: 0.9159\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1783 - accuracy: 0.9278 - val_loss: 0.1814 - val_accuracy: 0.9260\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9274 - val_loss: 0.1834 - val_accuracy: 0.9287\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1746 - accuracy: 0.9286 - val_loss: 0.1637 - val_accuracy: 0.9324\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1677 - accuracy: 0.9332 - val_loss: 0.2067 - val_accuracy: 0.9138\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9309 - val_loss: 0.1699 - val_accuracy: 0.9308\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.9320 - val_loss: 0.1565 - val_accuracy: 0.9388\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9351 - val_loss: 0.1708 - val_accuracy: 0.9335\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1714 - accuracy: 0.9315 - val_loss: 0.1702 - val_accuracy: 0.9335\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9373 - val_loss: 0.1670 - val_accuracy: 0.9340\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1634 - accuracy: 0.9331 - val_loss: 0.1667 - val_accuracy: 0.9282\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1598 - accuracy: 0.9363 - val_loss: 0.1555 - val_accuracy: 0.9361\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1583 - accuracy: 0.9397 - val_loss: 0.2137 - val_accuracy: 0.9159\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9363 - val_loss: 0.1641 - val_accuracy: 0.9388\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9365 - val_loss: 0.1573 - val_accuracy: 0.9372\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9373 - val_loss: 0.1596 - val_accuracy: 0.9420\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9383 - val_loss: 0.1484 - val_accuracy: 0.9436\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9421 - val_loss: 0.1447 - val_accuracy: 0.9462\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9390 - val_loss: 0.1885 - val_accuracy: 0.9297\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1570 - accuracy: 0.9354 - val_loss: 0.1719 - val_accuracy: 0.9308\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9382 - val_loss: 0.1535 - val_accuracy: 0.9452\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9401 - val_loss: 0.1449 - val_accuracy: 0.9489\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9410 - val_loss: 0.1631 - val_accuracy: 0.9367\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1471 - accuracy: 0.9406 - val_loss: 0.1556 - val_accuracy: 0.9431\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1454 - accuracy: 0.9394 - val_loss: 0.1456 - val_accuracy: 0.9447\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9428 - val_loss: 0.1591 - val_accuracy: 0.9420\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9420 - val_loss: 0.1424 - val_accuracy: 0.9447\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1405 - accuracy: 0.9436 - val_loss: 0.1469 - val_accuracy: 0.9431\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9456 - val_loss: 0.1579 - val_accuracy: 0.9436\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9437 - val_loss: 0.1621 - val_accuracy: 0.9383\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9455 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9466 - val_loss: 0.1527 - val_accuracy: 0.9388\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9448 - val_loss: 0.1415 - val_accuracy: 0.9425\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9483 - val_loss: 0.1528 - val_accuracy: 0.9447\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9450 - val_loss: 0.1474 - val_accuracy: 0.9399\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9478 - val_loss: 0.1455 - val_accuracy: 0.9500\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9460 - val_loss: 0.1359 - val_accuracy: 0.9468\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9462 - val_loss: 0.1458 - val_accuracy: 0.9452\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.9482 - val_loss: 0.1339 - val_accuracy: 0.9526\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9483 - val_loss: 0.1468 - val_accuracy: 0.9473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1285 - accuracy: 0.9510 - val_loss: 0.1499 - val_accuracy: 0.9425\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9495 - val_loss: 0.1320 - val_accuracy: 0.9510\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1279 - accuracy: 0.9498 - val_loss: 0.1421 - val_accuracy: 0.9489\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9513 - val_loss: 0.1304 - val_accuracy: 0.9500\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9479 - val_loss: 0.1528 - val_accuracy: 0.9452\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1235 - accuracy: 0.9509 - val_loss: 0.1521 - val_accuracy: 0.9478\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9532 - val_loss: 0.1405 - val_accuracy: 0.9510\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9545 - val_loss: 0.1463 - val_accuracy: 0.9436\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9526 - val_loss: 0.1658 - val_accuracy: 0.9468\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9557 - val_loss: 0.1614 - val_accuracy: 0.9441\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1217 - accuracy: 0.9525 - val_loss: 0.1327 - val_accuracy: 0.9478\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9547 - val_loss: 0.1309 - val_accuracy: 0.9553\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1181 - accuracy: 0.9541 - val_loss: 0.1391 - val_accuracy: 0.9468\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.1194 - accuracy: 0.9535 - val_loss: 0.1493 - val_accuracy: 0.9383\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9557 - val_loss: 0.1592 - val_accuracy: 0.9500\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9557 - val_loss: 0.1367 - val_accuracy: 0.9516\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9547 - val_loss: 0.1380 - val_accuracy: 0.9489\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9574 - val_loss: 0.1387 - val_accuracy: 0.9526\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9574 - val_loss: 0.1275 - val_accuracy: 0.9548\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1115 - accuracy: 0.9586 - val_loss: 0.1346 - val_accuracy: 0.9526\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9576 - val_loss: 0.1227 - val_accuracy: 0.9585\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1102 - accuracy: 0.9607 - val_loss: 0.1398 - val_accuracy: 0.9532\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1099 - accuracy: 0.9582 - val_loss: 0.1333 - val_accuracy: 0.9548\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9574 - val_loss: 0.1430 - val_accuracy: 0.9564\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.1794 - val_accuracy: 0.9409\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.1490 - val_accuracy: 0.9489\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9598 - val_loss: 0.1412 - val_accuracy: 0.9521\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9618 - val_loss: 0.1357 - val_accuracy: 0.9532\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1054 - accuracy: 0.9614 - val_loss: 0.1254 - val_accuracy: 0.9580\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9607 - val_loss: 0.1469 - val_accuracy: 0.9553\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9609 - val_loss: 0.1368 - val_accuracy: 0.9553\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9602 - val_loss: 0.1385 - val_accuracy: 0.9521\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9630 - val_loss: 0.1285 - val_accuracy: 0.9569\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9636 - val_loss: 0.1376 - val_accuracy: 0.9569\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9626 - val_loss: 0.1464 - val_accuracy: 0.9441\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9636 - val_loss: 0.1294 - val_accuracy: 0.9553\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9644 - val_loss: 0.1389 - val_accuracy: 0.9553\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9633 - val_loss: 0.1380 - val_accuracy: 0.9542\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.1416 - val_accuracy: 0.9558\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9632 - val_loss: 0.1636 - val_accuracy: 0.9500\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9626 - val_loss: 0.1451 - val_accuracy: 0.9526\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9657 - val_loss: 0.1348 - val_accuracy: 0.9585\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9656 - val_loss: 0.1403 - val_accuracy: 0.9569\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9651 - val_loss: 0.1430 - val_accuracy: 0.9537\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9657 - val_loss: 0.1541 - val_accuracy: 0.9468\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9645 - val_loss: 0.1376 - val_accuracy: 0.9569\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9652 - val_loss: 0.1698 - val_accuracy: 0.9420\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9668 - val_loss: 0.1403 - val_accuracy: 0.9564\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9668 - val_loss: 0.1489 - val_accuracy: 0.9553\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9687 - val_loss: 0.1811 - val_accuracy: 0.9388\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9669 - val_loss: 0.1426 - val_accuracy: 0.9542\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9675 - val_loss: 0.1450 - val_accuracy: 0.9553\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9661 - val_loss: 0.1444 - val_accuracy: 0.9532\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9672 - val_loss: 0.1441 - val_accuracy: 0.9542\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9690 - val_loss: 0.1425 - val_accuracy: 0.9521\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9674 - val_loss: 0.1334 - val_accuracy: 0.9622\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9659 - val_loss: 0.1561 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: 0.1458 - val_accuracy: 0.9569\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9687 - val_loss: 0.1349 - val_accuracy: 0.9596\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9652 - val_loss: 0.1297 - val_accuracy: 0.9611\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9687 - val_loss: 0.1543 - val_accuracy: 0.9510\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.1685 - val_accuracy: 0.9505\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9700 - val_loss: 0.1426 - val_accuracy: 0.9574\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9699 - val_loss: 0.1383 - val_accuracy: 0.9532\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0819 - accuracy: 0.9692 - val_loss: 0.1452 - val_accuracy: 0.9569\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9683 - val_loss: 0.1464 - val_accuracy: 0.9558\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9683 - val_loss: 0.1527 - val_accuracy: 0.9617\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9694 - val_loss: 0.2051 - val_accuracy: 0.9399\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.1405 - val_accuracy: 0.9590\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9719 - val_loss: 0.1603 - val_accuracy: 0.9558\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.9687 - val_loss: 0.1766 - val_accuracy: 0.9558\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9684 - val_loss: 0.1535 - val_accuracy: 0.9564\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9722 - val_loss: 0.1594 - val_accuracy: 0.9521\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9698 - val_loss: 0.1767 - val_accuracy: 0.9473\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9706 - val_loss: 0.1956 - val_accuracy: 0.9404\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0807 - accuracy: 0.9721 - val_loss: 0.1536 - val_accuracy: 0.9558\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9722 - val_loss: 0.1791 - val_accuracy: 0.9494\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9703 - val_loss: 0.1501 - val_accuracy: 0.9611\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9703 - val_loss: 0.1651 - val_accuracy: 0.9548\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9714 - val_loss: 0.1593 - val_accuracy: 0.9564\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9726 - val_loss: 0.1552 - val_accuracy: 0.9558\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9706 - val_loss: 0.1740 - val_accuracy: 0.9521\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9700 - val_loss: 0.1526 - val_accuracy: 0.9558\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9736 - val_loss: 0.1389 - val_accuracy: 0.9590\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.1392 - val_accuracy: 0.9611\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9719 - val_loss: 0.1589 - val_accuracy: 0.9553\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0788 - accuracy: 0.9725 - val_loss: 0.1560 - val_accuracy: 0.9564\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.1722 - val_accuracy: 0.9521\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9715 - val_loss: 0.1674 - val_accuracy: 0.9516\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.1561 - val_accuracy: 0.9617\n",
      "4\n",
      "1\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 7, 64)             16448     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                14368     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,202\n",
      "Trainable params: 31,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.4529 - accuracy: 0.7906 - val_loss: 0.3722 - val_accuracy: 0.8632\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8505 - val_loss: 0.3138 - val_accuracy: 0.8781\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8636 - val_loss: 0.2894 - val_accuracy: 0.8909\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.8768 - val_loss: 0.3226 - val_accuracy: 0.8866\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.8803 - val_loss: 0.2524 - val_accuracy: 0.8952\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.8863 - val_loss: 0.2394 - val_accuracy: 0.8946\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2637 - accuracy: 0.8927 - val_loss: 0.2566 - val_accuracy: 0.9015\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.8987 - val_loss: 0.2227 - val_accuracy: 0.9031\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9018 - val_loss: 0.2461 - val_accuracy: 0.8952\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.9046 - val_loss: 0.2322 - val_accuracy: 0.8968\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.9065 - val_loss: 0.2876 - val_accuracy: 0.8952\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2319 - accuracy: 0.9096 - val_loss: 0.2119 - val_accuracy: 0.9122\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2298 - accuracy: 0.9104 - val_loss: 0.2751 - val_accuracy: 0.8893\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9151 - val_loss: 0.1995 - val_accuracy: 0.9170\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2110 - accuracy: 0.9173 - val_loss: 0.3325 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2128 - accuracy: 0.9159 - val_loss: 0.1877 - val_accuracy: 0.9292\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2090 - accuracy: 0.9178 - val_loss: 0.1826 - val_accuracy: 0.9202\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2100 - accuracy: 0.9168 - val_loss: 0.2131 - val_accuracy: 0.9170\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1989 - accuracy: 0.9193 - val_loss: 0.1754 - val_accuracy: 0.9276\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1982 - accuracy: 0.9226 - val_loss: 0.1853 - val_accuracy: 0.9239\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9235 - val_loss: 0.1703 - val_accuracy: 0.9303\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1891 - accuracy: 0.9244 - val_loss: 0.1751 - val_accuracy: 0.9234\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9244 - val_loss: 0.1688 - val_accuracy: 0.9266\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1862 - accuracy: 0.9222 - val_loss: 0.2318 - val_accuracy: 0.9037\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1825 - accuracy: 0.9258 - val_loss: 0.1830 - val_accuracy: 0.9340\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1781 - accuracy: 0.9266 - val_loss: 0.1778 - val_accuracy: 0.9244\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9289 - val_loss: 0.1796 - val_accuracy: 0.9244\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1787 - accuracy: 0.9286 - val_loss: 0.1662 - val_accuracy: 0.9415\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9307 - val_loss: 0.1631 - val_accuracy: 0.9266\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9329 - val_loss: 0.1523 - val_accuracy: 0.9425\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9324 - val_loss: 0.1580 - val_accuracy: 0.9329\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9320 - val_loss: 0.1685 - val_accuracy: 0.9266\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1682 - accuracy: 0.9335 - val_loss: 0.1532 - val_accuracy: 0.9415\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9351 - val_loss: 0.1611 - val_accuracy: 0.9335\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1667 - accuracy: 0.9309 - val_loss: 0.1588 - val_accuracy: 0.9329\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9359 - val_loss: 0.1743 - val_accuracy: 0.9329\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9379 - val_loss: 0.1482 - val_accuracy: 0.9340\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 0.1629 - val_accuracy: 0.9202\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9400 - val_loss: 0.1505 - val_accuracy: 0.9393\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9394 - val_loss: 0.1469 - val_accuracy: 0.9377\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1536 - accuracy: 0.9406 - val_loss: 0.1469 - val_accuracy: 0.9478\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1571 - accuracy: 0.9383 - val_loss: 0.1531 - val_accuracy: 0.9404\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9420 - val_loss: 0.1635 - val_accuracy: 0.9340\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9420 - val_loss: 0.1578 - val_accuracy: 0.9377\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1461 - accuracy: 0.9448 - val_loss: 0.2152 - val_accuracy: 0.9122\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1492 - accuracy: 0.9437 - val_loss: 0.1402 - val_accuracy: 0.9505\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9431 - val_loss: 0.1435 - val_accuracy: 0.9383\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9440 - val_loss: 0.1441 - val_accuracy: 0.9500\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9440 - val_loss: 0.1430 - val_accuracy: 0.9404\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1516 - accuracy: 0.9414 - val_loss: 0.1489 - val_accuracy: 0.9356\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9451 - val_loss: 0.1460 - val_accuracy: 0.9383\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9452 - val_loss: 0.1415 - val_accuracy: 0.9489\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1444 - accuracy: 0.9443 - val_loss: 0.1334 - val_accuracy: 0.9494\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9435 - val_loss: 0.1336 - val_accuracy: 0.9431\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9485 - val_loss: 0.1376 - val_accuracy: 0.9468\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1382 - accuracy: 0.9454 - val_loss: 0.1415 - val_accuracy: 0.9425\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9462 - val_loss: 0.1764 - val_accuracy: 0.9292\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.1575 - val_accuracy: 0.9340\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9494 - val_loss: 0.1433 - val_accuracy: 0.9468\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9470 - val_loss: 0.1339 - val_accuracy: 0.9521\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1343 - accuracy: 0.9490 - val_loss: 0.1323 - val_accuracy: 0.9468\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9501 - val_loss: 0.1351 - val_accuracy: 0.9494\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1329 - accuracy: 0.9504 - val_loss: 0.1276 - val_accuracy: 0.9500\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9481 - val_loss: 0.1324 - val_accuracy: 0.9489\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1393 - accuracy: 0.9481 - val_loss: 0.1255 - val_accuracy: 0.9558\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9497 - val_loss: 0.1312 - val_accuracy: 0.9510\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9498 - val_loss: 0.1347 - val_accuracy: 0.9462\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9512 - val_loss: 0.1408 - val_accuracy: 0.9436\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9521 - val_loss: 0.1435 - val_accuracy: 0.9447\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9533 - val_loss: 0.1384 - val_accuracy: 0.9447\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9529 - val_loss: 0.1309 - val_accuracy: 0.9462\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9530 - val_loss: 0.1374 - val_accuracy: 0.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1267 - accuracy: 0.9540 - val_loss: 0.1506 - val_accuracy: 0.9462\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9528 - val_loss: 0.1358 - val_accuracy: 0.9505\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9543 - val_loss: 0.1372 - val_accuracy: 0.9473\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1235 - accuracy: 0.9545 - val_loss: 0.1333 - val_accuracy: 0.9537\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9525 - val_loss: 0.1621 - val_accuracy: 0.9324\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9537 - val_loss: 0.1287 - val_accuracy: 0.9548\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9516 - val_loss: 0.1268 - val_accuracy: 0.9569\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1191 - accuracy: 0.9551 - val_loss: 0.1272 - val_accuracy: 0.9521\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1198 - accuracy: 0.9557 - val_loss: 0.1238 - val_accuracy: 0.9532\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1198 - accuracy: 0.9568 - val_loss: 0.1394 - val_accuracy: 0.9468\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9544 - val_loss: 0.1302 - val_accuracy: 0.9457\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1152 - accuracy: 0.9578 - val_loss: 0.1424 - val_accuracy: 0.9452\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1165 - accuracy: 0.9579 - val_loss: 0.1303 - val_accuracy: 0.9521\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9570 - val_loss: 0.1217 - val_accuracy: 0.9574\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9580 - val_loss: 0.1333 - val_accuracy: 0.9558\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9595 - val_loss: 0.1228 - val_accuracy: 0.9596\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9560 - val_loss: 0.1182 - val_accuracy: 0.9580\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1141 - accuracy: 0.9576 - val_loss: 0.1246 - val_accuracy: 0.9537\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1105 - accuracy: 0.9598 - val_loss: 0.1338 - val_accuracy: 0.9505\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9552 - val_loss: 0.1361 - val_accuracy: 0.9473\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9589 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1068 - accuracy: 0.9589 - val_loss: 0.1453 - val_accuracy: 0.9431\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9601 - val_loss: 0.1564 - val_accuracy: 0.9415\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9625 - val_loss: 0.1202 - val_accuracy: 0.9596\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1077 - accuracy: 0.9610 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1096 - accuracy: 0.9597 - val_loss: 0.1406 - val_accuracy: 0.9505\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9601 - val_loss: 0.1156 - val_accuracy: 0.9558\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9601 - val_loss: 0.1292 - val_accuracy: 0.9521\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9621 - val_loss: 0.1362 - val_accuracy: 0.9478\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1064 - accuracy: 0.9614 - val_loss: 0.1376 - val_accuracy: 0.9532\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9628 - val_loss: 0.1532 - val_accuracy: 0.9478\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9638 - val_loss: 0.1498 - val_accuracy: 0.9452\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1040 - accuracy: 0.9609 - val_loss: 0.1228 - val_accuracy: 0.9611\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9629 - val_loss: 0.1373 - val_accuracy: 0.9526\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9609 - val_loss: 0.1251 - val_accuracy: 0.9606\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9634 - val_loss: 0.1394 - val_accuracy: 0.9548\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1013 - accuracy: 0.9640 - val_loss: 0.1386 - val_accuracy: 0.9537\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1027 - accuracy: 0.9628 - val_loss: 0.1448 - val_accuracy: 0.9532\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9624 - val_loss: 0.1331 - val_accuracy: 0.9510\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9630 - val_loss: 0.1177 - val_accuracy: 0.9601\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9629 - val_loss: 0.1460 - val_accuracy: 0.9537\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9645 - val_loss: 0.1288 - val_accuracy: 0.9580\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9669 - val_loss: 0.1316 - val_accuracy: 0.9590\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9637 - val_loss: 0.1283 - val_accuracy: 0.9569\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9632 - val_loss: 0.1208 - val_accuracy: 0.9606\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9653 - val_loss: 0.1273 - val_accuracy: 0.9553\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9655 - val_loss: 0.1693 - val_accuracy: 0.9409\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9628 - val_loss: 0.1368 - val_accuracy: 0.9553\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9660 - val_loss: 0.1312 - val_accuracy: 0.9580\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9668 - val_loss: 0.1317 - val_accuracy: 0.9548\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9657 - val_loss: 0.1250 - val_accuracy: 0.9596\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9684 - val_loss: 0.1347 - val_accuracy: 0.9564\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9655 - val_loss: 0.1310 - val_accuracy: 0.9532\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9656 - val_loss: 0.1326 - val_accuracy: 0.9564\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9660 - val_loss: 0.1307 - val_accuracy: 0.9558\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9667 - val_loss: 0.1383 - val_accuracy: 0.9516\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9682 - val_loss: 0.1295 - val_accuracy: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9669 - val_loss: 0.1412 - val_accuracy: 0.9574\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9674 - val_loss: 0.1725 - val_accuracy: 0.9500\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9698 - val_loss: 0.1249 - val_accuracy: 0.9590\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9679 - val_loss: 0.1246 - val_accuracy: 0.9611\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9675 - val_loss: 0.1303 - val_accuracy: 0.9596\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9651 - val_loss: 0.1208 - val_accuracy: 0.9601\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9642 - val_loss: 0.1457 - val_accuracy: 0.9553\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9645 - val_loss: 0.1312 - val_accuracy: 0.9606\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9684 - val_loss: 0.1354 - val_accuracy: 0.9596\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9664 - val_loss: 0.1343 - val_accuracy: 0.9553\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9695 - val_loss: 0.1366 - val_accuracy: 0.9542\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9707 - val_loss: 0.1447 - val_accuracy: 0.9537\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9714 - val_loss: 0.1346 - val_accuracy: 0.9601\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9691 - val_loss: 0.1508 - val_accuracy: 0.9521\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0861 - accuracy: 0.9687 - val_loss: 0.1322 - val_accuracy: 0.9564\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 0.1367 - val_accuracy: 0.9569\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9674 - val_loss: 0.1532 - val_accuracy: 0.9489\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0873 - accuracy: 0.9683 - val_loss: 0.1420 - val_accuracy: 0.9542\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9680 - val_loss: 0.1381 - val_accuracy: 0.9580\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9680 - val_loss: 0.1287 - val_accuracy: 0.9596\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9680 - val_loss: 0.2025 - val_accuracy: 0.9297\n",
      "6\n",
      "1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 8, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 3, 64)             24640     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,330\n",
      "Trainable params: 31,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.4503 - accuracy: 0.7984 - val_loss: 0.3635 - val_accuracy: 0.8547\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.3762 - accuracy: 0.8443 - val_loss: 0.4053 - val_accuracy: 0.8510\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8554 - val_loss: 0.3074 - val_accuracy: 0.8872\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.8676 - val_loss: 0.2689 - val_accuracy: 0.8904\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.8782 - val_loss: 0.2853 - val_accuracy: 0.8856\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.8851 - val_loss: 0.2512 - val_accuracy: 0.8962\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.8807 - val_loss: 0.2541 - val_accuracy: 0.8962\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2591 - accuracy: 0.8945 - val_loss: 0.2255 - val_accuracy: 0.9058\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.8958 - val_loss: 0.2309 - val_accuracy: 0.9053\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2457 - accuracy: 0.9006 - val_loss: 0.2173 - val_accuracy: 0.9095\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2382 - accuracy: 0.9011 - val_loss: 0.2346 - val_accuracy: 0.9053\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2242 - accuracy: 0.9097 - val_loss: 0.2012 - val_accuracy: 0.9186\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9134 - val_loss: 0.2268 - val_accuracy: 0.9047\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2134 - accuracy: 0.9145 - val_loss: 0.2498 - val_accuracy: 0.9170\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9170 - val_loss: 0.2149 - val_accuracy: 0.9234\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2029 - accuracy: 0.9177 - val_loss: 0.1950 - val_accuracy: 0.9234\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2014 - accuracy: 0.9200 - val_loss: 0.1822 - val_accuracy: 0.9260\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9224 - val_loss: 0.1762 - val_accuracy: 0.9303\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1888 - accuracy: 0.9247 - val_loss: 0.1846 - val_accuracy: 0.9196\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1869 - accuracy: 0.9255 - val_loss: 0.1855 - val_accuracy: 0.9297\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1842 - accuracy: 0.9244 - val_loss: 0.1673 - val_accuracy: 0.9324\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1791 - accuracy: 0.9284 - val_loss: 0.2105 - val_accuracy: 0.9143\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1751 - accuracy: 0.9294 - val_loss: 0.1699 - val_accuracy: 0.9345\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1746 - accuracy: 0.9293 - val_loss: 0.2004 - val_accuracy: 0.9218\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9347 - val_loss: 0.1871 - val_accuracy: 0.9239\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1662 - accuracy: 0.9351 - val_loss: 0.1530 - val_accuracy: 0.9367\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9329 - val_loss: 0.1960 - val_accuracy: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9344 - val_loss: 0.1578 - val_accuracy: 0.9377\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9365 - val_loss: 0.1787 - val_accuracy: 0.9250\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1574 - accuracy: 0.9397 - val_loss: 0.1540 - val_accuracy: 0.9351\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9359 - val_loss: 0.1635 - val_accuracy: 0.9361\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1562 - accuracy: 0.9382 - val_loss: 0.1621 - val_accuracy: 0.9431\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9414 - val_loss: 0.2388 - val_accuracy: 0.9170\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9398 - val_loss: 0.1604 - val_accuracy: 0.9340\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9389 - val_loss: 0.1615 - val_accuracy: 0.9393\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9402 - val_loss: 0.1475 - val_accuracy: 0.9436\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9451 - val_loss: 0.1507 - val_accuracy: 0.9324\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9437 - val_loss: 0.1555 - val_accuracy: 0.9383\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9444 - val_loss: 0.1435 - val_accuracy: 0.9468\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9458 - val_loss: 0.1521 - val_accuracy: 0.9436\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1456 - accuracy: 0.9454 - val_loss: 0.1766 - val_accuracy: 0.9282\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9447 - val_loss: 0.1508 - val_accuracy: 0.9361\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1389 - accuracy: 0.9456 - val_loss: 0.1346 - val_accuracy: 0.9484\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1394 - accuracy: 0.9463 - val_loss: 0.1351 - val_accuracy: 0.9478\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1385 - accuracy: 0.9458 - val_loss: 0.1359 - val_accuracy: 0.9468\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9437 - val_loss: 0.1296 - val_accuracy: 0.9516\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1362 - accuracy: 0.9486 - val_loss: 0.1444 - val_accuracy: 0.9484\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9466 - val_loss: 0.1749 - val_accuracy: 0.9319\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9483 - val_loss: 0.1622 - val_accuracy: 0.9297\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9477 - val_loss: 0.1456 - val_accuracy: 0.9473\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9483 - val_loss: 0.1472 - val_accuracy: 0.9409\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1332 - accuracy: 0.9506 - val_loss: 0.1320 - val_accuracy: 0.9516\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1313 - accuracy: 0.9512 - val_loss: 0.1414 - val_accuracy: 0.9452\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1318 - accuracy: 0.9489 - val_loss: 0.1358 - val_accuracy: 0.9489\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9510 - val_loss: 0.1472 - val_accuracy: 0.9516\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.1408 - val_accuracy: 0.9462\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1342 - accuracy: 0.9474 - val_loss: 0.1358 - val_accuracy: 0.9457\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9537 - val_loss: 0.1385 - val_accuracy: 0.9526\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1249 - accuracy: 0.9536 - val_loss: 0.1612 - val_accuracy: 0.9420\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9535 - val_loss: 0.1481 - val_accuracy: 0.9526\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1234 - accuracy: 0.9539 - val_loss: 0.1391 - val_accuracy: 0.9473\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1247 - accuracy: 0.9517 - val_loss: 0.1437 - val_accuracy: 0.9494\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1231 - accuracy: 0.9553 - val_loss: 0.1516 - val_accuracy: 0.9489\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9521 - val_loss: 0.1359 - val_accuracy: 0.9468\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1225 - accuracy: 0.9540 - val_loss: 0.1551 - val_accuracy: 0.9425\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9533 - val_loss: 0.1265 - val_accuracy: 0.9569\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1172 - accuracy: 0.9543 - val_loss: 0.1505 - val_accuracy: 0.9494\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1180 - accuracy: 0.9563 - val_loss: 0.1273 - val_accuracy: 0.9542\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9571 - val_loss: 0.1298 - val_accuracy: 0.9468\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1190 - accuracy: 0.9540 - val_loss: 0.1300 - val_accuracy: 0.9441\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9579 - val_loss: 0.1529 - val_accuracy: 0.9356\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1164 - accuracy: 0.9586 - val_loss: 0.1327 - val_accuracy: 0.9500\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1182 - accuracy: 0.9552 - val_loss: 0.1293 - val_accuracy: 0.9532\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9574 - val_loss: 0.1219 - val_accuracy: 0.9542\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9580 - val_loss: 0.1368 - val_accuracy: 0.9452\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9593 - val_loss: 0.1636 - val_accuracy: 0.9329\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1148 - accuracy: 0.9589 - val_loss: 0.1652 - val_accuracy: 0.9367\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9580 - val_loss: 0.1377 - val_accuracy: 0.9532\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9591 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1146 - accuracy: 0.9570 - val_loss: 0.1400 - val_accuracy: 0.9532\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1110 - accuracy: 0.9610 - val_loss: 0.1374 - val_accuracy: 0.9526\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9576 - val_loss: 0.1363 - val_accuracy: 0.9500\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1064 - accuracy: 0.9605 - val_loss: 0.1295 - val_accuracy: 0.9564\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1039 - accuracy: 0.9613 - val_loss: 0.1234 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9593 - val_loss: 0.1258 - val_accuracy: 0.9564\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9613 - val_loss: 0.1363 - val_accuracy: 0.9510\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1089 - accuracy: 0.9598 - val_loss: 0.1278 - val_accuracy: 0.9526\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9622 - val_loss: 0.1293 - val_accuracy: 0.9558\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1090 - accuracy: 0.9613 - val_loss: 0.1448 - val_accuracy: 0.9393\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1022 - accuracy: 0.9613 - val_loss: 0.1203 - val_accuracy: 0.9574\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9625 - val_loss: 0.1521 - val_accuracy: 0.9404\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1017 - accuracy: 0.9597 - val_loss: 0.1351 - val_accuracy: 0.9553\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1030 - accuracy: 0.9622 - val_loss: 0.1310 - val_accuracy: 0.9585\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1074 - accuracy: 0.9620 - val_loss: 0.1457 - val_accuracy: 0.9489\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9645 - val_loss: 0.1431 - val_accuracy: 0.9526\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9636 - val_loss: 0.1247 - val_accuracy: 0.9596\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9632 - val_loss: 0.1244 - val_accuracy: 0.9569\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9640 - val_loss: 0.1290 - val_accuracy: 0.9580\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9636 - val_loss: 0.1233 - val_accuracy: 0.9548\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9664 - val_loss: 0.1264 - val_accuracy: 0.9580\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9649 - val_loss: 0.1209 - val_accuracy: 0.9590\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9624 - val_loss: 0.1305 - val_accuracy: 0.9484\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9645 - val_loss: 0.1473 - val_accuracy: 0.9436\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9634 - val_loss: 0.1340 - val_accuracy: 0.9564\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9660 - val_loss: 0.1409 - val_accuracy: 0.9542\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9660 - val_loss: 0.1346 - val_accuracy: 0.9478\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.1426 - val_accuracy: 0.9574\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9655 - val_loss: 0.1378 - val_accuracy: 0.9564\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.1613 - val_accuracy: 0.9478\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9678 - val_loss: 0.1198 - val_accuracy: 0.9611\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9669 - val_loss: 0.1351 - val_accuracy: 0.9569\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.1308 - val_accuracy: 0.9564\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9679 - val_loss: 0.1264 - val_accuracy: 0.9585\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0941 - accuracy: 0.9669 - val_loss: 0.1520 - val_accuracy: 0.9516\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9653 - val_loss: 0.1246 - val_accuracy: 0.9580\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9669 - val_loss: 0.1392 - val_accuracy: 0.9558\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.1300 - val_accuracy: 0.9558\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.9691 - val_loss: 0.1217 - val_accuracy: 0.9585\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9703 - val_loss: 0.1317 - val_accuracy: 0.9580\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.9680 - val_loss: 0.1506 - val_accuracy: 0.9452\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9713 - val_loss: 0.1339 - val_accuracy: 0.9627\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9705 - val_loss: 0.1394 - val_accuracy: 0.9596\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.9690 - val_loss: 0.1386 - val_accuracy: 0.9510\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9672 - val_loss: 0.1373 - val_accuracy: 0.9590\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9726 - val_loss: 0.1367 - val_accuracy: 0.9532\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9671 - val_loss: 0.1213 - val_accuracy: 0.9580\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9707 - val_loss: 0.1246 - val_accuracy: 0.9585\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9688 - val_loss: 0.1518 - val_accuracy: 0.9457\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9675 - val_loss: 0.1475 - val_accuracy: 0.9484\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9707 - val_loss: 0.1515 - val_accuracy: 0.9452\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.1435 - val_accuracy: 0.9462\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9713 - val_loss: 0.1636 - val_accuracy: 0.9473\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9744 - val_loss: 0.1440 - val_accuracy: 0.9580\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.1338 - val_accuracy: 0.9627\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9705 - val_loss: 0.1248 - val_accuracy: 0.9617\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9687 - val_loss: 0.1276 - val_accuracy: 0.9596\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9710 - val_loss: 0.1480 - val_accuracy: 0.9500\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.1361 - val_accuracy: 0.9606\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0771 - accuracy: 0.9725 - val_loss: 0.1248 - val_accuracy: 0.9665\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9722 - val_loss: 0.1290 - val_accuracy: 0.9606\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9700 - val_loss: 0.1321 - val_accuracy: 0.9590\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9700 - val_loss: 0.1328 - val_accuracy: 0.9590\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9726 - val_loss: 0.1602 - val_accuracy: 0.9478\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9687 - val_loss: 0.1432 - val_accuracy: 0.9564\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9750 - val_loss: 0.1447 - val_accuracy: 0.9580\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9699 - val_loss: 0.1310 - val_accuracy: 0.9617\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 0.1440 - val_accuracy: 0.9601\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9713 - val_loss: 0.1426 - val_accuracy: 0.9611\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9722 - val_loss: 0.1403 - val_accuracy: 0.9590\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9732 - val_loss: 0.1425 - val_accuracy: 0.9564\n",
      "4\n",
      "1\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 9, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 6, 64)             16448     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,154\n",
      "Trainable params: 29,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.4651 - accuracy: 0.7805 - val_loss: 0.3578 - val_accuracy: 0.8552\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8506 - val_loss: 0.3104 - val_accuracy: 0.8696\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8590 - val_loss: 0.3733 - val_accuracy: 0.8819\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.8739 - val_loss: 0.2913 - val_accuracy: 0.8973\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.8818 - val_loss: 0.2575 - val_accuracy: 0.9005\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.8906 - val_loss: 0.2547 - val_accuracy: 0.9015\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.8988 - val_loss: 0.2288 - val_accuracy: 0.9106\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9027 - val_loss: 0.2101 - val_accuracy: 0.9122\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.9057 - val_loss: 0.2324 - val_accuracy: 0.9154\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2329 - accuracy: 0.9080 - val_loss: 0.1950 - val_accuracy: 0.9154\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2245 - accuracy: 0.9110 - val_loss: 0.2361 - val_accuracy: 0.9069\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2259 - accuracy: 0.9092 - val_loss: 0.1926 - val_accuracy: 0.9164\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2204 - accuracy: 0.9127 - val_loss: 0.1895 - val_accuracy: 0.9170\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2170 - accuracy: 0.9149 - val_loss: 0.2072 - val_accuracy: 0.9101\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9139 - val_loss: 0.1906 - val_accuracy: 0.9148\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9157 - val_loss: 0.2016 - val_accuracy: 0.9159\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2095 - accuracy: 0.9169 - val_loss: 0.2784 - val_accuracy: 0.8898\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9181 - val_loss: 0.1957 - val_accuracy: 0.9223\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2038 - accuracy: 0.9177 - val_loss: 0.2055 - val_accuracy: 0.9106\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2026 - accuracy: 0.9145 - val_loss: 0.1786 - val_accuracy: 0.9266\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9222 - val_loss: 0.1982 - val_accuracy: 0.9196\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9205 - val_loss: 0.1875 - val_accuracy: 0.9255\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9209 - val_loss: 0.1785 - val_accuracy: 0.9218\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9184 - val_loss: 0.2037 - val_accuracy: 0.9063\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1899 - accuracy: 0.9208 - val_loss: 0.1959 - val_accuracy: 0.9180\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1898 - accuracy: 0.9203 - val_loss: 0.2037 - val_accuracy: 0.9122\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1861 - accuracy: 0.9230 - val_loss: 0.2036 - val_accuracy: 0.9250\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1885 - accuracy: 0.9203 - val_loss: 0.1860 - val_accuracy: 0.9234\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1828 - accuracy: 0.9217 - val_loss: 0.1819 - val_accuracy: 0.9282\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9253 - val_loss: 0.2197 - val_accuracy: 0.9133\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1809 - accuracy: 0.9275 - val_loss: 0.1656 - val_accuracy: 0.9313\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1830 - accuracy: 0.9274 - val_loss: 0.1706 - val_accuracy: 0.9282\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9258 - val_loss: 0.1677 - val_accuracy: 0.9345\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9286 - val_loss: 0.1698 - val_accuracy: 0.9218\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.9259 - val_loss: 0.1650 - val_accuracy: 0.9335\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9278 - val_loss: 0.1647 - val_accuracy: 0.9276\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1736 - accuracy: 0.9278 - val_loss: 0.2049 - val_accuracy: 0.9095\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9293 - val_loss: 0.2144 - val_accuracy: 0.9122\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9288 - val_loss: 0.1819 - val_accuracy: 0.9212\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9309 - val_loss: 0.1803 - val_accuracy: 0.9255\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.9321 - val_loss: 0.1583 - val_accuracy: 0.9292\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9304 - val_loss: 0.1715 - val_accuracy: 0.9282\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.9285 - val_loss: 0.2057 - val_accuracy: 0.9154\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9311 - val_loss: 0.1823 - val_accuracy: 0.9234\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9320 - val_loss: 0.1683 - val_accuracy: 0.9308\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9336 - val_loss: 0.1889 - val_accuracy: 0.9133\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9363 - val_loss: 0.1600 - val_accuracy: 0.9303\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9344 - val_loss: 0.1569 - val_accuracy: 0.9313\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1558 - accuracy: 0.9348 - val_loss: 0.1737 - val_accuracy: 0.9234\n",
      "Epoch 50/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9355 - val_loss: 0.1679 - val_accuracy: 0.9260\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9346 - val_loss: 0.1708 - val_accuracy: 0.9335\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9348 - val_loss: 0.1625 - val_accuracy: 0.9324\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9369 - val_loss: 0.2338 - val_accuracy: 0.9010\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9383 - val_loss: 0.1592 - val_accuracy: 0.9367\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9381 - val_loss: 0.1656 - val_accuracy: 0.9255\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1536 - accuracy: 0.9379 - val_loss: 0.1774 - val_accuracy: 0.9202\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1559 - accuracy: 0.9394 - val_loss: 0.1364 - val_accuracy: 0.9420\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9398 - val_loss: 0.1586 - val_accuracy: 0.9324\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9354 - val_loss: 0.1445 - val_accuracy: 0.9431\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9402 - val_loss: 0.1305 - val_accuracy: 0.9484\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9414 - val_loss: 0.1421 - val_accuracy: 0.9457\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9419 - val_loss: 0.1562 - val_accuracy: 0.9420\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1470 - accuracy: 0.9396 - val_loss: 0.1373 - val_accuracy: 0.9436\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9421 - val_loss: 0.2079 - val_accuracy: 0.9063\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9413 - val_loss: 0.1374 - val_accuracy: 0.9388\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1434 - accuracy: 0.9429 - val_loss: 0.1461 - val_accuracy: 0.9494\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1435 - accuracy: 0.9441 - val_loss: 0.1406 - val_accuracy: 0.9436\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1426 - accuracy: 0.9437 - val_loss: 0.1427 - val_accuracy: 0.9409\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9419 - val_loss: 0.1361 - val_accuracy: 0.9415\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9437 - val_loss: 0.1306 - val_accuracy: 0.9510\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9450 - val_loss: 0.1320 - val_accuracy: 0.9532\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9448 - val_loss: 0.1274 - val_accuracy: 0.9532\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1382 - accuracy: 0.9436 - val_loss: 0.1376 - val_accuracy: 0.9468\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1333 - accuracy: 0.9489 - val_loss: 0.1292 - val_accuracy: 0.9526\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9475 - val_loss: 0.1304 - val_accuracy: 0.9468\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1354 - accuracy: 0.9467 - val_loss: 0.1340 - val_accuracy: 0.9431\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9467 - val_loss: 0.1438 - val_accuracy: 0.9457\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9479 - val_loss: 0.1301 - val_accuracy: 0.9510\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1322 - accuracy: 0.9487 - val_loss: 0.1210 - val_accuracy: 0.9521\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9497 - val_loss: 0.1220 - val_accuracy: 0.9505\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1304 - accuracy: 0.9478 - val_loss: 0.1421 - val_accuracy: 0.9457\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1333 - accuracy: 0.9474 - val_loss: 0.1284 - val_accuracy: 0.9516\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1288 - accuracy: 0.9493 - val_loss: 0.1270 - val_accuracy: 0.9478\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1344 - accuracy: 0.9479 - val_loss: 0.1475 - val_accuracy: 0.9372\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9508 - val_loss: 0.1228 - val_accuracy: 0.9532\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1277 - accuracy: 0.9479 - val_loss: 0.1295 - val_accuracy: 0.9521\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1282 - accuracy: 0.9518 - val_loss: 0.1546 - val_accuracy: 0.9351\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1247 - accuracy: 0.9521 - val_loss: 0.1274 - val_accuracy: 0.9489\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1236 - accuracy: 0.9506 - val_loss: 0.1407 - val_accuracy: 0.9457\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1277 - accuracy: 0.9505 - val_loss: 0.1335 - val_accuracy: 0.9537\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1250 - accuracy: 0.9509 - val_loss: 0.1290 - val_accuracy: 0.9489\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9493 - val_loss: 0.1301 - val_accuracy: 0.9542\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1238 - accuracy: 0.9520 - val_loss: 0.1218 - val_accuracy: 0.9516\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1217 - accuracy: 0.9508 - val_loss: 0.1282 - val_accuracy: 0.9537\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1187 - accuracy: 0.9559 - val_loss: 0.1189 - val_accuracy: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1244 - accuracy: 0.9516 - val_loss: 0.1253 - val_accuracy: 0.9532\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9522 - val_loss: 0.1539 - val_accuracy: 0.9441\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1240 - accuracy: 0.9504 - val_loss: 0.1309 - val_accuracy: 0.9532\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9537 - val_loss: 0.1362 - val_accuracy: 0.9452\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1162 - accuracy: 0.9551 - val_loss: 0.1322 - val_accuracy: 0.9516\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1200 - accuracy: 0.9548 - val_loss: 0.1195 - val_accuracy: 0.9601\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9540 - val_loss: 0.1241 - val_accuracy: 0.9553\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1183 - accuracy: 0.9551 - val_loss: 0.1554 - val_accuracy: 0.9372\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1147 - accuracy: 0.9548 - val_loss: 0.1250 - val_accuracy: 0.9564\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9571 - val_loss: 0.1341 - val_accuracy: 0.9505\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9568 - val_loss: 0.1253 - val_accuracy: 0.9542\n",
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1139 - accuracy: 0.9571 - val_loss: 0.1280 - val_accuracy: 0.9510\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.1195 - val_accuracy: 0.9564\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9598 - val_loss: 0.1234 - val_accuracy: 0.9585\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9556 - val_loss: 0.1255 - val_accuracy: 0.9564\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9556 - val_loss: 0.1503 - val_accuracy: 0.9436\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9582 - val_loss: 0.1289 - val_accuracy: 0.9542\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 0.1339 - val_accuracy: 0.9489\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1138 - accuracy: 0.9575 - val_loss: 0.1180 - val_accuracy: 0.9558\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9599 - val_loss: 0.1380 - val_accuracy: 0.9452\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9571 - val_loss: 0.1257 - val_accuracy: 0.9542\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1064 - accuracy: 0.9599 - val_loss: 0.1188 - val_accuracy: 0.9558\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9591 - val_loss: 0.1274 - val_accuracy: 0.9526\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9591 - val_loss: 0.1597 - val_accuracy: 0.9431\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9557 - val_loss: 0.1510 - val_accuracy: 0.9415\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9562 - val_loss: 0.1466 - val_accuracy: 0.9558\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1057 - accuracy: 0.9587 - val_loss: 0.1216 - val_accuracy: 0.9558\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9582 - val_loss: 0.1350 - val_accuracy: 0.9510\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9607 - val_loss: 0.1498 - val_accuracy: 0.9473\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1017 - accuracy: 0.9632 - val_loss: 0.1355 - val_accuracy: 0.9537\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9611 - val_loss: 0.1216 - val_accuracy: 0.9580\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9609 - val_loss: 0.1243 - val_accuracy: 0.9564\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9595 - val_loss: 0.1639 - val_accuracy: 0.9489\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9599 - val_loss: 0.1201 - val_accuracy: 0.9574\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1039 - accuracy: 0.9622 - val_loss: 0.1212 - val_accuracy: 0.9585\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9611 - val_loss: 0.1351 - val_accuracy: 0.9558\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9599 - val_loss: 0.1318 - val_accuracy: 0.9580\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9637 - val_loss: 0.1324 - val_accuracy: 0.9553\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1040 - accuracy: 0.9614 - val_loss: 0.1180 - val_accuracy: 0.9617\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9626 - val_loss: 0.1286 - val_accuracy: 0.9601\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9641 - val_loss: 0.1287 - val_accuracy: 0.9548\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9614 - val_loss: 0.1497 - val_accuracy: 0.9489\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9632 - val_loss: 0.1343 - val_accuracy: 0.9548\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9648 - val_loss: 0.1229 - val_accuracy: 0.9633\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9626 - val_loss: 0.1189 - val_accuracy: 0.9617\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9634 - val_loss: 0.1370 - val_accuracy: 0.9564\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9610 - val_loss: 0.1344 - val_accuracy: 0.9548\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9632 - val_loss: 0.1405 - val_accuracy: 0.9574\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9638 - val_loss: 0.1436 - val_accuracy: 0.9500\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9642 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9641 - val_loss: 0.1286 - val_accuracy: 0.9585\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9641 - val_loss: 0.1329 - val_accuracy: 0.9590\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.1219 - val_accuracy: 0.9617\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9640 - val_loss: 0.1252 - val_accuracy: 0.9564\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9629 - val_loss: 0.1323 - val_accuracy: 0.9521\n",
      "6\n",
      "1\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_11 (Conv1D)          (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 7, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 2, 64)             24640     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,282\n",
      "Trainable params: 29,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.7751 - val_loss: 0.4114 - val_accuracy: 0.8552\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3738 - accuracy: 0.8509 - val_loss: 0.3061 - val_accuracy: 0.8616\n",
      "Epoch 3/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.8641 - val_loss: 0.3409 - val_accuracy: 0.8829\n",
      "Epoch 4/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.8730 - val_loss: 0.2549 - val_accuracy: 0.8925\n",
      "Epoch 5/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.8814 - val_loss: 0.2415 - val_accuracy: 0.8968\n",
      "Epoch 6/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8887 - val_loss: 0.2857 - val_accuracy: 0.8771\n",
      "Epoch 7/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.8940 - val_loss: 0.2743 - val_accuracy: 0.9053\n",
      "Epoch 8/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.9008 - val_loss: 0.2249 - val_accuracy: 0.9111\n",
      "Epoch 9/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.9035 - val_loss: 0.2580 - val_accuracy: 0.8898\n",
      "Epoch 10/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.9049 - val_loss: 0.2291 - val_accuracy: 0.9127\n",
      "Epoch 11/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9115 - val_loss: 0.1969 - val_accuracy: 0.9143\n",
      "Epoch 12/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2295 - accuracy: 0.9114 - val_loss: 0.2062 - val_accuracy: 0.9191\n",
      "Epoch 13/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9141 - val_loss: 0.1867 - val_accuracy: 0.9223\n",
      "Epoch 14/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2075 - accuracy: 0.9151 - val_loss: 0.1923 - val_accuracy: 0.9255\n",
      "Epoch 15/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9143 - val_loss: 0.2015 - val_accuracy: 0.9164\n",
      "Epoch 16/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.9195 - val_loss: 0.2212 - val_accuracy: 0.9090\n",
      "Epoch 17/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.2022 - accuracy: 0.9178 - val_loss: 0.1945 - val_accuracy: 0.9186\n",
      "Epoch 18/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1940 - accuracy: 0.9224 - val_loss: 0.1882 - val_accuracy: 0.9287\n",
      "Epoch 19/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9208 - val_loss: 0.1774 - val_accuracy: 0.9234\n",
      "Epoch 20/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1885 - accuracy: 0.9212 - val_loss: 0.1715 - val_accuracy: 0.9340\n",
      "Epoch 21/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1855 - accuracy: 0.9255 - val_loss: 0.1775 - val_accuracy: 0.9276\n",
      "Epoch 22/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1852 - accuracy: 0.9257 - val_loss: 0.1736 - val_accuracy: 0.9308\n",
      "Epoch 23/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9277 - val_loss: 0.1831 - val_accuracy: 0.9287\n",
      "Epoch 24/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1806 - accuracy: 0.9269 - val_loss: 0.1681 - val_accuracy: 0.9351\n",
      "Epoch 25/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1810 - accuracy: 0.9265 - val_loss: 0.1902 - val_accuracy: 0.9228\n",
      "Epoch 26/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9275 - val_loss: 0.1953 - val_accuracy: 0.9196\n",
      "Epoch 27/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1788 - accuracy: 0.9281 - val_loss: 0.2052 - val_accuracy: 0.9196\n",
      "Epoch 28/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9350 - val_loss: 0.1796 - val_accuracy: 0.9271\n",
      "Epoch 29/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9305 - val_loss: 0.1602 - val_accuracy: 0.9399\n",
      "Epoch 30/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9331 - val_loss: 0.1884 - val_accuracy: 0.9266\n",
      "Epoch 31/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.9308 - val_loss: 0.1679 - val_accuracy: 0.9351\n",
      "Epoch 32/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9356 - val_loss: 0.1640 - val_accuracy: 0.9287\n",
      "Epoch 33/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9317 - val_loss: 0.1723 - val_accuracy: 0.9282\n",
      "Epoch 34/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9355 - val_loss: 0.1799 - val_accuracy: 0.9207\n",
      "Epoch 35/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9359 - val_loss: 0.1730 - val_accuracy: 0.9292\n",
      "Epoch 36/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9308 - val_loss: 0.1835 - val_accuracy: 0.9186\n",
      "Epoch 37/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9350 - val_loss: 0.1734 - val_accuracy: 0.9260\n",
      "Epoch 38/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9367 - val_loss: 0.1540 - val_accuracy: 0.9404\n",
      "Epoch 39/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9381 - val_loss: 0.1865 - val_accuracy: 0.9303\n",
      "Epoch 40/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9394 - val_loss: 0.1877 - val_accuracy: 0.9313\n",
      "Epoch 41/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9383 - val_loss: 0.1483 - val_accuracy: 0.9441\n",
      "Epoch 42/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1520 - accuracy: 0.9402 - val_loss: 0.1452 - val_accuracy: 0.9452\n",
      "Epoch 43/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1537 - accuracy: 0.9402 - val_loss: 0.1675 - val_accuracy: 0.9377\n",
      "Epoch 44/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9396 - val_loss: 0.1552 - val_accuracy: 0.9436\n",
      "Epoch 45/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9409 - val_loss: 0.1431 - val_accuracy: 0.9494\n",
      "Epoch 46/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1443 - accuracy: 0.9437 - val_loss: 0.1417 - val_accuracy: 0.9473\n",
      "Epoch 47/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9447 - val_loss: 0.1497 - val_accuracy: 0.9393\n",
      "Epoch 48/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1484 - accuracy: 0.9417 - val_loss: 0.1488 - val_accuracy: 0.9441\n",
      "Epoch 49/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9455 - val_loss: 0.1490 - val_accuracy: 0.9484\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1464 - accuracy: 0.9431 - val_loss: 0.1934 - val_accuracy: 0.9271\n",
      "Epoch 51/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1445 - accuracy: 0.9454 - val_loss: 0.1576 - val_accuracy: 0.9399\n",
      "Epoch 52/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9479 - val_loss: 0.1543 - val_accuracy: 0.9436\n",
      "Epoch 53/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9471 - val_loss: 0.1731 - val_accuracy: 0.9319\n",
      "Epoch 54/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9429 - val_loss: 0.1482 - val_accuracy: 0.9425\n",
      "Epoch 55/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9472 - val_loss: 0.1349 - val_accuracy: 0.9489\n",
      "Epoch 56/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9477 - val_loss: 0.1588 - val_accuracy: 0.9457\n",
      "Epoch 57/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1378 - accuracy: 0.9459 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
      "Epoch 58/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9464 - val_loss: 0.1454 - val_accuracy: 0.9441\n",
      "Epoch 59/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9466 - val_loss: 0.1426 - val_accuracy: 0.9462\n",
      "Epoch 60/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1321 - accuracy: 0.9487 - val_loss: 0.1959 - val_accuracy: 0.9287\n",
      "Epoch 61/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1324 - accuracy: 0.9495 - val_loss: 0.1567 - val_accuracy: 0.9404\n",
      "Epoch 62/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9481 - val_loss: 0.1387 - val_accuracy: 0.9484\n",
      "Epoch 63/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9477 - val_loss: 0.1362 - val_accuracy: 0.9553\n",
      "Epoch 64/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9501 - val_loss: 0.1367 - val_accuracy: 0.9489\n",
      "Epoch 65/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1282 - accuracy: 0.9495 - val_loss: 0.1543 - val_accuracy: 0.9404\n",
      "Epoch 66/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1294 - accuracy: 0.9490 - val_loss: 0.1509 - val_accuracy: 0.9404\n",
      "Epoch 67/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9495 - val_loss: 0.1331 - val_accuracy: 0.9564\n",
      "Epoch 68/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1230 - accuracy: 0.9530 - val_loss: 0.1398 - val_accuracy: 0.9468\n",
      "Epoch 69/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1280 - accuracy: 0.9498 - val_loss: 0.1397 - val_accuracy: 0.9505\n",
      "Epoch 70/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9529 - val_loss: 0.1442 - val_accuracy: 0.9516\n",
      "Epoch 71/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9529 - val_loss: 0.1351 - val_accuracy: 0.9532\n",
      "Epoch 72/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9516 - val_loss: 0.1364 - val_accuracy: 0.9516\n",
      "Epoch 73/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1208 - accuracy: 0.9553 - val_loss: 0.1409 - val_accuracy: 0.9462\n",
      "Epoch 74/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1199 - accuracy: 0.9548 - val_loss: 0.1669 - val_accuracy: 0.9383\n",
      "Epoch 75/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9537 - val_loss: 0.1373 - val_accuracy: 0.9494\n",
      "Epoch 76/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.1420 - val_accuracy: 0.9516\n",
      "Epoch 77/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1226 - accuracy: 0.9532 - val_loss: 0.1357 - val_accuracy: 0.9553\n",
      "Epoch 78/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1182 - accuracy: 0.9556 - val_loss: 0.1340 - val_accuracy: 0.9532\n",
      "Epoch 79/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1151 - accuracy: 0.9559 - val_loss: 0.1726 - val_accuracy: 0.9399\n",
      "Epoch 80/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1195 - accuracy: 0.9532 - val_loss: 0.1813 - val_accuracy: 0.9393\n",
      "Epoch 81/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9566 - val_loss: 0.1447 - val_accuracy: 0.9548\n",
      "Epoch 82/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1166 - accuracy: 0.9549 - val_loss: 0.1433 - val_accuracy: 0.9484\n",
      "Epoch 83/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9594 - val_loss: 0.1546 - val_accuracy: 0.9473\n",
      "Epoch 84/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1150 - accuracy: 0.9562 - val_loss: 0.1359 - val_accuracy: 0.9505\n",
      "Epoch 85/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1189 - accuracy: 0.9537 - val_loss: 0.1329 - val_accuracy: 0.9521\n",
      "Epoch 86/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9578 - val_loss: 0.1533 - val_accuracy: 0.9473\n",
      "Epoch 87/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9574 - val_loss: 0.1432 - val_accuracy: 0.9510\n",
      "Epoch 88/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1116 - accuracy: 0.9589 - val_loss: 0.1426 - val_accuracy: 0.9510\n",
      "Epoch 89/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1112 - accuracy: 0.9578 - val_loss: 0.1282 - val_accuracy: 0.9558\n",
      "Epoch 90/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9555 - val_loss: 0.1343 - val_accuracy: 0.9532\n",
      "Epoch 91/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1111 - accuracy: 0.9580 - val_loss: 0.1807 - val_accuracy: 0.9372\n",
      "Epoch 92/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1099 - accuracy: 0.9578 - val_loss: 0.1358 - val_accuracy: 0.9516\n",
      "Epoch 93/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9591 - val_loss: 0.1318 - val_accuracy: 0.9558\n",
      "Epoch 94/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9591 - val_loss: 0.1772 - val_accuracy: 0.9367\n",
      "Epoch 95/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9594 - val_loss: 0.1365 - val_accuracy: 0.9553\n",
      "Epoch 96/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1104 - accuracy: 0.9570 - val_loss: 0.1340 - val_accuracy: 0.9542\n",
      "Epoch 97/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9594 - val_loss: 0.1460 - val_accuracy: 0.9494\n",
      "Epoch 98/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9640 - val_loss: 0.1409 - val_accuracy: 0.9500\n",
      "Epoch 99/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1106 - accuracy: 0.9564 - val_loss: 0.1360 - val_accuracy: 0.9564\n",
      "Epoch 100/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1049 - accuracy: 0.9622 - val_loss: 0.1498 - val_accuracy: 0.9521\n",
      "Epoch 101/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1061 - accuracy: 0.9609 - val_loss: 0.1352 - val_accuracy: 0.9521\n",
      "Epoch 102/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9630 - val_loss: 0.1391 - val_accuracy: 0.9542\n",
      "Epoch 103/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1062 - accuracy: 0.9621 - val_loss: 0.1367 - val_accuracy: 0.9548\n",
      "Epoch 104/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9622 - val_loss: 0.1341 - val_accuracy: 0.9542\n",
      "Epoch 105/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9617 - val_loss: 0.1354 - val_accuracy: 0.9580\n",
      "Epoch 106/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.1325 - val_accuracy: 0.9542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9620 - val_loss: 0.1507 - val_accuracy: 0.9489\n",
      "Epoch 108/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9626 - val_loss: 0.1320 - val_accuracy: 0.9569\n",
      "Epoch 109/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1017 - accuracy: 0.9626 - val_loss: 0.1412 - val_accuracy: 0.9558\n",
      "Epoch 110/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9603 - val_loss: 0.1206 - val_accuracy: 0.9601\n",
      "Epoch 111/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9620 - val_loss: 0.1592 - val_accuracy: 0.9484\n",
      "Epoch 112/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1055 - accuracy: 0.9610 - val_loss: 0.1423 - val_accuracy: 0.9526\n",
      "Epoch 113/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9637 - val_loss: 0.1336 - val_accuracy: 0.9558\n",
      "Epoch 114/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9628 - val_loss: 0.1428 - val_accuracy: 0.9569\n",
      "Epoch 115/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.1351 - val_accuracy: 0.9606\n",
      "Epoch 116/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9652 - val_loss: 0.1381 - val_accuracy: 0.9548\n",
      "Epoch 117/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9649 - val_loss: 0.1472 - val_accuracy: 0.9580\n",
      "Epoch 118/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9663 - val_loss: 0.1335 - val_accuracy: 0.9611\n",
      "Epoch 119/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9647 - val_loss: 0.1416 - val_accuracy: 0.9548\n",
      "Epoch 120/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9633 - val_loss: 0.1464 - val_accuracy: 0.9521\n",
      "Epoch 121/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9657 - val_loss: 0.1422 - val_accuracy: 0.9510\n",
      "Epoch 122/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9657 - val_loss: 0.1448 - val_accuracy: 0.9558\n",
      "Epoch 123/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9633 - val_loss: 0.1512 - val_accuracy: 0.9526\n",
      "Epoch 124/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9655 - val_loss: 0.1316 - val_accuracy: 0.9580\n",
      "Epoch 125/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9626 - val_loss: 0.1346 - val_accuracy: 0.9564\n",
      "Epoch 126/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9686 - val_loss: 0.1484 - val_accuracy: 0.9564\n",
      "Epoch 127/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9675 - val_loss: 0.1419 - val_accuracy: 0.9553\n",
      "Epoch 128/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 0.1503 - val_accuracy: 0.9569\n",
      "Epoch 129/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9645 - val_loss: 0.1452 - val_accuracy: 0.9542\n",
      "Epoch 130/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0881 - accuracy: 0.9668 - val_loss: 0.1451 - val_accuracy: 0.9596\n",
      "Epoch 131/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9682 - val_loss: 0.1510 - val_accuracy: 0.9521\n",
      "Epoch 132/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9694 - val_loss: 0.1362 - val_accuracy: 0.9596\n",
      "Epoch 133/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9699 - val_loss: 0.1399 - val_accuracy: 0.9606\n",
      "Epoch 134/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9637 - val_loss: 0.1642 - val_accuracy: 0.9569\n",
      "Epoch 135/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9682 - val_loss: 0.1423 - val_accuracy: 0.9574\n",
      "Epoch 136/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.1367 - val_accuracy: 0.9606\n",
      "Epoch 137/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9715 - val_loss: 0.1728 - val_accuracy: 0.9510\n",
      "Epoch 138/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9661 - val_loss: 0.1363 - val_accuracy: 0.9611\n",
      "Epoch 139/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9645 - val_loss: 0.1554 - val_accuracy: 0.9468\n",
      "Epoch 140/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 0.1774 - val_accuracy: 0.9537\n",
      "Epoch 141/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9722 - val_loss: 0.1366 - val_accuracy: 0.9617\n",
      "Epoch 142/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9713 - val_loss: 0.2321 - val_accuracy: 0.9255\n",
      "Epoch 143/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 0.1379 - val_accuracy: 0.9622\n",
      "Epoch 144/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.1401 - val_accuracy: 0.9585\n",
      "Epoch 145/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9678 - val_loss: 0.1412 - val_accuracy: 0.9611\n",
      "Epoch 146/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9690 - val_loss: 0.1475 - val_accuracy: 0.9532\n",
      "Epoch 147/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9717 - val_loss: 0.1569 - val_accuracy: 0.9505\n",
      "Epoch 148/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9705 - val_loss: 0.1393 - val_accuracy: 0.9611\n",
      "Epoch 149/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.1419 - val_accuracy: 0.9617\n",
      "Epoch 150/150\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0803 - accuracy: 0.9702 - val_loss: 0.1735 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "ms = []\n",
    "hs = []\n",
    "for p in [3,4,5]:\n",
    "    for k in [4,6]:\n",
    "        for s in [1]:\n",
    "            if not (s==2 and k==4):\n",
    "                print(k)\n",
    "                print(s)\n",
    "                model = CNN_Model(filters1=64, filters2 = 64,kernel_size=k,strides=s, pool_size=p)\n",
    "                model.summary()\n",
    "                ms.append(model)\n",
    "                history = model.fit(X_train, y_train, epochs=150, \n",
    "                                validation_data=(X_val, y_val))\n",
    "                hs.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59a9ae78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 - 0s - loss: 0.1142 - accuracy: 0.9628 - 99ms/epoch - 2ms/step\n",
      "Test Loss: 0.11419892311096191\n",
      "Test Accuracy: 0.9627659320831299\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAETCAYAAADDDDjdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASZElEQVR4nO3de7RcZX3G8e/DIQkmSOWiCEguSAS04ipIFkqLFKRGAZUUMKjLgiiiBayQqoiVAK0Vb6sqglyMVGFJqYhXhMrF4gUj8VIuhtAQQRKoARVJIiGQ/PrHu48ZJufyO8nsMztnns9ae2Xm3Xtmfjkn8+Td79773YoIzMwytuh2AWa2+XBgmFmaA8PM0hwYZpbmwDCzNAeGmaU5MMwszYHRAyTtKOlTku6V9ISkZZK+I+k1ydcfJ2ll3XVa823Z7QKsXpKmAj8EVgBnAP9D+Y/iEOBzwOSuFbeRJI2PiDXdrqMXuYcx9l1Q/fnSiLgqIhZFxMKIOB/YG0DSaZJul7Sq6n1cKulZ1bqDgC8AkyRFtcyt1o2XdJ6kpZL+KOk2Sa9q/XBJh0laJGm1pFskza7eY2rLNrMk3VH1fh6QdKYktay/T9JcSfMkPQpcIekmSee3fdY2VR2zOvoTtPUiwssYXYDtgHXAB4bZ7h+Ag4GpwCuA24EvVevGA+8GVgHPrZatq3VXAD8GDgR2A04G1gAvqdZPBp4APgnsARwF/BoIYGq1zb7AWuBs4AXAm4CVwCkt9d0HPAa8F9gdmA4cC/wOmNCy3TuA5cC4bv/sx+rS9QK81PjLhRnVl/PIEb5uZvVF36J6fhywsm2b51dhNLmt/WvABdXjfwUWtq3/QFtgXAHc1LbNXGBpy/P7gG+2bTMBeASY3dI2H/h4t3/uY3nxLsnYpuE3AUkHS/putWuxAvgqpWfx3CFetk/1/r+UtLJ/AQ6jhAnAnsBtba+b3/Z8L8oYS6sfALtI2qalbUHrBhHxBPAl4K3V3+FFlID8/BA12ybyoOfY9r+U/833Aq4ZaANJU4BvA5cAHwJ+SwmDL1NCYzBbVO+9H/Bk27rHN6nq9VovpV41wPpLgdslTaYEx60RsbBDn20DcA9jDIuI3wHXAydL2rp9fTWw+VJKMLwnIm6NiHuAnds2XQP0tbX9nNLDeG5ELG5bllXb3F29f6sZbc8XAge0tf0lZZdkxTB/v7soPZa3A28G5g21vXVAt/eJvNS7UAYjH6J8eY+mDD7uCbyTMgC5N+V/8tOBaZTBxPaByZdXzw8FdgAmVu2XA/dTBjN3o4TDHGBWtX4KZSzk49XnzqKMRwQwpdpmH8qg51zWD3quYMNBzzmD/P2Orz5jJfDMbv+8x/rS9QK8jMIvGXYCPgMsqb5cDwLfAWZW608FllF2JW4EjmkNjGqbCymDjAHMrdrGVV/0JZReyP8B3wD2bXnd4cA9wGrg+9UXPIAdW7aZBdxRvccDwJmAWtYPFRgTq4CZ1+2fcy8sqn7oZqNC0ruBc4BnRQf+8UnamdIjekVEtA+eWod50NNqJenvKUdKHgb2B/4JuGxTw0LSOGB74MPAzx0Wo8OBYXXbnXLuxfbAUsrp6Od04H0PAG6mHAk6pgPvZwneJTGzNB9WNbM0B4aZpTkwukDSzOoKzsWS3t/teiyvumJ2uaQ7u11LNzgwRpmkPuCzwKuBFwLHSnphd6uyEbiMcnFeT3JgjL4ZwOKIWBJlEpgrgdd1uSZLiohbKJfV9yQHxujbhXI2Y7+lVZtZ4zkwzCzNgTH6lgG7tjx/XtVm1ngOjNF3GzBd0jRJ44HZlAu2zBrPgTHKIuIpytyX11PmgrgqyrwOthmQ9GXgVmCPaoayE7pd02jyqeFmluYehpmlOTDMLM2BYWZpDgwzS3NgmFmaA6NLJJ3Y7Rps4/Xq78+B0T09+Q9uDOnJ358Dw8zSGn3iVt/Wk2LL7bfrdhm1WLtyJX1bb3AzsjFlwgN/7HYJtXkyVjNOW3W7jNqsjlWsidUb3Ju30bOGb7n9duz0vnd3uwzbSC84/RfdLsE20o+f+M6A7d4lMbM0B4aZpTkwzCzNgWFmaQ4MM0tzYJhZmgPDzNIcGGaW5sAwszQHhpmlOTDMLM2BYWZpDgwzS3NgmFmaA8PM0hwYZpbmwDCzNAeGmaU5MMwszYFhZmkODDNLc2CYWZoDw8zSHBhmlubAMLM0B4aZpTkwzCzNgWFmaQ4MM0tzYJhZmgPDzNIcGGaW5sAwszQHhpmlOTDMLM2BYWZpDgwzS3NgmFmaA8PM0hwYZpbmwDCzNAeGmaU5MMwszYFhZmmpwJD0NUmHS3LAmPWwbACsAv4DWCrpw5Km11iTmTVUKjAi4k3ATsC5wCuBRZJukfQWSc+os0Aza470LkZEPBYRF0bEDODFwE+Bi4CHJF0kaa+6ijSzZhjxmISknYHXAYcDTwFXA7sCt0ua09nyzKxJsoOe4yQdJela4H7g9cBHgZ0i4oSIeA3wt8AHa6vUzLou28N4iLL7cS+wb0TMiIhLImJlyza3AL8f6k0kzZS0SNJiSe/fuJLNrFu2TG73HuCatoB4moh4FJg22HpJfcBngUOBpcBtkr4REb/Ml2tm3TRsD6P6os8DJm/iZ80AFkfEkohYA1xJGQsxs83EsIEREWsp4xbjN/GzdgEeaHm+tGozs81EdgzjXOAjknaosxgASSdKWiBpwdqVg+4BmVkXZMcw5lDGJ5ZJWko58/NPImLvxHssoxx+7fe8qu1pIuJi4GKACVN2jWR9ZjYKsoHxlQ581m3AdEnTKEExG3hjB97XzEZJKjAi4uxN/aCIeErSycD1QB8wLyLu2tT3NbPRk+1hACDpYOCFQAB3RcT3RvL6iLgWuHYkrzGz5kgFhqRdgGuAfYEHq+adJS0AjoyIBwd9sZmNGdmjJJ8G1gK7R8SuEbErML1q+3RdxZlZs2R3SQ4FDoqIX/U3RMQSSacCN9ZSmZk1zkiuVh3oEKcPe5r1kGxg3Ah8RtKfzqOQNBn4N9zDMOsZ2cA4FZgELJF0v6T7KVeuTqrWmVkPyJ6H8YCkfSjT8+1ZNS+MiBtqq8zMGid9HkZEBPDdajGzHpQ9D+NDg6wKYDWwGLguIh7vVGFm1jzZHsbRlPkwJtFy4hblIrSHKReVLZf0iohY0vEqzawRsoOen6BcPDY1IiZHxGRgKjAfOIcSHvcAn6yjSDNrhmxgnAWcFhFL+xuqx+8FzomI3wJnAi/rfIlm1hTZwNgR2GqA9gnAc6rHvwEmdqIoM2umbGDcAFwkaT9JW1TLfsCFrD9q8mLgV4O+g5lt9rKB8TZKD2I+8ES1/Lhqe3u1zQrKzFxmNkZlT9xaDsyUtAewR9V8d0Tc07LNzTXUZ2YNMqIJdCJikaRHgYcjYl09JZlZU43kVokflbSCMh/n1Kr9PEnvqrE+M2uQkRxWPQJ4M2X8ot9PgOM6XJOZNVR2l+RY4K0R8d+SWndF7gRe0PmyzKyJsj2MnSl3P2u3JSMcBzGzzVc2MO4CDhyg/Rjgp50rx8yaLNs7OBu4vJpxqw84WtKelBsRHVZXcWbWLKkeRkR8k9Kb+BtgHWUQdDpwhCfRMesdI5lA53rKXcvMrEdlz8NYImn7AdqfJcnzX5j1iOyg51TK2EW7CcAuHavGzBptyF0SSbNanh4m6Q8tz/uAQ4D7aqjLzBpouDGMr1R/BvD5tnVPUsLi9A7XZGYNNWRgRMQWAJJ+BewXEY+MSlVm1kjZy9un1V2ImTVf+rCqpG2BV1NmDx/fui4izulwXWbWQNn7kuwPfJtypeqzKZe471Q9v48yc7iZjXHZw6ofA66gHEJdDRxM6WksAM6rpzQza5psYOwNnF/dLnEtMCEifgO8D5hbU21m1jDZwFjT8vg3wJTq8UrKpe9m1gOyg54/A/aj3N3se8A/S9qRMgPX7fWUZmZNk+1hnMn6e6p+kHI/1c8A2wIn1lCXmTVQ9jyMBS2PH6YcXjWzHjNkD0PSMyW9RdI2A6z7s2rdpPrKM7MmGW6X5CTgDRHxWPuKiPgDZVKdd9ZRmJk1z3CB8Qbg/CHWn0+ZUdzMesBwgTGdMgHwYH4JPL9z5ZhZkw0XGAKeM8T65yTew8zGiOG+7HdSJv4dzEyG7oGY2RgyXGDMA86U9Lr2FZJeD5zBhhPrmNkYNdwEOpdKOgi4RtIi4O5q1V6U8Y2rIuLSWis0s8YYdvwhIt4MzAYWUe6jugclOI6NCB8hMesh2TM9rwKuqrkWM2s4H+Ews7RG33l9wq9XMf3k+d0uwzbSdQ/+otsl2Eaa8apVA7a7h2FmaQ4MM0tzYJhZ2qBjGJLmZd8kIt7amXLMrMmGGvR8dtvzA4F1wB3V8z+n9FBuqaEuM2ugQQMjIo7ofyzpDOBx4PiIWFW1TaKcFn7HwO9gZmNNdgzjVGBuf1gAVI/PBU6pozAza55sYGzNwLcT2AmY2LlyzKzJsoFxNfAFSbMlTa2W2ZRdkq/WV56ZNUn2TM93Ap8ALgPGVW1PUQJjTufLMrMmyl589jjwLkn/yPop+e5tHdMws7FvpCduPaNaFjkszHpPKjCq+5P8J7Ac+BHlLu5I+pykufWVZ2ZNku1hnEc5SrIP5XyMft8Cjux0UWbWTNlBz9cCR0bELyRFS/tCYLfOl2VmTZTtYWwL/HaA9mcCaztXjpk1WTYwbqP0Mvr19zLeQRnTMLMekN0l+QBwvaQXVa85rXo8g3JRmpn1gFQPIyJ+BLwcGA/cCxwCPAi8LCJ+Vl95ZtYk6Tk9I+IO4O9qrMXMGi57HsZaSRvcY1XS9pI86GnWI7KDnhqkfQKwpkO1mFnDDblLIum06mEAJ0la2bK6D/gr1t8+0czGuOHGMPonxxHwNp5+zsUa4D7gpM6XZWZNNNzNmKcBSLoZmBURvx+VqsyskbJHSWYywDiGpK2AdRHhcQyzHpAd9LwKeNcA7SfhmzSb9YxsYBwA/NcA7d+lnNBlZj0gGxgTKVPytVtHuQDNzHpANjBuB44doP2NwJ2dK8fMmiw76HkO8HVJuwM3VW2HAEfjCXTMekb24rNrgSOAKcCnq2Uy8NqI+FZ95ZlZk4zk4rPrgOtqrMXMGm6ks4abWQ8btIch6TFgt4h4RNIK1s+ytYGI2KaO4sysWYbaJTkFWFE9PnkUajGzhhs0MCLi3wd6bGa9y2MYZpY21BjGOoYYt2gVEX0dq8jMGmuoMYxjWB8YO1JO3roGuLVqexnweuCsuoozs2YZagzjK/2PJX0DOCMiLmnZZJ6kn1BC44LaKjSzxsiOYRwM3DxA+83AQR2rxswaLRsYjwBHDdB+FPBw58oxsybLnhr+IeALkv6a9WMY+wOvBE6oozAza55UYETEFyUtAk5l/T1WFwIHRMT8uoozs2YZycVn84E31ViLmTVc+sQtSTtKmiPpAkk7VG0HSJpWX3lm1iTZWyXuCyyi9DDeBvRfbHYo8C/1lGZmTZPtYXwc+FRE/AXwREv79ZQJgs2sB2QDY19goAvQHqKcBWpmPSAbGI8D2w7QviewvHPlmFmTZQPj68BZkiZUz0PSVOA84Oo6CjOz5skGxhxgO8pZnROBHwCLgUeBD2beQNI8Scsl+bYEZpup7HkYT1GuGTkQ2IcSND+LiBtG8FmXAecDXxzBa8ysQYYNDEl9wB+Al0TETay/L8mIRMQt1W6MmW2mht0liYi1wP3A+PrLMbMmy45hnAt8pP8MzzpJOlHSAkkLnnzaKR9m1m3ZMYw5wDRgmaSlwKrWlRGxd6cKioiLgYsBttF2qSkCzWx0ZAPjapLze5rZ2JW9vH3upn6QpC9TjrTsUPVSzoqIz2/q+5rZ6BkyMCRNBD5GmbdzHHADcGpEPDLSD4qIYzemQDNrjuEGPc8GjgO+DVxJuTr1wpprMrOGGm6XZBZwQkRcCSDpcuCHkvqqw61m1kOG62HsCny//0lE/IRy1ufOdRZlZs00XGD0AWva2p5iBFP7mdnYMdwXX8DlklrPoNoKuETSH/sbIuK1G7zSzMac4QJjoElzLq+jEDNrviEDIyKOH61CzKz50rOGm5k5MMwszYFhZmkODDNLc2CYWZoDw8zSHBhmlubAMLM0B4aZpTkwzCzNgWFmaQ4MM0tzYJhZmgPDzNIcGGaW5sAwszQHhpmlOTDMLM2BYWZpDgwzS3NgmFmaA8PM0hwYZpbmwDCzNAeGmaU5MMwszYFhZmkODDNLc2CYWZoDw8zSHBhmlubAMLM0B4aZpTkwzCzNgWFmaQ4MM0tzYJhZmgPDzNIcGGaW5sAwszQHhpmlOTDMLM2BYWZpiohu1zAoSQ8D93e7jprsADzS7SJso43139+UiHh2e2OjA2Msk7QgIl7a7Tps4/Tq78+7JGaW5sAwszQHRvdc3O0CbJP05O/PYxhmluYehpmlOTDMLM2BYWZpDgwzS3NgmFna/wPZZsiO8kp3agAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       649\n",
      "           1       0.98      0.96      0.97      1231\n",
      "\n",
      "    accuracy                           0.96      1880\n",
      "   macro avg       0.96      0.96      0.96      1880\n",
      "weighted avg       0.96      0.96      0.96      1880\n",
      "\n",
      "59/59 - 0s - loss: 0.1292 - accuracy: 0.9559 - 95ms/epoch - 2ms/step\n",
      "Test Loss: 0.1292363703250885\n",
      "Test Accuracy: 0.9558510780334473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       664\n",
      "           1       0.97      0.96      0.97      1216\n",
      "\n",
      "    accuracy                           0.96      1880\n",
      "   macro avg       0.95      0.95      0.95      1880\n",
      "weighted avg       0.96      0.96      0.96      1880\n",
      "\n",
      "59/59 - 0s - loss: 0.1776 - accuracy: 0.9362 - 119ms/epoch - 2ms/step\n",
      "Test Loss: 0.1776052564382553\n",
      "Test Accuracy: 0.936170220375061\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.92       747\n",
      "           1       0.92      0.98      0.95      1133\n",
      "\n",
      "    accuracy                           0.94      1880\n",
      "   macro avg       0.94      0.93      0.93      1880\n",
      "weighted avg       0.94      0.94      0.94      1880\n",
      "\n",
      "59/59 - 0s - loss: 0.1303 - accuracy: 0.9569 - 91ms/epoch - 2ms/step\n",
      "Test Loss: 0.13033001124858856\n",
      "Test Accuracy: 0.9569149017333984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       672\n",
      "           1       0.97      0.97      0.97      1208\n",
      "\n",
      "    accuracy                           0.96      1880\n",
      "   macro avg       0.95      0.95      0.95      1880\n",
      "weighted avg       0.96      0.96      0.96      1880\n",
      "\n",
      "59/59 - 0s - loss: 0.1328 - accuracy: 0.9559 - 92ms/epoch - 2ms/step\n",
      "Test Loss: 0.13281965255737305\n",
      "Test Accuracy: 0.9558510780334473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       650\n",
      "           1       0.98      0.96      0.97      1230\n",
      "\n",
      "    accuracy                           0.96      1880\n",
      "   macro avg       0.95      0.96      0.95      1880\n",
      "weighted avg       0.96      0.96      0.96      1880\n",
      "\n",
      "59/59 - 0s - loss: 0.1342 - accuracy: 0.9559 - 89ms/epoch - 2ms/step\n",
      "Test Loss: 0.13416001200675964\n",
      "Test Accuracy: 0.9558510780334473\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       676\n",
      "           1       0.97      0.97      0.97      1204\n",
      "\n",
      "    accuracy                           0.96      1880\n",
      "   macro avg       0.95      0.95      0.95      1880\n",
      "weighted avg       0.96      0.96      0.96      1880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in ms:\n",
    "    test_loss, test_acc = m.evaluate(X_test,  y_test, verbose=2)\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "    y_pred = np.argmax(m.predict(X_test), axis=-1)\n",
    "    plt.matshow(confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "    plt.ylabel(\"Predicted Category\", fontsize=14)\n",
    "    plt.title(\"Category\", fontsize=14)\n",
    "    plt.show()\n",
    "    print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1125818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(hs)):\n",
    "    plt.plot(hs[i].history['accuracy'], label='accuracy')\n",
    "    plt.plot(hs[i].history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    print(\"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d629fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df= pd.read_csv('../feature_data/features.csv')\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X = df.drop([\"label\"],axis=1)\n",
    "X = X.drop([\"radius\"],axis=1)\n",
    "cols = X.keys()\n",
    "\n",
    "#normalize data\n",
    "X = preprocessing.normalize(X, norm='max')\n",
    "\n",
    "#labels\n",
    "y = df[\"label\"]\n",
    "#idx = y == 0\n",
    "#y[idx]=-1\n",
    "\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "X['label'] = y\n",
    "\n",
    "#features\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size= 0.3)\n",
    "\n",
    "\n",
    "from sklearn.svm import OneClassSVM,SVC\n",
    "\n",
    "rf= SVC(kernel = \"poly\", C=2000,verbose=True)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "predictions= rf.predict(X_test)\n",
    "print(predictions[0:10])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
