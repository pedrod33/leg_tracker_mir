{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7b81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:25:22.855988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 11:25:22.856010: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffe36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.read_csv('../feature_data/features.csv')\n",
    "allData.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "allData = allData.dropna()\n",
    "X = allData.drop([\"label\"],axis=1)\n",
    "X = X.drop([\"radius\"],axis=1)\n",
    "cols = X.keys()\n",
    "\n",
    "#normalize data\n",
    "X = preprocessing.normalize(X, norm='max')\n",
    "\n",
    "#labels\n",
    "y = allData[\"label\"]\n",
    "\n",
    "#features\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "X['label'] = y\n",
    "\n",
    "\n",
    "X = pd.DataFrame(X, columns = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e958f63c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_points</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_median_dev</th>\n",
       "      <th>width</th>\n",
       "      <th>linearity</th>\n",
       "      <th>circularity</th>\n",
       "      <th>boundary_length</th>\n",
       "      <th>boundary_regularity</th>\n",
       "      <th>mean_curvature</th>\n",
       "      <th>ang_diff</th>\n",
       "      <th>iav</th>\n",
       "      <th>std_iav</th>\n",
       "      <th>distance</th>\n",
       "      <th>dist_num_points</th>\n",
       "      <th>occluded_right</th>\n",
       "      <th>occluded_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9.489000e+03</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "      <td>9489.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.080554</td>\n",
       "      <td>1.073564e-03</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.746893</td>\n",
       "      <td>0.131135</td>\n",
       "      <td>0.155018</td>\n",
       "      <td>0.123128</td>\n",
       "      <td>0.264434</td>\n",
       "      <td>0.053376</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.044787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.301662</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.017596</td>\n",
       "      <td>0.216024</td>\n",
       "      <td>4.462697e-03</td>\n",
       "      <td>0.018928</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.356924</td>\n",
       "      <td>0.085117</td>\n",
       "      <td>0.096798</td>\n",
       "      <td>0.118237</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>0.089121</td>\n",
       "      <td>0.056148</td>\n",
       "      <td>0.053842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.989823e-16</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.324496</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>8.500852e-06</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.077845</td>\n",
       "      <td>0.037257</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.515469</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>3.110597e-05</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>0.136684</td>\n",
       "      <td>0.074860</td>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.033159</td>\n",
       "      <td>0.027403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>2.910429e-04</td>\n",
       "      <td>0.032701</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179543</td>\n",
       "      <td>0.211140</td>\n",
       "      <td>0.182841</td>\n",
       "      <td>0.375337</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>0.072341</td>\n",
       "      <td>0.061478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>0.029587</td>\n",
       "      <td>0.096485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.014070e-01</td>\n",
       "      <td>0.100089</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448640</td>\n",
       "      <td>0.663490</td>\n",
       "      <td>0.792277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_points          std  avg_median_dev        width    linearity  \\\n",
       "count  9489.000000  9489.000000     9489.000000  9489.000000  9489.000000   \n",
       "mean      0.591876     0.006595        0.005354     0.018044     0.080554   \n",
       "std       0.301662     0.006057        0.004928     0.017596     0.216024   \n",
       "min       0.013108     0.000091        0.000083     0.000258     0.000003   \n",
       "25%       0.324496     0.001434        0.001189     0.003823     0.000417   \n",
       "50%       0.515469     0.004599        0.003765     0.011499     0.001413   \n",
       "75%       1.000000     0.010100        0.007916     0.026915     0.035819   \n",
       "max       1.000000     0.037908        0.029587     0.096485     1.000000   \n",
       "\n",
       "        circularity  boundary_length  boundary_regularity  mean_curvature  \\\n",
       "count  9.489000e+03      9489.000000          9489.000000     9489.000000   \n",
       "mean   1.073564e-03         0.021039             0.001622        0.746893   \n",
       "std    4.462697e-03         0.018928             0.002130        0.356924   \n",
       "min    2.989823e-16         0.000450             0.000004        0.001178   \n",
       "25%    8.500852e-06         0.005043             0.000228        0.410400   \n",
       "50%    3.110597e-05         0.014725             0.000697        1.000000   \n",
       "75%    2.910429e-04         0.032701             0.002027        1.000000   \n",
       "max    1.014070e-01         0.100089             0.019309        1.000000   \n",
       "\n",
       "          ang_diff          iav      std_iav     distance  dist_num_points  \\\n",
       "count  9489.000000  9489.000000  9489.000000  9489.000000      9489.000000   \n",
       "mean      0.131135     0.155018     0.123128     0.264434         0.053376   \n",
       "std       0.085117     0.096798     0.118237     0.311487         0.089121   \n",
       "min       0.000784     0.000784     0.000072     0.000755         0.000003   \n",
       "25%       0.064074     0.077845     0.037257     0.041221         0.002814   \n",
       "50%       0.109722     0.136684     0.074860     0.114122         0.011405   \n",
       "75%       0.179543     0.211140     0.182841     0.375337         0.057234   \n",
       "max       0.448640     0.663490     0.792277     1.000000         0.333334   \n",
       "\n",
       "       occluded_right  occluded_left  \n",
       "count     9489.000000    9489.000000  \n",
       "mean         0.051616       0.044787  \n",
       "std          0.056148       0.053842  \n",
       "min          0.000000       0.000000  \n",
       "25%          0.012499       0.000000  \n",
       "50%          0.033159       0.027403  \n",
       "75%          0.072341       0.061478  \n",
       "max          0.333333       0.333333  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253c70ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "y_train.value_counts().plot.bar()\n",
    "\n",
    "\n",
    "#oversample the minority\n",
    "ros = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "addcb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(filters1 = 32, filters2=64, kernel_size=3,strides=1, pool_size=4, optimizer = 'adam'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=filters1, kernel_size=kernel_size, strides=strides, activation='relu',input_shape=(16,1)))\n",
    "    model.add(layers.MaxPooling1D(pool_size=pool_size,strides=strides))\n",
    "    model.add(layers.Conv1D(filters=filters2, kernel_size=kernel_size, strides=strides, activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(2))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a4b65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 11, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 8, 64)             16448     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                16416     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,250\n",
      "Trainable params: 33,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:25:34.812936: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-08 11:25:34.812982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pedrod33): /proc/driver/nvidia/version does not exist\n",
      "2023-03-08 11:25:34.814517: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.8786 - val_loss: 0.2093 - val_accuracy: 0.9162\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9134 - val_loss: 0.1818 - val_accuracy: 0.9231\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1781 - accuracy: 0.9231 - val_loss: 0.1577 - val_accuracy: 0.9415\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9297 - val_loss: 0.1344 - val_accuracy: 0.9399\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9318 - val_loss: 0.1298 - val_accuracy: 0.9463\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1415 - accuracy: 0.9367 - val_loss: 0.1231 - val_accuracy: 0.9536\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9375 - val_loss: 0.1174 - val_accuracy: 0.9510\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1378 - accuracy: 0.9388 - val_loss: 0.1178 - val_accuracy: 0.9531\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1329 - accuracy: 0.9444 - val_loss: 0.1109 - val_accuracy: 0.9579\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9461 - val_loss: 0.1162 - val_accuracy: 0.9531\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.9463 - val_loss: 0.1282 - val_accuracy: 0.9478\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1314 - accuracy: 0.9443 - val_loss: 0.1225 - val_accuracy: 0.9605\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9481 - val_loss: 0.1051 - val_accuracy: 0.9610\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9498 - val_loss: 0.1180 - val_accuracy: 0.9526\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9471 - val_loss: 0.1028 - val_accuracy: 0.9631\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9504 - val_loss: 0.1389 - val_accuracy: 0.9426\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9451 - val_loss: 0.1052 - val_accuracy: 0.9610\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1232 - accuracy: 0.9504 - val_loss: 0.1092 - val_accuracy: 0.9584\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.1163 - val_accuracy: 0.9573\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9484 - val_loss: 0.1143 - val_accuracy: 0.9579\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9524 - val_loss: 0.1092 - val_accuracy: 0.9600\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1179 - accuracy: 0.9526 - val_loss: 0.0993 - val_accuracy: 0.9626\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1205 - accuracy: 0.9498 - val_loss: 0.1022 - val_accuracy: 0.9605\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1205 - accuracy: 0.9507 - val_loss: 0.1250 - val_accuracy: 0.9563\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1180 - accuracy: 0.9496 - val_loss: 0.1174 - val_accuracy: 0.9505\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9486 - val_loss: 0.1038 - val_accuracy: 0.9600\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.9517 - val_loss: 0.1220 - val_accuracy: 0.9484\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1153 - accuracy: 0.9521 - val_loss: 0.1022 - val_accuracy: 0.9610\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9521 - val_loss: 0.1005 - val_accuracy: 0.9610\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1169 - accuracy: 0.9502 - val_loss: 0.1084 - val_accuracy: 0.9589\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1156 - accuracy: 0.9507 - val_loss: 0.0990 - val_accuracy: 0.9610\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9517 - val_loss: 0.1017 - val_accuracy: 0.9542\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9529 - val_loss: 0.0995 - val_accuracy: 0.9600\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9509 - val_loss: 0.0960 - val_accuracy: 0.9615\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1121 - accuracy: 0.9539 - val_loss: 0.0971 - val_accuracy: 0.9631\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9512 - val_loss: 0.1048 - val_accuracy: 0.9557\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9509 - val_loss: 0.0965 - val_accuracy: 0.9600\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9534 - val_loss: 0.1114 - val_accuracy: 0.9642\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9511 - val_loss: 0.0970 - val_accuracy: 0.9605\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9489 - val_loss: 0.0980 - val_accuracy: 0.9605\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9536 - val_loss: 0.0967 - val_accuracy: 0.9615\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9541 - val_loss: 0.0969 - val_accuracy: 0.9636\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9502 - val_loss: 0.0985 - val_accuracy: 0.9621\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9516 - val_loss: 0.1230 - val_accuracy: 0.9499\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1087 - accuracy: 0.9532 - val_loss: 0.0962 - val_accuracy: 0.9605\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1086 - accuracy: 0.9547 - val_loss: 0.0953 - val_accuracy: 0.9626\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9534 - val_loss: 0.0924 - val_accuracy: 0.9642\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9559 - val_loss: 0.0942 - val_accuracy: 0.9579\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9537 - val_loss: 0.0915 - val_accuracy: 0.9631\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1048 - accuracy: 0.9559 - val_loss: 0.0972 - val_accuracy: 0.9647\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9539 - val_loss: 0.0949 - val_accuracy: 0.9642\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1060 - accuracy: 0.9562 - val_loss: 0.1177 - val_accuracy: 0.9463\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1081 - accuracy: 0.9539 - val_loss: 0.1007 - val_accuracy: 0.9610\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1038 - accuracy: 0.9531 - val_loss: 0.0900 - val_accuracy: 0.9663\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9531 - val_loss: 0.0989 - val_accuracy: 0.9684\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9557 - val_loss: 0.1018 - val_accuracy: 0.9515\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9532 - val_loss: 0.0958 - val_accuracy: 0.9615\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9542 - val_loss: 0.0951 - val_accuracy: 0.9589\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9569 - val_loss: 0.1082 - val_accuracy: 0.9615\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9527 - val_loss: 0.0899 - val_accuracy: 0.9663\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9579 - val_loss: 0.0988 - val_accuracy: 0.9647\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9556 - val_loss: 0.0944 - val_accuracy: 0.9579\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9582 - val_loss: 0.1009 - val_accuracy: 0.9589\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9531 - val_loss: 0.1005 - val_accuracy: 0.9631\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1022 - accuracy: 0.9549 - val_loss: 0.0950 - val_accuracy: 0.9636\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9542 - val_loss: 0.0956 - val_accuracy: 0.9626\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1003 - accuracy: 0.9564 - val_loss: 0.0929 - val_accuracy: 0.9631\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9551 - val_loss: 0.0981 - val_accuracy: 0.9642\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9584 - val_loss: 0.0900 - val_accuracy: 0.9663\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9575 - val_loss: 0.0989 - val_accuracy: 0.9600\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9575 - val_loss: 0.0937 - val_accuracy: 0.9626\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9579 - val_loss: 0.0913 - val_accuracy: 0.9658\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9574 - val_loss: 0.0996 - val_accuracy: 0.9573\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9567 - val_loss: 0.0945 - val_accuracy: 0.9673\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9579 - val_loss: 0.0906 - val_accuracy: 0.9658\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9575 - val_loss: 0.0890 - val_accuracy: 0.9652\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9572 - val_loss: 0.0942 - val_accuracy: 0.9668\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9580 - val_loss: 0.0925 - val_accuracy: 0.9652\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9574 - val_loss: 0.0904 - val_accuracy: 0.9668\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9577 - val_loss: 0.1037 - val_accuracy: 0.9668\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9570 - val_loss: 0.0904 - val_accuracy: 0.9636\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9589 - val_loss: 0.0913 - val_accuracy: 0.9647\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9572 - val_loss: 0.0873 - val_accuracy: 0.9684\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9575 - val_loss: 0.0891 - val_accuracy: 0.9647\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9579 - val_loss: 0.0915 - val_accuracy: 0.9647\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9585 - val_loss: 0.0932 - val_accuracy: 0.9663\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9582 - val_loss: 0.0960 - val_accuracy: 0.9636\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9566 - val_loss: 0.0892 - val_accuracy: 0.9658\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9587 - val_loss: 0.0890 - val_accuracy: 0.9658\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9600 - val_loss: 0.0929 - val_accuracy: 0.9652\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9575 - val_loss: 0.0902 - val_accuracy: 0.9694\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9622 - val_loss: 0.0941 - val_accuracy: 0.9615\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9597 - val_loss: 0.1006 - val_accuracy: 0.9584\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9585 - val_loss: 0.0919 - val_accuracy: 0.9642\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9622 - val_loss: 0.1082 - val_accuracy: 0.9579\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9589 - val_loss: 0.0878 - val_accuracy: 0.9668\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9619 - val_loss: 0.0900 - val_accuracy: 0.9647\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9589 - val_loss: 0.0898 - val_accuracy: 0.9642\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9600 - val_loss: 0.0935 - val_accuracy: 0.9589\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9590 - val_loss: 0.0893 - val_accuracy: 0.9668\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9615 - val_loss: 0.0890 - val_accuracy: 0.9658\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9624 - val_loss: 0.0927 - val_accuracy: 0.9642\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9602 - val_loss: 0.0942 - val_accuracy: 0.9642\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9590 - val_loss: 0.0941 - val_accuracy: 0.9636\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0942 - accuracy: 0.9595 - val_loss: 0.0901 - val_accuracy: 0.9647\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9607 - val_loss: 0.0901 - val_accuracy: 0.9668\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9624 - val_loss: 0.0944 - val_accuracy: 0.9589\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0897 - accuracy: 0.9627 - val_loss: 0.0964 - val_accuracy: 0.9631\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9627 - val_loss: 0.1017 - val_accuracy: 0.9584\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9630 - val_loss: 0.0939 - val_accuracy: 0.9642\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9615 - val_loss: 0.0948 - val_accuracy: 0.9615\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0922 - accuracy: 0.9605 - val_loss: 0.0899 - val_accuracy: 0.9658\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9610 - val_loss: 0.0933 - val_accuracy: 0.9636\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9597 - val_loss: 0.0952 - val_accuracy: 0.9621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9614 - val_loss: 0.0928 - val_accuracy: 0.9642\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9627 - val_loss: 0.0936 - val_accuracy: 0.9626\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9622 - val_loss: 0.0917 - val_accuracy: 0.9652\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9642 - val_loss: 0.0955 - val_accuracy: 0.9642\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9638 - val_loss: 0.0998 - val_accuracy: 0.9626\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9624 - val_loss: 0.0887 - val_accuracy: 0.9652\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9625 - val_loss: 0.1422 - val_accuracy: 0.9473\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9602 - val_loss: 0.0983 - val_accuracy: 0.9652\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9637 - val_loss: 0.1041 - val_accuracy: 0.9568\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9635 - val_loss: 0.1129 - val_accuracy: 0.9600\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0882 - accuracy: 0.9615 - val_loss: 0.1041 - val_accuracy: 0.9557\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0851 - accuracy: 0.9647 - val_loss: 0.0945 - val_accuracy: 0.9647\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9657 - val_loss: 0.0884 - val_accuracy: 0.9679\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9633 - val_loss: 0.0911 - val_accuracy: 0.9658\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0822 - accuracy: 0.9653 - val_loss: 0.0925 - val_accuracy: 0.9652\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9647 - val_loss: 0.0893 - val_accuracy: 0.9663\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9638 - val_loss: 0.0971 - val_accuracy: 0.9642\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.0903 - val_accuracy: 0.9647\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9658 - val_loss: 0.0942 - val_accuracy: 0.9647\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0822 - accuracy: 0.9667 - val_loss: 0.0875 - val_accuracy: 0.9663\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9650 - val_loss: 0.0901 - val_accuracy: 0.9673\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.0893 - val_accuracy: 0.9668\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9629 - val_loss: 0.1004 - val_accuracy: 0.9658\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0851 - accuracy: 0.9647 - val_loss: 0.0903 - val_accuracy: 0.9689\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9658 - val_loss: 0.0945 - val_accuracy: 0.9652\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.0840 - accuracy: 0.9672 - val_loss: 0.0911 - val_accuracy: 0.9647\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0804 - accuracy: 0.9690 - val_loss: 0.0936 - val_accuracy: 0.9631\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0776 - accuracy: 0.9668 - val_loss: 0.0894 - val_accuracy: 0.9636\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0806 - accuracy: 0.9652 - val_loss: 0.0915 - val_accuracy: 0.9642\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9665 - val_loss: 0.0963 - val_accuracy: 0.9621\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9675 - val_loss: 0.0933 - val_accuracy: 0.9636\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0754 - accuracy: 0.9680 - val_loss: 0.1010 - val_accuracy: 0.9621\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9672 - val_loss: 0.0930 - val_accuracy: 0.9631\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9675 - val_loss: 0.0965 - val_accuracy: 0.9658\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9670 - val_loss: 0.0983 - val_accuracy: 0.9647\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0761 - accuracy: 0.9660 - val_loss: 0.0974 - val_accuracy: 0.9642\n",
      "6\n",
      "1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 9, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 4, 64)             24640     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,378\n",
      "Trainable params: 33,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.3005 - accuracy: 0.8776 - val_loss: 0.2463 - val_accuracy: 0.8941\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9128 - val_loss: 0.1635 - val_accuracy: 0.9294\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9232 - val_loss: 0.1520 - val_accuracy: 0.9378\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9294 - val_loss: 0.1326 - val_accuracy: 0.9436\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9307 - val_loss: 0.1436 - val_accuracy: 0.9378\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9328 - val_loss: 0.1322 - val_accuracy: 0.9436\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9355 - val_loss: 0.1437 - val_accuracy: 0.9378\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9340 - val_loss: 0.1237 - val_accuracy: 0.9510\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9355 - val_loss: 0.1320 - val_accuracy: 0.9431\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1344 - accuracy: 0.9411 - val_loss: 0.1277 - val_accuracy: 0.9499\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9434 - val_loss: 0.1316 - val_accuracy: 0.9426\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9438 - val_loss: 0.1144 - val_accuracy: 0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9443 - val_loss: 0.1287 - val_accuracy: 0.9542\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9430 - val_loss: 0.1103 - val_accuracy: 0.9584\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9444 - val_loss: 0.1159 - val_accuracy: 0.9589\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9410 - val_loss: 0.1100 - val_accuracy: 0.9573\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1261 - accuracy: 0.9449 - val_loss: 0.1446 - val_accuracy: 0.9394\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9469 - val_loss: 0.1215 - val_accuracy: 0.9463\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9461 - val_loss: 0.1245 - val_accuracy: 0.9457\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9476 - val_loss: 0.1166 - val_accuracy: 0.9631\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9494 - val_loss: 0.1068 - val_accuracy: 0.9652\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9474 - val_loss: 0.1041 - val_accuracy: 0.9579\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9517 - val_loss: 0.1040 - val_accuracy: 0.9600\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1162 - accuracy: 0.9501 - val_loss: 0.1034 - val_accuracy: 0.9636\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9489 - val_loss: 0.1043 - val_accuracy: 0.9594\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9486 - val_loss: 0.1176 - val_accuracy: 0.9442\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9504 - val_loss: 0.1347 - val_accuracy: 0.9505\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.9488 - val_loss: 0.1119 - val_accuracy: 0.9636\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9504 - val_loss: 0.0982 - val_accuracy: 0.9642\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9514 - val_loss: 0.1000 - val_accuracy: 0.9668\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9519 - val_loss: 0.1122 - val_accuracy: 0.9505\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1109 - accuracy: 0.9512 - val_loss: 0.1012 - val_accuracy: 0.9642\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9531 - val_loss: 0.0994 - val_accuracy: 0.9584\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9532 - val_loss: 0.0976 - val_accuracy: 0.9658\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9521 - val_loss: 0.1054 - val_accuracy: 0.9658\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9519 - val_loss: 0.1104 - val_accuracy: 0.9526\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9557 - val_loss: 0.0982 - val_accuracy: 0.9584\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9544 - val_loss: 0.1041 - val_accuracy: 0.9542\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9541 - val_loss: 0.0924 - val_accuracy: 0.9673\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1046 - accuracy: 0.9574 - val_loss: 0.0955 - val_accuracy: 0.9600\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9551 - val_loss: 0.1081 - val_accuracy: 0.9584\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9552 - val_loss: 0.1028 - val_accuracy: 0.9684\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9554 - val_loss: 0.1030 - val_accuracy: 0.9652\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9577 - val_loss: 0.0966 - val_accuracy: 0.9636\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1019 - accuracy: 0.9544 - val_loss: 0.0929 - val_accuracy: 0.9705\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9529 - val_loss: 0.0937 - val_accuracy: 0.9636\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9567 - val_loss: 0.0954 - val_accuracy: 0.9631\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9569 - val_loss: 0.1019 - val_accuracy: 0.9584\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1006 - accuracy: 0.9584 - val_loss: 0.0953 - val_accuracy: 0.9694\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9574 - val_loss: 0.0925 - val_accuracy: 0.9679\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9597 - val_loss: 0.0930 - val_accuracy: 0.9668\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9592 - val_loss: 0.0921 - val_accuracy: 0.9684\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9610 - val_loss: 0.0949 - val_accuracy: 0.9668\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9585 - val_loss: 0.0928 - val_accuracy: 0.9684\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9590 - val_loss: 0.0922 - val_accuracy: 0.9673\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0944 - accuracy: 0.9589 - val_loss: 0.1007 - val_accuracy: 0.9700\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9599 - val_loss: 0.0959 - val_accuracy: 0.9642\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9607 - val_loss: 0.0968 - val_accuracy: 0.9668\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.9620 - val_loss: 0.1030 - val_accuracy: 0.9673\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9607 - val_loss: 0.0968 - val_accuracy: 0.9652\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0930 - accuracy: 0.9595 - val_loss: 0.0984 - val_accuracy: 0.9658\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0934 - accuracy: 0.9614 - val_loss: 0.1009 - val_accuracy: 0.9642\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9577 - val_loss: 0.0959 - val_accuracy: 0.9663\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9625 - val_loss: 0.0920 - val_accuracy: 0.9647\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9617 - val_loss: 0.0939 - val_accuracy: 0.9684\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9627 - val_loss: 0.1012 - val_accuracy: 0.9631\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9633 - val_loss: 0.1041 - val_accuracy: 0.9605\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9619 - val_loss: 0.0985 - val_accuracy: 0.9652\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9645 - val_loss: 0.0990 - val_accuracy: 0.9652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9630 - val_loss: 0.0944 - val_accuracy: 0.9658\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9663 - val_loss: 0.0993 - val_accuracy: 0.9668\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9645 - val_loss: 0.0925 - val_accuracy: 0.9658\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9662 - val_loss: 0.0954 - val_accuracy: 0.9621\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9635 - val_loss: 0.1010 - val_accuracy: 0.9668\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9662 - val_loss: 0.0942 - val_accuracy: 0.9636\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0887 - accuracy: 0.9657 - val_loss: 0.0941 - val_accuracy: 0.9694\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9668 - val_loss: 0.0939 - val_accuracy: 0.9668\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0841 - accuracy: 0.9657 - val_loss: 0.1007 - val_accuracy: 0.9626\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9665 - val_loss: 0.1370 - val_accuracy: 0.9505\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9647 - val_loss: 0.1027 - val_accuracy: 0.9663\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9645 - val_loss: 0.0957 - val_accuracy: 0.9663\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9650 - val_loss: 0.1066 - val_accuracy: 0.9684\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0813 - accuracy: 0.9680 - val_loss: 0.1055 - val_accuracy: 0.9652\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9662 - val_loss: 0.1070 - val_accuracy: 0.9668\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9677 - val_loss: 0.1006 - val_accuracy: 0.9652\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0837 - accuracy: 0.9652 - val_loss: 0.0989 - val_accuracy: 0.9631\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0805 - accuracy: 0.9662 - val_loss: 0.1073 - val_accuracy: 0.9679\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9678 - val_loss: 0.1031 - val_accuracy: 0.9652\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9675 - val_loss: 0.0967 - val_accuracy: 0.9642\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9690 - val_loss: 0.1013 - val_accuracy: 0.9673\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9690 - val_loss: 0.0963 - val_accuracy: 0.9668\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9687 - val_loss: 0.1030 - val_accuracy: 0.9647\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9680 - val_loss: 0.1014 - val_accuracy: 0.9673\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0761 - accuracy: 0.9692 - val_loss: 0.1058 - val_accuracy: 0.9647\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9718 - val_loss: 0.1099 - val_accuracy: 0.9663\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9690 - val_loss: 0.1107 - val_accuracy: 0.9652\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9690 - val_loss: 0.1091 - val_accuracy: 0.9594\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9708 - val_loss: 0.1091 - val_accuracy: 0.9642\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9715 - val_loss: 0.1143 - val_accuracy: 0.9605\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9682 - val_loss: 0.1101 - val_accuracy: 0.9626\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9715 - val_loss: 0.1093 - val_accuracy: 0.9652\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0714 - accuracy: 0.9713 - val_loss: 0.1034 - val_accuracy: 0.9636\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9678 - val_loss: 0.1092 - val_accuracy: 0.9642\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9711 - val_loss: 0.1126 - val_accuracy: 0.9615\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9700 - val_loss: 0.1080 - val_accuracy: 0.9568\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9705 - val_loss: 0.1079 - val_accuracy: 0.9652\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9710 - val_loss: 0.1209 - val_accuracy: 0.9579\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9708 - val_loss: 0.1129 - val_accuracy: 0.9668\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9720 - val_loss: 0.1086 - val_accuracy: 0.9663\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.9718 - val_loss: 0.1059 - val_accuracy: 0.9673\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9726 - val_loss: 0.1075 - val_accuracy: 0.9631\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9743 - val_loss: 0.1077 - val_accuracy: 0.9684\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9735 - val_loss: 0.1202 - val_accuracy: 0.9621\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9718 - val_loss: 0.1141 - val_accuracy: 0.9668\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9720 - val_loss: 0.1218 - val_accuracy: 0.9621\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9753 - val_loss: 0.1179 - val_accuracy: 0.9568\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.9731 - val_loss: 0.1084 - val_accuracy: 0.9610\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0669 - accuracy: 0.9710 - val_loss: 0.1103 - val_accuracy: 0.9673\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9745 - val_loss: 0.1154 - val_accuracy: 0.9663\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0662 - accuracy: 0.9728 - val_loss: 0.1259 - val_accuracy: 0.9626\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9753 - val_loss: 0.1179 - val_accuracy: 0.9668\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0693 - accuracy: 0.9693 - val_loss: 0.1129 - val_accuracy: 0.9647\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9730 - val_loss: 0.1142 - val_accuracy: 0.9605\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9758 - val_loss: 0.1199 - val_accuracy: 0.9673\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9731 - val_loss: 0.1120 - val_accuracy: 0.9647\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9746 - val_loss: 0.1198 - val_accuracy: 0.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9738 - val_loss: 0.1297 - val_accuracy: 0.9615\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9718 - val_loss: 0.1205 - val_accuracy: 0.9658\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9728 - val_loss: 0.1276 - val_accuracy: 0.9610\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9741 - val_loss: 0.1232 - val_accuracy: 0.9600\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9731 - val_loss: 0.1173 - val_accuracy: 0.9642\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0662 - accuracy: 0.9721 - val_loss: 0.1128 - val_accuracy: 0.9663\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9756 - val_loss: 0.1244 - val_accuracy: 0.9642\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9758 - val_loss: 0.1192 - val_accuracy: 0.9642\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9738 - val_loss: 0.1260 - val_accuracy: 0.9626\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9743 - val_loss: 0.1192 - val_accuracy: 0.9658\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0625 - accuracy: 0.9750 - val_loss: 0.1216 - val_accuracy: 0.9679\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9741 - val_loss: 0.1179 - val_accuracy: 0.9647\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0581 - accuracy: 0.9776 - val_loss: 0.1179 - val_accuracy: 0.9684\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9763 - val_loss: 0.1294 - val_accuracy: 0.9668\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0630 - accuracy: 0.9746 - val_loss: 0.1131 - val_accuracy: 0.9679\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0564 - accuracy: 0.9769 - val_loss: 0.1214 - val_accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0628 - accuracy: 0.9748 - val_loss: 0.1170 - val_accuracy: 0.9652\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.1176 - val_accuracy: 0.9663\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9788 - val_loss: 0.1199 - val_accuracy: 0.9663\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0583 - accuracy: 0.9769 - val_loss: 0.1429 - val_accuracy: 0.9579\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0595 - accuracy: 0.9736 - val_loss: 0.1259 - val_accuracy: 0.9647\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9783 - val_loss: 0.1285 - val_accuracy: 0.9589\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 0.1295 - val_accuracy: 0.9626\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9784 - val_loss: 0.1258 - val_accuracy: 0.9621\n",
      "4\n",
      "1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 7, 64)             16448     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 448)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                14368     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,202\n",
      "Trainable params: 31,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 8ms/step - loss: 0.3222 - accuracy: 0.8620 - val_loss: 0.2175 - val_accuracy: 0.9094\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9124 - val_loss: 0.1861 - val_accuracy: 0.9294\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1890 - accuracy: 0.9226 - val_loss: 0.1557 - val_accuracy: 0.9299\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1689 - accuracy: 0.9249 - val_loss: 0.1940 - val_accuracy: 0.9220\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1605 - accuracy: 0.9294 - val_loss: 0.1626 - val_accuracy: 0.9373\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9302 - val_loss: 0.1391 - val_accuracy: 0.9410\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1510 - accuracy: 0.9320 - val_loss: 0.1400 - val_accuracy: 0.9352\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1485 - accuracy: 0.9355 - val_loss: 0.1321 - val_accuracy: 0.9399\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.9335 - val_loss: 0.1304 - val_accuracy: 0.9452\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1490 - accuracy: 0.9335 - val_loss: 0.1409 - val_accuracy: 0.9389\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1414 - accuracy: 0.9380 - val_loss: 0.1926 - val_accuracy: 0.9273\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.9335 - val_loss: 0.1400 - val_accuracy: 0.9405\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9368 - val_loss: 0.1347 - val_accuracy: 0.9478\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9340 - val_loss: 0.1262 - val_accuracy: 0.9452\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1388 - accuracy: 0.9358 - val_loss: 0.1245 - val_accuracy: 0.9521\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1397 - accuracy: 0.9405 - val_loss: 0.1338 - val_accuracy: 0.9362\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9395 - val_loss: 0.1318 - val_accuracy: 0.9473\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1354 - accuracy: 0.9410 - val_loss: 0.1221 - val_accuracy: 0.9478\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9396 - val_loss: 0.1172 - val_accuracy: 0.9547\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1375 - accuracy: 0.9403 - val_loss: 0.1152 - val_accuracy: 0.9505\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9370 - val_loss: 0.1175 - val_accuracy: 0.9510\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9449 - val_loss: 0.1450 - val_accuracy: 0.9373\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9438 - val_loss: 0.1127 - val_accuracy: 0.9515\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1261 - accuracy: 0.9474 - val_loss: 0.1065 - val_accuracy: 0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9430 - val_loss: 0.1097 - val_accuracy: 0.9552\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9471 - val_loss: 0.1156 - val_accuracy: 0.9499\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9464 - val_loss: 0.1209 - val_accuracy: 0.9468\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9441 - val_loss: 0.1221 - val_accuracy: 0.9568\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1194 - accuracy: 0.9502 - val_loss: 0.1159 - val_accuracy: 0.9573\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9488 - val_loss: 0.1228 - val_accuracy: 0.9473\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9489 - val_loss: 0.1107 - val_accuracy: 0.9494\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1202 - accuracy: 0.9473 - val_loss: 0.1221 - val_accuracy: 0.9468\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9521 - val_loss: 0.1087 - val_accuracy: 0.9621\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9506 - val_loss: 0.1071 - val_accuracy: 0.9563\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1209 - accuracy: 0.9468 - val_loss: 0.1102 - val_accuracy: 0.9494\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1164 - accuracy: 0.9509 - val_loss: 0.1238 - val_accuracy: 0.9463\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9504 - val_loss: 0.1019 - val_accuracy: 0.9579\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.9502 - val_loss: 0.1085 - val_accuracy: 0.9626\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9522 - val_loss: 0.1020 - val_accuracy: 0.9621\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9488 - val_loss: 0.0993 - val_accuracy: 0.9626\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9527 - val_loss: 0.1140 - val_accuracy: 0.9499\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9494 - val_loss: 0.1105 - val_accuracy: 0.9631\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9469 - val_loss: 0.1075 - val_accuracy: 0.9600\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9449 - val_loss: 0.1083 - val_accuracy: 0.9631\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9502 - val_loss: 0.1082 - val_accuracy: 0.9631\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1172 - accuracy: 0.9478 - val_loss: 0.1005 - val_accuracy: 0.9563\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1151 - accuracy: 0.9481 - val_loss: 0.1116 - val_accuracy: 0.9494\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9519 - val_loss: 0.1085 - val_accuracy: 0.9621\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9498 - val_loss: 0.1061 - val_accuracy: 0.9542\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1113 - accuracy: 0.9509 - val_loss: 0.0989 - val_accuracy: 0.9631\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1096 - accuracy: 0.9506 - val_loss: 0.1001 - val_accuracy: 0.9621\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9504 - val_loss: 0.0958 - val_accuracy: 0.9621\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9529 - val_loss: 0.1027 - val_accuracy: 0.9568\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9519 - val_loss: 0.1022 - val_accuracy: 0.9647\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1091 - accuracy: 0.9493 - val_loss: 0.0974 - val_accuracy: 0.9605\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1099 - accuracy: 0.9536 - val_loss: 0.1012 - val_accuracy: 0.9568\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1072 - accuracy: 0.9527 - val_loss: 0.1002 - val_accuracy: 0.9600\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1096 - accuracy: 0.9529 - val_loss: 0.0956 - val_accuracy: 0.9615\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1111 - accuracy: 0.9516 - val_loss: 0.1145 - val_accuracy: 0.9563\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9531 - val_loss: 0.1255 - val_accuracy: 0.9573\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1069 - accuracy: 0.9527 - val_loss: 0.0941 - val_accuracy: 0.9647\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1099 - accuracy: 0.9531 - val_loss: 0.0990 - val_accuracy: 0.9584\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9499 - val_loss: 0.0972 - val_accuracy: 0.9647\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9531 - val_loss: 0.0962 - val_accuracy: 0.9636\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9541 - val_loss: 0.0970 - val_accuracy: 0.9626\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9532 - val_loss: 0.0961 - val_accuracy: 0.9642\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9532 - val_loss: 0.0949 - val_accuracy: 0.9642\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9507 - val_loss: 0.0958 - val_accuracy: 0.9631\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9544 - val_loss: 0.0945 - val_accuracy: 0.9663\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9542 - val_loss: 0.0969 - val_accuracy: 0.9594\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9524 - val_loss: 0.0957 - val_accuracy: 0.9621\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9526 - val_loss: 0.0950 - val_accuracy: 0.9636\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9552 - val_loss: 0.0988 - val_accuracy: 0.9573\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9522 - val_loss: 0.0941 - val_accuracy: 0.9615\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1059 - accuracy: 0.9544 - val_loss: 0.0972 - val_accuracy: 0.9615\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1049 - accuracy: 0.9546 - val_loss: 0.0937 - val_accuracy: 0.9658\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9549 - val_loss: 0.1110 - val_accuracy: 0.9610\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9551 - val_loss: 0.0942 - val_accuracy: 0.9647\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9551 - val_loss: 0.1042 - val_accuracy: 0.9647\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9527 - val_loss: 0.0990 - val_accuracy: 0.9600\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9557 - val_loss: 0.0926 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1022 - accuracy: 0.9544 - val_loss: 0.0999 - val_accuracy: 0.9663\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9537 - val_loss: 0.0966 - val_accuracy: 0.9579\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.9534 - val_loss: 0.0970 - val_accuracy: 0.9594\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9547 - val_loss: 0.0923 - val_accuracy: 0.9668\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9556 - val_loss: 0.0919 - val_accuracy: 0.9631\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1009 - accuracy: 0.9564 - val_loss: 0.0905 - val_accuracy: 0.9636\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9534 - val_loss: 0.0940 - val_accuracy: 0.9600\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9547 - val_loss: 0.0976 - val_accuracy: 0.9610\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9546 - val_loss: 0.0929 - val_accuracy: 0.9642\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1012 - accuracy: 0.9561 - val_loss: 0.0933 - val_accuracy: 0.9621\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9564 - val_loss: 0.0974 - val_accuracy: 0.9600\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9549 - val_loss: 0.0916 - val_accuracy: 0.9658\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9561 - val_loss: 0.1138 - val_accuracy: 0.9478\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9566 - val_loss: 0.1003 - val_accuracy: 0.9642\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9574 - val_loss: 0.0933 - val_accuracy: 0.9636\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1034 - accuracy: 0.9559 - val_loss: 0.0953 - val_accuracy: 0.9584\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9584 - val_loss: 0.1018 - val_accuracy: 0.9631\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9562 - val_loss: 0.0921 - val_accuracy: 0.9652\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0982 - accuracy: 0.9567 - val_loss: 0.0981 - val_accuracy: 0.9594\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9562 - val_loss: 0.0956 - val_accuracy: 0.9621\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9599 - val_loss: 0.1066 - val_accuracy: 0.9536\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9562 - val_loss: 0.0950 - val_accuracy: 0.9584\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9574 - val_loss: 0.1010 - val_accuracy: 0.9542\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9579 - val_loss: 0.0918 - val_accuracy: 0.9652\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9597 - val_loss: 0.0960 - val_accuracy: 0.9647\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9589 - val_loss: 0.0997 - val_accuracy: 0.9563\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9546 - val_loss: 0.0916 - val_accuracy: 0.9652\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9562 - val_loss: 0.0918 - val_accuracy: 0.9668\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9575 - val_loss: 0.1048 - val_accuracy: 0.9573\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9580 - val_loss: 0.0924 - val_accuracy: 0.9663\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9602 - val_loss: 0.0920 - val_accuracy: 0.9668\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.9584 - val_loss: 0.0948 - val_accuracy: 0.9652\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9594 - val_loss: 0.0943 - val_accuracy: 0.9621\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9589 - val_loss: 0.0958 - val_accuracy: 0.9663\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9554 - val_loss: 0.0920 - val_accuracy: 0.9652\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9592 - val_loss: 0.0921 - val_accuracy: 0.9658\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9584 - val_loss: 0.0988 - val_accuracy: 0.9589\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9605 - val_loss: 0.0924 - val_accuracy: 0.9668\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9599 - val_loss: 0.0952 - val_accuracy: 0.9626\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0948 - accuracy: 0.9587 - val_loss: 0.0910 - val_accuracy: 0.9658\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9599 - val_loss: 0.0889 - val_accuracy: 0.9668\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0944 - accuracy: 0.9582 - val_loss: 0.1334 - val_accuracy: 0.9442\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9605 - val_loss: 0.0912 - val_accuracy: 0.9652\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0941 - accuracy: 0.9610 - val_loss: 0.0911 - val_accuracy: 0.9679\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9597 - val_loss: 0.0922 - val_accuracy: 0.9652\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9605 - val_loss: 0.0903 - val_accuracy: 0.9689\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9614 - val_loss: 0.0899 - val_accuracy: 0.9673\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9595 - val_loss: 0.0968 - val_accuracy: 0.9621\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9622 - val_loss: 0.0946 - val_accuracy: 0.9642\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9614 - val_loss: 0.1031 - val_accuracy: 0.9610\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9615 - val_loss: 0.1010 - val_accuracy: 0.9668\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9600 - val_loss: 0.0916 - val_accuracy: 0.9673\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9592 - val_loss: 0.1000 - val_accuracy: 0.9626\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9614 - val_loss: 0.0975 - val_accuracy: 0.9668\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9624 - val_loss: 0.0995 - val_accuracy: 0.9610\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0929 - accuracy: 0.9599 - val_loss: 0.0960 - val_accuracy: 0.9631\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0900 - accuracy: 0.9614 - val_loss: 0.0931 - val_accuracy: 0.9642\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9609 - val_loss: 0.0955 - val_accuracy: 0.9626\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9620 - val_loss: 0.0903 - val_accuracy: 0.9647\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9627 - val_loss: 0.0913 - val_accuracy: 0.9658\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9617 - val_loss: 0.0998 - val_accuracy: 0.9626\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9627 - val_loss: 0.1012 - val_accuracy: 0.9573\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9609 - val_loss: 0.0908 - val_accuracy: 0.9652\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0877 - accuracy: 0.9615 - val_loss: 0.0950 - val_accuracy: 0.9610\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9632 - val_loss: 0.0950 - val_accuracy: 0.9636\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9640 - val_loss: 0.0938 - val_accuracy: 0.9700\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9629 - val_loss: 0.0910 - val_accuracy: 0.9663\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9619 - val_loss: 0.0949 - val_accuracy: 0.9694\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9617 - val_loss: 0.0943 - val_accuracy: 0.9631\n",
      "6\n",
      "1\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 8, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 3, 64)             24640     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                6176      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,330\n",
      "Trainable params: 31,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.8897 - val_loss: 0.2062 - val_accuracy: 0.9204\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2073 - accuracy: 0.9154 - val_loss: 0.1768 - val_accuracy: 0.9299\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1780 - accuracy: 0.9242 - val_loss: 0.1442 - val_accuracy: 0.9384\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9274 - val_loss: 0.1558 - val_accuracy: 0.9320\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9315 - val_loss: 0.1322 - val_accuracy: 0.9452\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1505 - accuracy: 0.9350 - val_loss: 0.1409 - val_accuracy: 0.9420\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9367 - val_loss: 0.1284 - val_accuracy: 0.9447\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9327 - val_loss: 0.1244 - val_accuracy: 0.9463\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1409 - accuracy: 0.9363 - val_loss: 0.1240 - val_accuracy: 0.9489\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9371 - val_loss: 0.1227 - val_accuracy: 0.9484\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9362 - val_loss: 0.1220 - val_accuracy: 0.9505\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1397 - accuracy: 0.9393 - val_loss: 0.1220 - val_accuracy: 0.9499\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9383 - val_loss: 0.1226 - val_accuracy: 0.9473\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1327 - accuracy: 0.9418 - val_loss: 0.1226 - val_accuracy: 0.9494\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9430 - val_loss: 0.1151 - val_accuracy: 0.9526\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1324 - accuracy: 0.9411 - val_loss: 0.1169 - val_accuracy: 0.9584\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9448 - val_loss: 0.1115 - val_accuracy: 0.9589\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9454 - val_loss: 0.1124 - val_accuracy: 0.9573\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1302 - accuracy: 0.9431 - val_loss: 0.1128 - val_accuracy: 0.9568\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9436 - val_loss: 0.1152 - val_accuracy: 0.9589\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1234 - accuracy: 0.9459 - val_loss: 0.1227 - val_accuracy: 0.9463\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1219 - accuracy: 0.9488 - val_loss: 0.1110 - val_accuracy: 0.9552\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1240 - accuracy: 0.9458 - val_loss: 0.1075 - val_accuracy: 0.9642\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9474 - val_loss: 0.1067 - val_accuracy: 0.9605\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9491 - val_loss: 0.1087 - val_accuracy: 0.9679\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9486 - val_loss: 0.1147 - val_accuracy: 0.9610\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9474 - val_loss: 0.1119 - val_accuracy: 0.9521\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1154 - accuracy: 0.9504 - val_loss: 0.1036 - val_accuracy: 0.9621\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9488 - val_loss: 0.1018 - val_accuracy: 0.9621\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9476 - val_loss: 0.1096 - val_accuracy: 0.9600\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9511 - val_loss: 0.1013 - val_accuracy: 0.9673\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9537 - val_loss: 0.1053 - val_accuracy: 0.9631\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9552 - val_loss: 0.1090 - val_accuracy: 0.9542\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9529 - val_loss: 0.1015 - val_accuracy: 0.9600\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9519 - val_loss: 0.1062 - val_accuracy: 0.9552\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1123 - accuracy: 0.9507 - val_loss: 0.1137 - val_accuracy: 0.9484\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9534 - val_loss: 0.1028 - val_accuracy: 0.9626\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9544 - val_loss: 0.0949 - val_accuracy: 0.9658\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9536 - val_loss: 0.1191 - val_accuracy: 0.9626\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9534 - val_loss: 0.1027 - val_accuracy: 0.9626\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9547 - val_loss: 0.1033 - val_accuracy: 0.9557\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9537 - val_loss: 0.1161 - val_accuracy: 0.9594\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9536 - val_loss: 0.1004 - val_accuracy: 0.9615\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9559 - val_loss: 0.0932 - val_accuracy: 0.9679\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9544 - val_loss: 0.1004 - val_accuracy: 0.9579\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1042 - accuracy: 0.9567 - val_loss: 0.0959 - val_accuracy: 0.9647\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9575 - val_loss: 0.0970 - val_accuracy: 0.9626\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.9564 - val_loss: 0.0946 - val_accuracy: 0.9631\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1033 - accuracy: 0.9575 - val_loss: 0.1007 - val_accuracy: 0.9668\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9587 - val_loss: 0.0952 - val_accuracy: 0.9610\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1029 - accuracy: 0.9574 - val_loss: 0.0911 - val_accuracy: 0.9684\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9570 - val_loss: 0.0993 - val_accuracy: 0.9663\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9590 - val_loss: 0.1018 - val_accuracy: 0.9568\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9570 - val_loss: 0.0931 - val_accuracy: 0.9673\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9590 - val_loss: 0.1083 - val_accuracy: 0.9521\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9584 - val_loss: 0.0957 - val_accuracy: 0.9636\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9599 - val_loss: 0.0945 - val_accuracy: 0.9673\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9599 - val_loss: 0.0965 - val_accuracy: 0.9615\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9585 - val_loss: 0.0939 - val_accuracy: 0.9679\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9602 - val_loss: 0.0972 - val_accuracy: 0.9631\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9587 - val_loss: 0.0939 - val_accuracy: 0.9668\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9599 - val_loss: 0.1001 - val_accuracy: 0.9631\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9602 - val_loss: 0.0969 - val_accuracy: 0.9615\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9587 - val_loss: 0.1062 - val_accuracy: 0.9621\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9600 - val_loss: 0.1173 - val_accuracy: 0.9531\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9600 - val_loss: 0.0951 - val_accuracy: 0.9610\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9597 - val_loss: 0.0922 - val_accuracy: 0.9684\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0922 - accuracy: 0.9602 - val_loss: 0.0928 - val_accuracy: 0.9642\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9615 - val_loss: 0.1000 - val_accuracy: 0.9605\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9615 - val_loss: 0.0987 - val_accuracy: 0.9626\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.0959 - val_accuracy: 0.9689\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9632 - val_loss: 0.0922 - val_accuracy: 0.9642\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9629 - val_loss: 0.0900 - val_accuracy: 0.9647\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9633 - val_loss: 0.0982 - val_accuracy: 0.9605\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9632 - val_loss: 0.0969 - val_accuracy: 0.9700\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0889 - accuracy: 0.9635 - val_loss: 0.0950 - val_accuracy: 0.9636\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9642 - val_loss: 0.0938 - val_accuracy: 0.9668\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9642 - val_loss: 0.0958 - val_accuracy: 0.9631\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9652 - val_loss: 0.0994 - val_accuracy: 0.9579\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9624 - val_loss: 0.0955 - val_accuracy: 0.9631\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9647 - val_loss: 0.0963 - val_accuracy: 0.9658\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9645 - val_loss: 0.0905 - val_accuracy: 0.9642\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0858 - accuracy: 0.9655 - val_loss: 0.0929 - val_accuracy: 0.9621\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9650 - val_loss: 0.0961 - val_accuracy: 0.9626\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0861 - accuracy: 0.9662 - val_loss: 0.0930 - val_accuracy: 0.9621\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0826 - accuracy: 0.9648 - val_loss: 0.0965 - val_accuracy: 0.9626\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 2s 9ms/step - loss: 0.0832 - accuracy: 0.9672 - val_loss: 0.0943 - val_accuracy: 0.9652\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0854 - accuracy: 0.9647 - val_loss: 0.0990 - val_accuracy: 0.9605\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0826 - accuracy: 0.9657 - val_loss: 0.0974 - val_accuracy: 0.9658\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9677 - val_loss: 0.0966 - val_accuracy: 0.9621\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9648 - val_loss: 0.0984 - val_accuracy: 0.9668\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0831 - accuracy: 0.9682 - val_loss: 0.1000 - val_accuracy: 0.9647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0818 - accuracy: 0.9663 - val_loss: 0.0965 - val_accuracy: 0.9658\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 0.0991 - val_accuracy: 0.9636\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9657 - val_loss: 0.1138 - val_accuracy: 0.9615\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9687 - val_loss: 0.0964 - val_accuracy: 0.9631\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9655 - val_loss: 0.0932 - val_accuracy: 0.9684\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9695 - val_loss: 0.1039 - val_accuracy: 0.9673\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9698 - val_loss: 0.0983 - val_accuracy: 0.9658\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9675 - val_loss: 0.1012 - val_accuracy: 0.9652\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9683 - val_loss: 0.0952 - val_accuracy: 0.9658\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9710 - val_loss: 0.1025 - val_accuracy: 0.9658\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0779 - accuracy: 0.9693 - val_loss: 0.1028 - val_accuracy: 0.9621\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0786 - accuracy: 0.9687 - val_loss: 0.0982 - val_accuracy: 0.9663\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9692 - val_loss: 0.1002 - val_accuracy: 0.9673\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9678 - val_loss: 0.0994 - val_accuracy: 0.9663\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9693 - val_loss: 0.0982 - val_accuracy: 0.9642\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9690 - val_loss: 0.1064 - val_accuracy: 0.9610\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9703 - val_loss: 0.1034 - val_accuracy: 0.9663\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9698 - val_loss: 0.0998 - val_accuracy: 0.9636\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9667 - val_loss: 0.1087 - val_accuracy: 0.9600\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9708 - val_loss: 0.1165 - val_accuracy: 0.9589\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9693 - val_loss: 0.1029 - val_accuracy: 0.9642\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9703 - val_loss: 0.1033 - val_accuracy: 0.9636\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9718 - val_loss: 0.1014 - val_accuracy: 0.9658\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9725 - val_loss: 0.1063 - val_accuracy: 0.9631\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9692 - val_loss: 0.1049 - val_accuracy: 0.9631\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0744 - accuracy: 0.9701 - val_loss: 0.1159 - val_accuracy: 0.9615\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9741 - val_loss: 0.1026 - val_accuracy: 0.9668\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0738 - accuracy: 0.9708 - val_loss: 0.1001 - val_accuracy: 0.9615\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9716 - val_loss: 0.1140 - val_accuracy: 0.9642\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9713 - val_loss: 0.1035 - val_accuracy: 0.9679\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9706 - val_loss: 0.1084 - val_accuracy: 0.9626\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9715 - val_loss: 0.1087 - val_accuracy: 0.9610\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9705 - val_loss: 0.1038 - val_accuracy: 0.9668\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9726 - val_loss: 0.1032 - val_accuracy: 0.9631\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9698 - val_loss: 0.1096 - val_accuracy: 0.9636\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9746 - val_loss: 0.1010 - val_accuracy: 0.9626\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9698 - val_loss: 0.0959 - val_accuracy: 0.9663\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9738 - val_loss: 0.1034 - val_accuracy: 0.9642\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 0.9736 - val_loss: 0.1051 - val_accuracy: 0.9673\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9740 - val_loss: 0.1120 - val_accuracy: 0.9610\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 0.9728 - val_loss: 0.1089 - val_accuracy: 0.9621\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0687 - accuracy: 0.9735 - val_loss: 0.1028 - val_accuracy: 0.9658\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9723 - val_loss: 0.1158 - val_accuracy: 0.9584\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9736 - val_loss: 0.1140 - val_accuracy: 0.9615\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9758 - val_loss: 0.1192 - val_accuracy: 0.9642\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9755 - val_loss: 0.1105 - val_accuracy: 0.9626\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0691 - accuracy: 0.9713 - val_loss: 0.1056 - val_accuracy: 0.9642\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0644 - accuracy: 0.9743 - val_loss: 0.1048 - val_accuracy: 0.9647\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 0.9728 - val_loss: 0.1124 - val_accuracy: 0.9610\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 0.9731 - val_loss: 0.1234 - val_accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9766 - val_loss: 0.1108 - val_accuracy: 0.9652\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0670 - accuracy: 0.9718 - val_loss: 0.1138 - val_accuracy: 0.9626\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9735 - val_loss: 0.1276 - val_accuracy: 0.9658\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9741 - val_loss: 0.1176 - val_accuracy: 0.9621\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9745 - val_loss: 0.1188 - val_accuracy: 0.9610\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9711 - val_loss: 0.1180 - val_accuracy: 0.9636\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9723 - val_loss: 0.1101 - val_accuracy: 0.9605\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9748 - val_loss: 0.1116 - val_accuracy: 0.9631\n",
      "4\n",
      "1\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 13, 64)            320       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 9, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 6, 64)             16448     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                12320     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,154\n",
      "Trainable params: 29,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 2s 6ms/step - loss: 0.3088 - accuracy: 0.8731 - val_loss: 0.2216 - val_accuracy: 0.9083\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.2308 - accuracy: 0.9076 - val_loss: 0.2105 - val_accuracy: 0.9120\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9111 - val_loss: 0.1920 - val_accuracy: 0.9357\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9235 - val_loss: 0.1626 - val_accuracy: 0.9299\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1760 - accuracy: 0.9255 - val_loss: 0.1474 - val_accuracy: 0.9373\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1658 - accuracy: 0.9282 - val_loss: 0.1634 - val_accuracy: 0.9331\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1646 - accuracy: 0.9285 - val_loss: 0.1365 - val_accuracy: 0.9362\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9342 - val_loss: 0.1869 - val_accuracy: 0.9305\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1626 - accuracy: 0.9299 - val_loss: 0.1514 - val_accuracy: 0.9315\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.9337 - val_loss: 0.1372 - val_accuracy: 0.9410\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1518 - accuracy: 0.9317 - val_loss: 0.1366 - val_accuracy: 0.9426\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1422 - accuracy: 0.9353 - val_loss: 0.1352 - val_accuracy: 0.9452\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1482 - accuracy: 0.9353 - val_loss: 0.1236 - val_accuracy: 0.9473\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9367 - val_loss: 0.1614 - val_accuracy: 0.9305\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9357 - val_loss: 0.1347 - val_accuracy: 0.9442\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1492 - accuracy: 0.9342 - val_loss: 0.1227 - val_accuracy: 0.9478\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1433 - accuracy: 0.9347 - val_loss: 0.1228 - val_accuracy: 0.9473\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1425 - accuracy: 0.9330 - val_loss: 0.1246 - val_accuracy: 0.9468\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1384 - accuracy: 0.9370 - val_loss: 0.1287 - val_accuracy: 0.9457\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1407 - accuracy: 0.9358 - val_loss: 0.1268 - val_accuracy: 0.9478\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9396 - val_loss: 0.1251 - val_accuracy: 0.9484\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9385 - val_loss: 0.1217 - val_accuracy: 0.9526\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9415 - val_loss: 0.1316 - val_accuracy: 0.9415\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9375 - val_loss: 0.1226 - val_accuracy: 0.9505\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9408 - val_loss: 0.1198 - val_accuracy: 0.9521\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9388 - val_loss: 0.1197 - val_accuracy: 0.9547\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.9396 - val_loss: 0.1238 - val_accuracy: 0.9447\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9423 - val_loss: 0.1202 - val_accuracy: 0.9552\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1317 - accuracy: 0.9408 - val_loss: 0.1175 - val_accuracy: 0.9536\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9428 - val_loss: 0.1200 - val_accuracy: 0.9542\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1320 - accuracy: 0.9431 - val_loss: 0.1284 - val_accuracy: 0.9505\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1327 - accuracy: 0.9420 - val_loss: 0.1179 - val_accuracy: 0.9526\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1307 - accuracy: 0.9421 - val_loss: 0.1136 - val_accuracy: 0.9552\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9443 - val_loss: 0.1144 - val_accuracy: 0.9557\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9398 - val_loss: 0.1136 - val_accuracy: 0.9547\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.9434 - val_loss: 0.1156 - val_accuracy: 0.9510\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9468 - val_loss: 0.1189 - val_accuracy: 0.9478\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1259 - accuracy: 0.9436 - val_loss: 0.1289 - val_accuracy: 0.9415\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1258 - accuracy: 0.9469 - val_loss: 0.1173 - val_accuracy: 0.9499\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1277 - accuracy: 0.9426 - val_loss: 0.1367 - val_accuracy: 0.9378\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9463 - val_loss: 0.1145 - val_accuracy: 0.9610\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9448 - val_loss: 0.1100 - val_accuracy: 0.9557\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1269 - accuracy: 0.9448 - val_loss: 0.1130 - val_accuracy: 0.9552\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9449 - val_loss: 0.1129 - val_accuracy: 0.9573\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1214 - accuracy: 0.9449 - val_loss: 0.1136 - val_accuracy: 0.9594\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1238 - accuracy: 0.9430 - val_loss: 0.1078 - val_accuracy: 0.9526\n",
      "Epoch 47/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1212 - accuracy: 0.9461 - val_loss: 0.1119 - val_accuracy: 0.9568\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1216 - accuracy: 0.9439 - val_loss: 0.1092 - val_accuracy: 0.9615\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9481 - val_loss: 0.1126 - val_accuracy: 0.9610\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1186 - accuracy: 0.9474 - val_loss: 0.1102 - val_accuracy: 0.9636\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9473 - val_loss: 0.1042 - val_accuracy: 0.9579\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9479 - val_loss: 0.1158 - val_accuracy: 0.9484\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9491 - val_loss: 0.1126 - val_accuracy: 0.9579\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9456 - val_loss: 0.1136 - val_accuracy: 0.9473\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.9493 - val_loss: 0.1081 - val_accuracy: 0.9579\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1157 - accuracy: 0.9471 - val_loss: 0.1080 - val_accuracy: 0.9584\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9488 - val_loss: 0.1059 - val_accuracy: 0.9515\n",
      "Epoch 58/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9517 - val_loss: 0.1140 - val_accuracy: 0.9605\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1163 - accuracy: 0.9498 - val_loss: 0.1259 - val_accuracy: 0.9594\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9547 - val_loss: 0.1026 - val_accuracy: 0.9647\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1113 - accuracy: 0.9512 - val_loss: 0.1029 - val_accuracy: 0.9652\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.9502 - val_loss: 0.1131 - val_accuracy: 0.9647\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9489 - val_loss: 0.0988 - val_accuracy: 0.9668\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9514 - val_loss: 0.1040 - val_accuracy: 0.9658\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1115 - accuracy: 0.9521 - val_loss: 0.1057 - val_accuracy: 0.9563\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9506 - val_loss: 0.0985 - val_accuracy: 0.9631\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9522 - val_loss: 0.1031 - val_accuracy: 0.9694\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9478 - val_loss: 0.1039 - val_accuracy: 0.9626\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1127 - accuracy: 0.9519 - val_loss: 0.1000 - val_accuracy: 0.9610\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1083 - accuracy: 0.9521 - val_loss: 0.1052 - val_accuracy: 0.9573\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1084 - accuracy: 0.9534 - val_loss: 0.0996 - val_accuracy: 0.9626\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1053 - accuracy: 0.9539 - val_loss: 0.1171 - val_accuracy: 0.9547\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1098 - accuracy: 0.9529 - val_loss: 0.1070 - val_accuracy: 0.9652\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1072 - accuracy: 0.9536 - val_loss: 0.0981 - val_accuracy: 0.9673\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9552 - val_loss: 0.1021 - val_accuracy: 0.9589\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9531 - val_loss: 0.0987 - val_accuracy: 0.9652\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9532 - val_loss: 0.1070 - val_accuracy: 0.9526\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9556 - val_loss: 0.0971 - val_accuracy: 0.9663\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1042 - accuracy: 0.9537 - val_loss: 0.1021 - val_accuracy: 0.9594\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9557 - val_loss: 0.0983 - val_accuracy: 0.9626\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1064 - accuracy: 0.9567 - val_loss: 0.1031 - val_accuracy: 0.9615\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1095 - accuracy: 0.9547 - val_loss: 0.0981 - val_accuracy: 0.9610\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1043 - accuracy: 0.9547 - val_loss: 0.1272 - val_accuracy: 0.9573\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1049 - accuracy: 0.9541 - val_loss: 0.0983 - val_accuracy: 0.9621\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1029 - accuracy: 0.9579 - val_loss: 0.1062 - val_accuracy: 0.9552\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1069 - accuracy: 0.9536 - val_loss: 0.1018 - val_accuracy: 0.9668\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1007 - accuracy: 0.9572 - val_loss: 0.0975 - val_accuracy: 0.9647\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9557 - val_loss: 0.0978 - val_accuracy: 0.9631\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9559 - val_loss: 0.0979 - val_accuracy: 0.9621\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1020 - accuracy: 0.9552 - val_loss: 0.1043 - val_accuracy: 0.9584\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9569 - val_loss: 0.1007 - val_accuracy: 0.9631\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9564 - val_loss: 0.1020 - val_accuracy: 0.9605\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1004 - accuracy: 0.9566 - val_loss: 0.0953 - val_accuracy: 0.9668\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1005 - accuracy: 0.9561 - val_loss: 0.0952 - val_accuracy: 0.9647\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1009 - accuracy: 0.9564 - val_loss: 0.0960 - val_accuracy: 0.9658\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9552 - val_loss: 0.0946 - val_accuracy: 0.9631\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9587 - val_loss: 0.0938 - val_accuracy: 0.9642\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9570 - val_loss: 0.1011 - val_accuracy: 0.9626\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9561 - val_loss: 0.1017 - val_accuracy: 0.9642\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9557 - val_loss: 0.0953 - val_accuracy: 0.9642\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1006 - accuracy: 0.9569 - val_loss: 0.0982 - val_accuracy: 0.9673\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0948 - accuracy: 0.9604 - val_loss: 0.1021 - val_accuracy: 0.9631\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0982 - accuracy: 0.9574 - val_loss: 0.0940 - val_accuracy: 0.9642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9590 - val_loss: 0.0968 - val_accuracy: 0.9679\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9595 - val_loss: 0.1010 - val_accuracy: 0.9600\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9590 - val_loss: 0.1004 - val_accuracy: 0.9673\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9579 - val_loss: 0.1109 - val_accuracy: 0.9589\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9582 - val_loss: 0.1027 - val_accuracy: 0.9557\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9585 - val_loss: 0.1155 - val_accuracy: 0.9531\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9575 - val_loss: 0.0997 - val_accuracy: 0.9600\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9590 - val_loss: 0.1088 - val_accuracy: 0.9636\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9589 - val_loss: 0.0942 - val_accuracy: 0.9626\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9605 - val_loss: 0.0919 - val_accuracy: 0.9658\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.1036 - val_accuracy: 0.9621\n",
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9582 - val_loss: 0.1094 - val_accuracy: 0.9531\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9600 - val_loss: 0.0973 - val_accuracy: 0.9610\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9602 - val_loss: 0.1183 - val_accuracy: 0.9526\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9604 - val_loss: 0.1019 - val_accuracy: 0.9610\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9587 - val_loss: 0.1008 - val_accuracy: 0.9615\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0920 - accuracy: 0.9594 - val_loss: 0.0972 - val_accuracy: 0.9621\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9619 - val_loss: 0.0959 - val_accuracy: 0.9679\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9614 - val_loss: 0.0949 - val_accuracy: 0.9626\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9609 - val_loss: 0.1018 - val_accuracy: 0.9579\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9619 - val_loss: 0.1065 - val_accuracy: 0.9647\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9642 - val_loss: 0.0952 - val_accuracy: 0.9621\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9599 - val_loss: 0.0956 - val_accuracy: 0.9642\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0921 - accuracy: 0.9614 - val_loss: 0.1100 - val_accuracy: 0.9631\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9622 - val_loss: 0.0951 - val_accuracy: 0.9647\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9635 - val_loss: 0.1081 - val_accuracy: 0.9542\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9609 - val_loss: 0.0932 - val_accuracy: 0.9626\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0892 - accuracy: 0.9615 - val_loss: 0.0951 - val_accuracy: 0.9658\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0884 - accuracy: 0.9620 - val_loss: 0.1032 - val_accuracy: 0.9600\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 8ms/step - loss: 0.0892 - accuracy: 0.9617 - val_loss: 0.0988 - val_accuracy: 0.9652\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0893 - accuracy: 0.9630 - val_loss: 0.0998 - val_accuracy: 0.9652\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9632 - val_loss: 0.0960 - val_accuracy: 0.9631\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9630 - val_loss: 0.1004 - val_accuracy: 0.9642\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9610 - val_loss: 0.0949 - val_accuracy: 0.9647\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9619 - val_loss: 0.0972 - val_accuracy: 0.9636\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9630 - val_loss: 0.1197 - val_accuracy: 0.9642\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9617 - val_loss: 0.0985 - val_accuracy: 0.9636\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9624 - val_loss: 0.1080 - val_accuracy: 0.9557\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0863 - accuracy: 0.9627 - val_loss: 0.0982 - val_accuracy: 0.9600\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9653 - val_loss: 0.0990 - val_accuracy: 0.9631\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9632 - val_loss: 0.0992 - val_accuracy: 0.9621\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9638 - val_loss: 0.1008 - val_accuracy: 0.9636\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9617 - val_loss: 0.1031 - val_accuracy: 0.9626\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0863 - accuracy: 0.9630 - val_loss: 0.1037 - val_accuracy: 0.9610\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0857 - accuracy: 0.9665 - val_loss: 0.1077 - val_accuracy: 0.9642\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9645 - val_loss: 0.1065 - val_accuracy: 0.9594\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9650 - val_loss: 0.1024 - val_accuracy: 0.9636\n",
      "6\n",
      "1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 11, 64)            448       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 7, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 2, 64)             24640     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,282\n",
      "Trainable params: 29,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.3074 - accuracy: 0.8667 - val_loss: 0.2070 - val_accuracy: 0.9178\n",
      "Epoch 2/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.2098 - accuracy: 0.9126 - val_loss: 0.1783 - val_accuracy: 0.9326\n",
      "Epoch 3/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9245 - val_loss: 0.1982 - val_accuracy: 0.9210\n",
      "Epoch 4/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9250 - val_loss: 0.1420 - val_accuracy: 0.9362\n",
      "Epoch 5/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9307 - val_loss: 0.1294 - val_accuracy: 0.9415\n",
      "Epoch 6/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9322 - val_loss: 0.1341 - val_accuracy: 0.9468\n",
      "Epoch 7/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9320 - val_loss: 0.1337 - val_accuracy: 0.9405\n",
      "Epoch 8/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1417 - accuracy: 0.9367 - val_loss: 0.1324 - val_accuracy: 0.9442\n",
      "Epoch 9/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.1454 - accuracy: 0.9335 - val_loss: 0.1317 - val_accuracy: 0.9457\n",
      "Epoch 10/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9401 - val_loss: 0.1224 - val_accuracy: 0.9494\n",
      "Epoch 11/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.1415 - accuracy: 0.9378 - val_loss: 0.1694 - val_accuracy: 0.9252\n",
      "Epoch 12/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1365 - accuracy: 0.9378 - val_loss: 0.1203 - val_accuracy: 0.9510\n",
      "Epoch 13/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1340 - accuracy: 0.9390 - val_loss: 0.1218 - val_accuracy: 0.9489\n",
      "Epoch 14/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9410 - val_loss: 0.1255 - val_accuracy: 0.9505\n",
      "Epoch 15/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9395 - val_loss: 0.1167 - val_accuracy: 0.9547\n",
      "Epoch 16/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9405 - val_loss: 0.1320 - val_accuracy: 0.9499\n",
      "Epoch 17/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1299 - accuracy: 0.9408 - val_loss: 0.1170 - val_accuracy: 0.9542\n",
      "Epoch 18/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1281 - accuracy: 0.9410 - val_loss: 0.1210 - val_accuracy: 0.9536\n",
      "Epoch 19/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9438 - val_loss: 0.1328 - val_accuracy: 0.9362\n",
      "Epoch 20/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1286 - accuracy: 0.9416 - val_loss: 0.1256 - val_accuracy: 0.9552\n",
      "Epoch 21/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9415 - val_loss: 0.1140 - val_accuracy: 0.9563\n",
      "Epoch 22/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.9434 - val_loss: 0.1349 - val_accuracy: 0.9452\n",
      "Epoch 23/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9403 - val_loss: 0.1188 - val_accuracy: 0.9494\n",
      "Epoch 24/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9458 - val_loss: 0.1174 - val_accuracy: 0.9531\n",
      "Epoch 25/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9438 - val_loss: 0.1179 - val_accuracy: 0.9531\n",
      "Epoch 26/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9403 - val_loss: 0.1153 - val_accuracy: 0.9542\n",
      "Epoch 27/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9423 - val_loss: 0.1140 - val_accuracy: 0.9536\n",
      "Epoch 28/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1240 - accuracy: 0.9434 - val_loss: 0.1238 - val_accuracy: 0.9399\n",
      "Epoch 29/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9471 - val_loss: 0.1161 - val_accuracy: 0.9557\n",
      "Epoch 30/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9466 - val_loss: 0.1170 - val_accuracy: 0.9568\n",
      "Epoch 31/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9456 - val_loss: 0.1149 - val_accuracy: 0.9531\n",
      "Epoch 32/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9481 - val_loss: 0.1117 - val_accuracy: 0.9563\n",
      "Epoch 33/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9471 - val_loss: 0.1139 - val_accuracy: 0.9505\n",
      "Epoch 34/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9466 - val_loss: 0.1147 - val_accuracy: 0.9505\n",
      "Epoch 35/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9499 - val_loss: 0.1178 - val_accuracy: 0.9463\n",
      "Epoch 36/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9461 - val_loss: 0.1124 - val_accuracy: 0.9536\n",
      "Epoch 37/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9524 - val_loss: 0.1056 - val_accuracy: 0.9615\n",
      "Epoch 38/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9501 - val_loss: 0.1103 - val_accuracy: 0.9668\n",
      "Epoch 39/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9516 - val_loss: 0.1252 - val_accuracy: 0.9436\n",
      "Epoch 40/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1133 - accuracy: 0.9493 - val_loss: 0.1058 - val_accuracy: 0.9679\n",
      "Epoch 41/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9501 - val_loss: 0.1248 - val_accuracy: 0.9415\n",
      "Epoch 42/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9524 - val_loss: 0.1113 - val_accuracy: 0.9510\n",
      "Epoch 43/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9541 - val_loss: 0.1168 - val_accuracy: 0.9536\n",
      "Epoch 44/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9529 - val_loss: 0.1039 - val_accuracy: 0.9594\n",
      "Epoch 45/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9521 - val_loss: 0.1133 - val_accuracy: 0.9636\n",
      "Epoch 46/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9541 - val_loss: 0.1021 - val_accuracy: 0.9615\n",
      "Epoch 47/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9539 - val_loss: 0.1132 - val_accuracy: 0.9636\n",
      "Epoch 48/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9549 - val_loss: 0.1087 - val_accuracy: 0.9531\n",
      "Epoch 49/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.9554 - val_loss: 0.1040 - val_accuracy: 0.9626\n",
      "Epoch 50/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1046 - accuracy: 0.9539 - val_loss: 0.1045 - val_accuracy: 0.9663\n",
      "Epoch 51/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1077 - accuracy: 0.9537 - val_loss: 0.1123 - val_accuracy: 0.9642\n",
      "Epoch 52/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9541 - val_loss: 0.1024 - val_accuracy: 0.9673\n",
      "Epoch 53/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9561 - val_loss: 0.1009 - val_accuracy: 0.9621\n",
      "Epoch 54/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9547 - val_loss: 0.1033 - val_accuracy: 0.9642\n",
      "Epoch 55/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9556 - val_loss: 0.1108 - val_accuracy: 0.9521\n",
      "Epoch 56/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9549 - val_loss: 0.1014 - val_accuracy: 0.9594\n",
      "Epoch 57/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9554 - val_loss: 0.1067 - val_accuracy: 0.9631\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9580 - val_loss: 0.1004 - val_accuracy: 0.9631\n",
      "Epoch 59/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9566 - val_loss: 0.1007 - val_accuracy: 0.9626\n",
      "Epoch 60/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9577 - val_loss: 0.0982 - val_accuracy: 0.9652\n",
      "Epoch 61/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9575 - val_loss: 0.1120 - val_accuracy: 0.9610\n",
      "Epoch 62/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9552 - val_loss: 0.1005 - val_accuracy: 0.9621\n",
      "Epoch 63/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9572 - val_loss: 0.1031 - val_accuracy: 0.9589\n",
      "Epoch 64/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9559 - val_loss: 0.1109 - val_accuracy: 0.9589\n",
      "Epoch 65/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9594 - val_loss: 0.1043 - val_accuracy: 0.9610\n",
      "Epoch 66/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0975 - accuracy: 0.9569 - val_loss: 0.1087 - val_accuracy: 0.9631\n",
      "Epoch 67/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9569 - val_loss: 0.1019 - val_accuracy: 0.9658\n",
      "Epoch 68/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9594 - val_loss: 0.1054 - val_accuracy: 0.9594\n",
      "Epoch 69/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9574 - val_loss: 0.1055 - val_accuracy: 0.9636\n",
      "Epoch 70/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9610 - val_loss: 0.1013 - val_accuracy: 0.9621\n",
      "Epoch 71/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9612 - val_loss: 0.1135 - val_accuracy: 0.9610\n",
      "Epoch 72/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9614 - val_loss: 0.1033 - val_accuracy: 0.9605\n",
      "Epoch 73/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9599 - val_loss: 0.1013 - val_accuracy: 0.9642\n",
      "Epoch 74/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9604 - val_loss: 0.1026 - val_accuracy: 0.9652\n",
      "Epoch 75/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9589 - val_loss: 0.1070 - val_accuracy: 0.9626\n",
      "Epoch 76/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9604 - val_loss: 0.1053 - val_accuracy: 0.9636\n",
      "Epoch 77/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9597 - val_loss: 0.1019 - val_accuracy: 0.9631\n",
      "Epoch 78/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9607 - val_loss: 0.1026 - val_accuracy: 0.9600\n",
      "Epoch 79/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9629 - val_loss: 0.1106 - val_accuracy: 0.9626\n",
      "Epoch 80/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9617 - val_loss: 0.1036 - val_accuracy: 0.9647\n",
      "Epoch 81/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9597 - val_loss: 0.1013 - val_accuracy: 0.9589\n",
      "Epoch 82/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0885 - accuracy: 0.9627 - val_loss: 0.1054 - val_accuracy: 0.9584\n",
      "Epoch 83/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9627 - val_loss: 0.1016 - val_accuracy: 0.9631\n",
      "Epoch 84/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9602 - val_loss: 0.1013 - val_accuracy: 0.9615\n",
      "Epoch 85/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9624 - val_loss: 0.1029 - val_accuracy: 0.9610\n",
      "Epoch 86/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9605 - val_loss: 0.1009 - val_accuracy: 0.9626\n",
      "Epoch 87/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0884 - accuracy: 0.9630 - val_loss: 0.1054 - val_accuracy: 0.9573\n",
      "Epoch 88/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0901 - accuracy: 0.9650 - val_loss: 0.1089 - val_accuracy: 0.9605\n",
      "Epoch 89/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0879 - accuracy: 0.9627 - val_loss: 0.1058 - val_accuracy: 0.9626\n",
      "Epoch 90/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9629 - val_loss: 0.1041 - val_accuracy: 0.9642\n",
      "Epoch 91/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0875 - accuracy: 0.9642 - val_loss: 0.1031 - val_accuracy: 0.9631\n",
      "Epoch 92/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0895 - accuracy: 0.9633 - val_loss: 0.1035 - val_accuracy: 0.9610\n",
      "Epoch 93/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9625 - val_loss: 0.1011 - val_accuracy: 0.9626\n",
      "Epoch 94/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9640 - val_loss: 0.1057 - val_accuracy: 0.9626\n",
      "Epoch 95/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9648 - val_loss: 0.1033 - val_accuracy: 0.9621\n",
      "Epoch 96/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9627 - val_loss: 0.1054 - val_accuracy: 0.9652\n",
      "Epoch 97/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0847 - accuracy: 0.9652 - val_loss: 0.1160 - val_accuracy: 0.9568\n",
      "Epoch 98/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9662 - val_loss: 0.1015 - val_accuracy: 0.9636\n",
      "Epoch 99/150\n",
      "189/189 [==============================] - 1s 6ms/step - loss: 0.0835 - accuracy: 0.9643 - val_loss: 0.1121 - val_accuracy: 0.9610\n",
      "Epoch 100/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0828 - accuracy: 0.9662 - val_loss: 0.1075 - val_accuracy: 0.9652\n",
      "Epoch 101/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9650 - val_loss: 0.1030 - val_accuracy: 0.9615\n",
      "Epoch 102/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0832 - accuracy: 0.9660 - val_loss: 0.1051 - val_accuracy: 0.9631\n",
      "Epoch 103/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9667 - val_loss: 0.1132 - val_accuracy: 0.9626\n",
      "Epoch 104/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9653 - val_loss: 0.1049 - val_accuracy: 0.9647\n",
      "Epoch 105/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9653 - val_loss: 0.1056 - val_accuracy: 0.9615\n",
      "Epoch 106/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.9657 - val_loss: 0.1038 - val_accuracy: 0.9636\n",
      "Epoch 107/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9655 - val_loss: 0.1164 - val_accuracy: 0.9568\n",
      "Epoch 108/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9688 - val_loss: 0.1074 - val_accuracy: 0.9652\n",
      "Epoch 109/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9697 - val_loss: 0.1051 - val_accuracy: 0.9615\n",
      "Epoch 110/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9678 - val_loss: 0.1038 - val_accuracy: 0.9663\n",
      "Epoch 111/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9657 - val_loss: 0.1129 - val_accuracy: 0.9658\n",
      "Epoch 112/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9650 - val_loss: 0.1112 - val_accuracy: 0.9600\n",
      "Epoch 113/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0782 - accuracy: 0.9687 - val_loss: 0.1045 - val_accuracy: 0.9626\n",
      "Epoch 114/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9683 - val_loss: 0.1079 - val_accuracy: 0.9626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9672 - val_loss: 0.1117 - val_accuracy: 0.9594\n",
      "Epoch 116/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9683 - val_loss: 0.1055 - val_accuracy: 0.9642\n",
      "Epoch 117/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0760 - accuracy: 0.9682 - val_loss: 0.1071 - val_accuracy: 0.9663\n",
      "Epoch 118/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9675 - val_loss: 0.1073 - val_accuracy: 0.9594\n",
      "Epoch 119/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0727 - accuracy: 0.9718 - val_loss: 0.1139 - val_accuracy: 0.9636\n",
      "Epoch 120/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0782 - accuracy: 0.9685 - val_loss: 0.1130 - val_accuracy: 0.9652\n",
      "Epoch 121/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9667 - val_loss: 0.1108 - val_accuracy: 0.9631\n",
      "Epoch 122/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.9675 - val_loss: 0.1078 - val_accuracy: 0.9652\n",
      "Epoch 123/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9725 - val_loss: 0.1184 - val_accuracy: 0.9589\n",
      "Epoch 124/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0754 - accuracy: 0.9685 - val_loss: 0.1144 - val_accuracy: 0.9621\n",
      "Epoch 125/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0737 - accuracy: 0.9700 - val_loss: 0.1160 - val_accuracy: 0.9615\n",
      "Epoch 126/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9692 - val_loss: 0.1079 - val_accuracy: 0.9647\n",
      "Epoch 127/150\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9701 - val_loss: 0.1104 - val_accuracy: 0.9600\n",
      "Epoch 128/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0757 - accuracy: 0.9673 - val_loss: 0.1101 - val_accuracy: 0.9647\n",
      "Epoch 129/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9690 - val_loss: 0.1111 - val_accuracy: 0.9615\n",
      "Epoch 130/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9692 - val_loss: 0.1199 - val_accuracy: 0.9636\n",
      "Epoch 131/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9710 - val_loss: 0.1195 - val_accuracy: 0.9621\n",
      "Epoch 132/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9700 - val_loss: 0.1097 - val_accuracy: 0.9652\n",
      "Epoch 133/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9698 - val_loss: 0.1139 - val_accuracy: 0.9589\n",
      "Epoch 134/150\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.0706 - accuracy: 0.9695 - val_loss: 0.1211 - val_accuracy: 0.9626\n",
      "Epoch 135/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9711 - val_loss: 0.1091 - val_accuracy: 0.9652\n",
      "Epoch 136/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 0.9715 - val_loss: 0.1207 - val_accuracy: 0.9663\n",
      "Epoch 137/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9731 - val_loss: 0.1176 - val_accuracy: 0.9573\n",
      "Epoch 138/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0694 - accuracy: 0.9715 - val_loss: 0.1209 - val_accuracy: 0.9658\n",
      "Epoch 139/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9715 - val_loss: 0.1122 - val_accuracy: 0.9621\n",
      "Epoch 140/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9746 - val_loss: 0.1369 - val_accuracy: 0.9621\n",
      "Epoch 141/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9706 - val_loss: 0.1164 - val_accuracy: 0.9642\n",
      "Epoch 142/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9710 - val_loss: 0.1216 - val_accuracy: 0.9605\n",
      "Epoch 143/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9698 - val_loss: 0.1190 - val_accuracy: 0.9600\n",
      "Epoch 144/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9733 - val_loss: 0.1363 - val_accuracy: 0.9573\n",
      "Epoch 145/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9703 - val_loss: 0.1200 - val_accuracy: 0.9647\n",
      "Epoch 146/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.9720 - val_loss: 0.1233 - val_accuracy: 0.9615\n",
      "Epoch 147/150\n",
      "189/189 [==============================] - 1s 5ms/step - loss: 0.0716 - accuracy: 0.9680 - val_loss: 0.1132 - val_accuracy: 0.9631\n",
      "Epoch 148/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9721 - val_loss: 0.1164 - val_accuracy: 0.9621\n",
      "Epoch 149/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9728 - val_loss: 0.1280 - val_accuracy: 0.9668\n",
      "Epoch 150/150\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9723 - val_loss: 0.1154 - val_accuracy: 0.9636\n"
     ]
    }
   ],
   "source": [
    "ms = []\n",
    "hs = []\n",
    "for p in [3,4,5]:\n",
    "    for k in [4,6]:\n",
    "        for s in [1]:\n",
    "            if not (s==2 and k==4):\n",
    "                print(k)\n",
    "                print(s)\n",
    "                model = CNN_Model(filters1=64, filters2 = 64,kernel_size=k,strides=s, pool_size=p)\n",
    "                model.summary()\n",
    "                ms.append(model)\n",
    "                history = model.fit(X_train, y_train, epochs=150, \n",
    "                                validation_data=(X_val, y_val))\n",
    "                hs.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a9ae78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 - 0s - loss: 0.1172 - accuracy: 0.9579 - 123ms/epoch - 2ms/step\n",
      "Test Loss: 0.11721281707286835\n",
      "Test Accuracy: 0.9578503966331482\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       947\n",
      "           1       0.95      0.97      0.96       951\n",
      "\n",
      "    accuracy                           0.96      1898\n",
      "   macro avg       0.96      0.96      0.96      1898\n",
      "weighted avg       0.96      0.96      0.96      1898\n",
      "\n",
      "60/60 - 0s - loss: 0.1223 - accuracy: 0.9594 - 120ms/epoch - 2ms/step\n",
      "Test Loss: 0.12232336401939392\n",
      "Test Accuracy: 0.959430992603302\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       926\n",
      "           1       0.96      0.96      0.96       972\n",
      "\n",
      "    accuracy                           0.96      1898\n",
      "   macro avg       0.96      0.96      0.96      1898\n",
      "weighted avg       0.96      0.96      0.96      1898\n",
      "\n",
      "60/60 - 0s - loss: 0.1106 - accuracy: 0.9521 - 125ms/epoch - 2ms/step\n",
      "Test Loss: 0.11055293679237366\n",
      "Test Accuracy: 0.9520547986030579\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       962\n",
      "           1       0.94      0.97      0.95       936\n",
      "\n",
      "    accuracy                           0.95      1898\n",
      "   macro avg       0.95      0.95      0.95      1898\n",
      "weighted avg       0.95      0.95      0.95      1898\n",
      "\n",
      "60/60 - 0s - loss: 0.1155 - accuracy: 0.9610 - 112ms/epoch - 2ms/step\n",
      "Test Loss: 0.1155407726764679\n",
      "Test Accuracy: 0.9610115885734558\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       909\n",
      "           1       0.97      0.95      0.96       989\n",
      "\n",
      "    accuracy                           0.96      1898\n",
      "   macro avg       0.96      0.96      0.96      1898\n",
      "weighted avg       0.96      0.96      0.96      1898\n",
      "\n",
      "60/60 - 0s - loss: 0.1208 - accuracy: 0.9510 - 162ms/epoch - 3ms/step\n",
      "Test Loss: 0.12083180248737335\n",
      "Test Accuracy: 0.9510010480880737\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       882\n",
      "           1       0.98      0.93      0.95      1016\n",
      "\n",
      "    accuracy                           0.95      1898\n",
      "   macro avg       0.95      0.95      0.95      1898\n",
      "weighted avg       0.95      0.95      0.95      1898\n",
      "\n",
      "60/60 - 0s - loss: 0.1175 - accuracy: 0.9589 - 132ms/epoch - 2ms/step\n",
      "Test Loss: 0.11746390163898468\n",
      "Test Accuracy: 0.9589040875434875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       913\n",
      "           1       0.97      0.95      0.96       985\n",
      "\n",
      "    accuracy                           0.96      1898\n",
      "   macro avg       0.96      0.96      0.96      1898\n",
      "weighted avg       0.96      0.96      0.96      1898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in ms:\n",
    "    test_loss, test_acc = m.evaluate(X_test,  y_test, verbose=2)\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "    y_pred = np.argmax(m.predict(X_test), axis=-1)\n",
    "    plt.matshow(confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "    plt.ylabel(\"Predicted Category\", fontsize=14)\n",
    "    plt.title(\"Category\", fontsize=14)\n",
    "    plt.show()\n",
    "    print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1125818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(hs)):\n",
    "    plt.plot(hs[i].history['accuracy'], label='accuracy')\n",
    "    plt.plot(hs[i].history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    print(\"a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d629fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................*....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................*...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................*...........................................................................................................................................................................................................................................................................................................................................................................*\n",
      "optimization finished, #iter = 2626748\n",
      "obj = -1115025.993229, rho = -0.530004\n",
      "nSV = 644, nBSV = 560\n",
      "Total nSV = 644\n",
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "[[1280   61]\n",
      " [  64 1442]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1341\n",
      "           1       0.96      0.96      0.96      1506\n",
      "\n",
      "    accuracy                           0.96      2847\n",
      "   macro avg       0.96      0.96      0.96      2847\n",
      "weighted avg       0.96      0.96      0.96      2847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df= pd.read_csv('../feature_data/features.csv')\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X = df.drop([\"label\"],axis=1)\n",
    "X = X.drop([\"radius\"],axis=1)\n",
    "cols = X.keys()\n",
    "\n",
    "#normalize data\n",
    "X = preprocessing.normalize(X, norm='max')\n",
    "\n",
    "#labels\n",
    "y = df[\"label\"]\n",
    "#idx = y == 0\n",
    "#y[idx]=-1\n",
    "\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "X['label'] = y\n",
    "\n",
    "#features\n",
    "X = pd.DataFrame(X, columns = cols)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size= 0.3)\n",
    "\n",
    "\n",
    "from sklearn.svm import OneClassSVM,SVC\n",
    "\n",
    "rf= SVC(kernel = \"poly\", C=2000,verbose=True)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "predictions= rf.predict(X_test)\n",
    "print(predictions[0:10])\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
